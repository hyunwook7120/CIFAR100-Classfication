{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab219bd-07ce-41b3-93dc-733f628561ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481d66eb-1120-4cf2-83d8-f8447a0a3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa702f55-e7fc-4da1-ad9b-f11aa95b5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3813a9b5-f613-4dbd-b441-96c46c4f94b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ee18c5-0e2d-4dd6-9e5e-cadf2c181821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhw03\\AppData\\Local\\Temp\\ipykernel_22504\\3178576206.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(\"./runs/resnet_18_base/savepoints/Sunday_06_October_2024_13h_21m_09s/ResNet_18_base-238-best.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 부분만 수정!!\n",
    "from models import resnet\n",
    "net = resnet.resnet18()\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(\"./runs/resnet_18_base/savepoints/Sunday_06_October_2024_13h_21m_09s/ResNet_18_base-238-best.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad7e98a-cc27-45be-b201-c03229eab6b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2_x): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv3_x): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv4_x): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv5_x): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (residual_function): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e1fa4-85c6-4041-ae97-7e5553ccf1fa",
   "metadata": {},
   "source": [
    "##### **fine_to_superclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ffe3ba-26c9-4ef5-a090-875d67d4c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_to_superclass = {\n",
    "    # aquatic mammals\n",
    "    4: 0, 30: 0, 55: 0, 72: 0, 95: 0,\n",
    "    \n",
    "    # fish\n",
    "    1: 1, 32: 1, 67: 1, 73: 1, 91: 1,\n",
    "    \n",
    "    # flowers\n",
    "    54: 2, 62: 2, 70: 2, 82: 2, 92: 2,\n",
    "    \n",
    "    # food containers\n",
    "    9: 3, 10: 3, 16: 3, 28: 3, 61: 3,\n",
    "    \n",
    "    # fruit and vegetables\n",
    "    0: 4, 51: 4, 53: 4, 57: 4, 83: 4,\n",
    "    \n",
    "    # household electrical devices\n",
    "    22: 5, 39: 5, 40: 5, 86: 5, 87: 5,\n",
    "    \n",
    "    # household furniture\n",
    "    5: 6, 20: 6, 25: 6, 84: 6, 94: 6,\n",
    "    \n",
    "    # insects\n",
    "    6: 7, 7: 7, 14: 7, 18: 7, 24: 7,\n",
    "    \n",
    "    # large carnivores\n",
    "    3: 8, 42: 8, 43: 8, 88: 8, 97: 8,\n",
    "    \n",
    "    # large man-made outdoor things\n",
    "    12: 9, 17: 9, 37: 9, 68: 9, 76: 9,\n",
    "    \n",
    "    # large natural outdoor scenes\n",
    "    23: 10, 33: 10, 49: 10, 60: 10, 71: 10,\n",
    "    \n",
    "    # large omnivores and herbivores\n",
    "    15: 11, 19: 11, 21: 11, 31: 11, 38: 11,\n",
    "    \n",
    "    # medium-sized mammals\n",
    "    34: 12, 63: 12, 64: 12, 66: 12, 75: 12,\n",
    "    \n",
    "    # non-insect invertebrates\n",
    "    26: 13, 45: 13, 77: 13, 79: 13, 99: 13,\n",
    "    \n",
    "    # people\n",
    "    2: 14, 11: 14, 35: 14, 46: 14, 98: 14,\n",
    "    \n",
    "    # reptiles\n",
    "    27: 15, 29: 15, 44: 15, 78: 15, 93: 15,\n",
    "    \n",
    "    # small mammals\n",
    "    36: 16, 50: 16, 65: 16, 74: 16, 80: 16,\n",
    "    \n",
    "    # trees\n",
    "    47: 17, 52: 17, 56: 17, 59: 17, 96: 17,\n",
    "    \n",
    "    # vehicles 1\n",
    "    8: 18, 13: 18, 48: 18, 58: 18, 90: 18,\n",
    "    \n",
    "    # vehicles 2\n",
    "    41: 19, 69: 19, 81: 19, 85: 19, 89: 19\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02661f-4404-48e9-82d3-6b3e8fcf23ac",
   "metadata": {},
   "source": [
    "##### **Get Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b88fb4-3cc2-4272-81f0-9f5d1bde4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_accuracy(net, test_loader, device):\n",
    "    correct_1_fine = 0.0  # 세부 클래스 top-1 정확도\n",
    "    correct_5_fine = 0.0  # 세부 클래스 top-5 정확도\n",
    "    correct_1_super = 0.0  # 슈퍼 클래스 top-1 정확도\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_iter, (image, label) in enumerate(test_loader):\n",
    "            print(\"iteration: {}\\ttotal {} iterations\".format(n_iter + 1, len(test_loader)))\n",
    "    \n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "    \n",
    "            output = net(image)\n",
    "            _, pred = output.topk(5, 1, largest=True, sorted=True)\n",
    "    \n",
    "            label = label.view(label.size(0), -1).expand_as(pred)\n",
    "            correct = pred.eq(label).float()\n",
    "    \n",
    "            # 세부 클래스 top-5 정확도\n",
    "            correct_5_fine += correct[:, :5].sum()\n",
    "            # 세부 클래스 top-1 정확도\n",
    "            correct_1_fine += correct[:, :1].sum()\n",
    "    \n",
    "            # 슈퍼 클래스 변환 (contiguous()로 메모리 연속성 확보 후 view() 사용)\n",
    "            target_super = torch.tensor([fine_to_superclass[t.item()] for t in label.contiguous().view(-1)], device=device)\n",
    "            pred_super = torch.tensor([fine_to_superclass[p.item()] for p in pred.contiguous().view(-1)], device=device).view_as(pred)\n",
    "    \n",
    "            # target_super를 pred_super의 크기로 확장\n",
    "            target_super = target_super.view(label.size(0), 5).expand_as(pred_super)\n",
    "    \n",
    "            # 슈퍼 클래스 top-1 정확도만 계산\n",
    "            correct_super = pred_super.eq(target_super).float()\n",
    "            correct_1_super += correct_super[:, :1].sum()\n",
    "    \n",
    "            total += label.size(0)\n",
    "    \n",
    "    # 세부 클래스 및 슈퍼 클래스 정확도 계산\n",
    "    top1_acc_fine = correct_1_fine / total\n",
    "    top5_acc_fine = correct_5_fine / total\n",
    "    top1_acc_super = correct_1_super / total\n",
    "\n",
    "    return top1_acc_fine, top5_acc_fine, top1_acc_super"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe07f0d-299f-4c27-95b7-56a8e4db37a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\ttotal 79 iterations\n",
      "iteration: 2\ttotal 79 iterations\n",
      "iteration: 3\ttotal 79 iterations\n",
      "iteration: 4\ttotal 79 iterations\n",
      "iteration: 5\ttotal 79 iterations\n",
      "iteration: 6\ttotal 79 iterations\n",
      "iteration: 7\ttotal 79 iterations\n",
      "iteration: 8\ttotal 79 iterations\n",
      "iteration: 9\ttotal 79 iterations\n",
      "iteration: 10\ttotal 79 iterations\n",
      "iteration: 11\ttotal 79 iterations\n",
      "iteration: 12\ttotal 79 iterations\n",
      "iteration: 13\ttotal 79 iterations\n",
      "iteration: 14\ttotal 79 iterations\n",
      "iteration: 15\ttotal 79 iterations\n",
      "iteration: 16\ttotal 79 iterations\n",
      "iteration: 17\ttotal 79 iterations\n",
      "iteration: 18\ttotal 79 iterations\n",
      "iteration: 19\ttotal 79 iterations\n",
      "iteration: 20\ttotal 79 iterations\n",
      "iteration: 21\ttotal 79 iterations\n",
      "iteration: 22\ttotal 79 iterations\n",
      "iteration: 23\ttotal 79 iterations\n",
      "iteration: 24\ttotal 79 iterations\n",
      "iteration: 25\ttotal 79 iterations\n",
      "iteration: 26\ttotal 79 iterations\n",
      "iteration: 27\ttotal 79 iterations\n",
      "iteration: 28\ttotal 79 iterations\n",
      "iteration: 29\ttotal 79 iterations\n",
      "iteration: 30\ttotal 79 iterations\n",
      "iteration: 31\ttotal 79 iterations\n",
      "iteration: 32\ttotal 79 iterations\n",
      "iteration: 33\ttotal 79 iterations\n",
      "iteration: 34\ttotal 79 iterations\n",
      "iteration: 35\ttotal 79 iterations\n",
      "iteration: 36\ttotal 79 iterations\n",
      "iteration: 37\ttotal 79 iterations\n",
      "iteration: 38\ttotal 79 iterations\n",
      "iteration: 39\ttotal 79 iterations\n",
      "iteration: 40\ttotal 79 iterations\n",
      "iteration: 41\ttotal 79 iterations\n",
      "iteration: 42\ttotal 79 iterations\n",
      "iteration: 43\ttotal 79 iterations\n",
      "iteration: 44\ttotal 79 iterations\n",
      "iteration: 45\ttotal 79 iterations\n",
      "iteration: 46\ttotal 79 iterations\n",
      "iteration: 47\ttotal 79 iterations\n",
      "iteration: 48\ttotal 79 iterations\n",
      "iteration: 49\ttotal 79 iterations\n",
      "iteration: 50\ttotal 79 iterations\n",
      "iteration: 51\ttotal 79 iterations\n",
      "iteration: 52\ttotal 79 iterations\n",
      "iteration: 53\ttotal 79 iterations\n",
      "iteration: 54\ttotal 79 iterations\n",
      "iteration: 55\ttotal 79 iterations\n",
      "iteration: 56\ttotal 79 iterations\n",
      "iteration: 57\ttotal 79 iterations\n",
      "iteration: 58\ttotal 79 iterations\n",
      "iteration: 59\ttotal 79 iterations\n",
      "iteration: 60\ttotal 79 iterations\n",
      "iteration: 61\ttotal 79 iterations\n",
      "iteration: 62\ttotal 79 iterations\n",
      "iteration: 63\ttotal 79 iterations\n",
      "iteration: 64\ttotal 79 iterations\n",
      "iteration: 65\ttotal 79 iterations\n",
      "iteration: 66\ttotal 79 iterations\n",
      "iteration: 67\ttotal 79 iterations\n",
      "iteration: 68\ttotal 79 iterations\n",
      "iteration: 69\ttotal 79 iterations\n",
      "iteration: 70\ttotal 79 iterations\n",
      "iteration: 71\ttotal 79 iterations\n",
      "iteration: 72\ttotal 79 iterations\n",
      "iteration: 73\ttotal 79 iterations\n",
      "iteration: 74\ttotal 79 iterations\n",
      "iteration: 75\ttotal 79 iterations\n",
      "iteration: 76\ttotal 79 iterations\n",
      "iteration: 77\ttotal 79 iterations\n",
      "iteration: 78\ttotal 79 iterations\n",
      "iteration: 79\ttotal 79 iterations\n"
     ]
    }
   ],
   "source": [
    "acc = all_accuracy(net, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97c601b-df1e-48e3-8c5b-45387709d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Fine Class accuracy: 0.7581\n",
      "Top 5 Fine Class accuracy: 0.9345\n",
      "Top 1 Super Class accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 1 Fine Class accuracy: {:.4f}\".format(acc[0]))\n",
    "print(\"Top 5 Fine Class accuracy: {:.4f}\".format(acc[1]))\n",
    "print(\"Top 1 Super Class accuracy: {:.4f}\".format(acc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0179ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
