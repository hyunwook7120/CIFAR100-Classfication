{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab70dee5-0563-44bf-aac5-fd2065985481",
   "metadata": {},
   "source": [
    "# **Data - 나영**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457d367-10af-4473-8f3d-77198447a7bb",
   "metadata": {},
   "source": [
    "### **Load Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562d9cb0-9691-4f07-a788-38b1f17bb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from utility.early_stopping import EarlyStopping\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8e0bb-e8d3-45cf-a26f-2405ff3fce13",
   "metadata": {},
   "source": [
    "**Seed Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84c3f64-0389-4b7c-83c8-a32ee52e3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348e605-f472-4e8b-9e59-d7f9971c7c55",
   "metadata": {},
   "source": [
    "**Device Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "035d096c-7962-4214-a220-c5b27b3d04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2a04d-7b38-4826-b55c-f31ad07811d9",
   "metadata": {},
   "source": [
    "**Set Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4225472f-8390-4f0e-b3ea-85598022cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936f9c8-6a53-4d17-8b05-2f7bbde99746",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb77a99-0ecc-4dee-8373-8f73d0814215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4), \n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2bee68-5466-4bdc-bbaa-2ae55ca6463e",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3ac53-39cd-458e-802e-6b7da0170f63",
   "metadata": {},
   "source": [
    "**Splitting th training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cf780b-d6ba-4123-a0c1-be7a7a762575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_val_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_val_transform)\n",
    "test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "257be9c9-628b-4ef4-8f1e-a9466ee8d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
    "# test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00da17f-0962-4907-8aae-505f5a64cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 train/val로 나누기\n",
    "num_train = len(train_val_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.2 * num_train))  # validation 데이터를 20%로 설정\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b3c41-7fe8-4959-81b8-50354ef33c9c",
   "metadata": {},
   "source": [
    "**Define DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6133b787-b855-4064-b019-88a62b64d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_val_data, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "val_loader = DataLoader(train_val_data, batch_size=batch_size, sampler=val_sampler, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b18f60-5d55-4b53-9506-788bcb425362",
   "metadata": {},
   "source": [
    "# **Model - 하연**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb4694-6995-4316-8009-49c47d4d5fdd",
   "metadata": {},
   "source": [
    "models 폴더에 만들고 import 하는 식으로 해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9548e-68bc-4b50-8f43-75c084ae7f3d",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16c71685-4257-4da5-8f8b-6d8f8945f4d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use: cuda:0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,728\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "            Conv2d-7         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-8         [-1, 64, 224, 224]             128\n",
      "        BasicBlock-9         [-1, 64, 224, 224]               0\n",
      "           Conv2d-10         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-11         [-1, 64, 224, 224]             128\n",
      "             ReLU-12         [-1, 64, 224, 224]               0\n",
      "           Conv2d-13         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-14         [-1, 64, 224, 224]             128\n",
      "       BasicBlock-15         [-1, 64, 224, 224]               0\n",
      "           Conv2d-16        [-1, 128, 112, 112]          73,728\n",
      "      BatchNorm2d-17        [-1, 128, 112, 112]             256\n",
      "             ReLU-18        [-1, 128, 112, 112]               0\n",
      "           Conv2d-19        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-20        [-1, 128, 112, 112]             256\n",
      "           Conv2d-21        [-1, 128, 112, 112]           8,192\n",
      "      BatchNorm2d-22        [-1, 128, 112, 112]             256\n",
      "       BasicBlock-23        [-1, 128, 112, 112]               0\n",
      "           Conv2d-24        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-25        [-1, 128, 112, 112]             256\n",
      "             ReLU-26        [-1, 128, 112, 112]               0\n",
      "           Conv2d-27        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-28        [-1, 128, 112, 112]             256\n",
      "       BasicBlock-29        [-1, 128, 112, 112]               0\n",
      "           Conv2d-30          [-1, 256, 56, 56]         294,912\n",
      "      BatchNorm2d-31          [-1, 256, 56, 56]             512\n",
      "             ReLU-32          [-1, 256, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "           Conv2d-35          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "       BasicBlock-37          [-1, 256, 56, 56]               0\n",
      "           Conv2d-38          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 56, 56]             512\n",
      "             ReLU-40          [-1, 256, 56, 56]               0\n",
      "           Conv2d-41          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-42          [-1, 256, 56, 56]             512\n",
      "       BasicBlock-43          [-1, 256, 56, 56]               0\n",
      "           Conv2d-44          [-1, 512, 28, 28]       1,179,648\n",
      "      BatchNorm2d-45          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-46          [-1, 512, 28, 28]               0\n",
      "           Conv2d-47          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-48          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "       BasicBlock-51          [-1, 512, 28, 28]               0\n",
      "           Conv2d-52          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-53          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-54          [-1, 512, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "       BasicBlock-57          [-1, 512, 28, 28]               0\n",
      "AdaptiveAvgPool2d-58            [-1, 512, 1, 1]               0\n",
      "           Linear-59                  [-1, 100]          51,300\n",
      "================================================================\n",
      "Total params: 11,220,132\n",
      "Trainable params: 11,220,132\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 667.63\n",
      "Params size (MB): 42.80\n",
      "Estimated Total Size (MB): 711.01\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # models 폴더의 경로 추가\n",
    "# sys.path.append('./models')\n",
    "\n",
    "print(\"use:\", device)\n",
    "\n",
    "# 모델 import 하기\n",
    "from models.resnetRS import ResNetRS18\n",
    "from models import resnet\n",
    "\n",
    "# 모델 초기화\n",
    "net = resnet.resnet18()\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "net.to(device)\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(summary(net, (3, 224, 224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae781b4f-9e8b-4ea3-8b1e-9b67e857a088",
   "metadata": {},
   "source": [
    "### **Loss and Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1b668f-0288-43c3-a08a-83a11a0d85d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]}]\n"
     ]
    }
   ],
   "source": [
    "# 손실함수 초기화\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# 옵티마이저의 state_dict 출력\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09003b-468e-4e89-9285-b6ec501c20cf",
   "metadata": {},
   "source": [
    "# **Train - 하연**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a80805-e7a2-4bdc-b854-9d183c306bf5",
   "metadata": {},
   "source": [
    "### **Model Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4337e604-8477-4a57-80fc-a2d96afcb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./runs/resnet_18/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13f6bb1b-efc7-4146-acbb-b2b28de16580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./runs/resnet_18/checkpoints\"\n",
    "# early_stopping = EarlyStopping(save_path)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b20456-0576-49db-b3d1-97ef4cb49d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train_model(model, trainloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            labels = labels.type(torch.LongTensor).to(device)  # CPU에서 long type tensor로 변환\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 역전파 및 최적화\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # 30번째 배치마다 상태 출력\n",
    "            if (batch_idx + 1) % 30 == 0:\n",
    "                print(f\"Batch [{batch_idx+1}/{len(trainloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Epoch당 평균 손실 계산 및 출력\n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping 체크\n",
    "        early_stopping(epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825de7e7-59bc-49aa-bd7a-c27a61c10fcb",
   "metadata": {},
   "source": [
    "**Model Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15180770-96df-487a-8c70-5743cc4dd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 및 테스트 함수 (superclass 예측 포함)\n",
    "def test_model(model, testloader, criterion, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "            \n",
    "            # 예측 결과 저장 및 정확도 계산\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "\n",
    "            # TensorBoard에 테스트 손실 및 정확도 기록\n",
    "            writer.add_scalar(\"Test Loss\", test_loss / len(testloader.dataset), epoch)\n",
    "            writer.add_scalar(\"Test Accuracy\", correct / len(testloader.dataset), epoch)\n",
    "\n",
    "    # 평균 손실 및 정확도 계산\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0669a96-2d88-4b8b-bc33-82701eabf923",
   "metadata": {},
   "source": [
    "### **Per-Epoch Activity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330ce51-1f1d-4ad8-a127-a82f34c3899e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [30/313], Loss: 4.5407\n",
      "Batch [60/313], Loss: 4.4200\n",
      "Batch [90/313], Loss: 4.2457\n",
      "Batch [120/313], Loss: 4.2392\n",
      "Batch [150/313], Loss: 3.9844\n",
      "Batch [180/313], Loss: 4.0849\n",
      "Batch [210/313], Loss: 3.9340\n",
      "Batch [240/313], Loss: 3.8321\n",
      "Batch [270/313], Loss: 3.8538\n",
      "Batch [300/313], Loss: 3.8021\n",
      "Epoch [1/20], Loss: 3.2889\n",
      "Validation loss decreased (inf --> 3.288852).  Saving model ...\n",
      "Batch [30/313], Loss: 3.9197\n",
      "Batch [60/313], Loss: 3.7285\n",
      "Batch [90/313], Loss: 3.4634\n",
      "Batch [120/313], Loss: 3.6148\n",
      "Batch [150/313], Loss: 3.5735\n",
      "Batch [180/313], Loss: 3.5115\n",
      "Batch [210/313], Loss: 3.5495\n",
      "Batch [240/313], Loss: 3.5395\n",
      "Batch [270/313], Loss: 3.4256\n",
      "Batch [300/313], Loss: 3.3767\n",
      "Epoch [2/20], Loss: 2.8679\n",
      "Validation loss decreased (3.288852 --> 2.867903).  Saving model ...\n",
      "Batch [30/313], Loss: 3.6272\n",
      "Batch [60/313], Loss: 3.4037\n",
      "Batch [90/313], Loss: 3.3992\n",
      "Batch [120/313], Loss: 3.1510\n",
      "Batch [150/313], Loss: 3.3535\n",
      "Batch [180/313], Loss: 3.2254\n",
      "Batch [210/313], Loss: 3.2571\n",
      "Batch [240/313], Loss: 3.1672\n",
      "Batch [270/313], Loss: 3.0323\n",
      "Batch [300/313], Loss: 3.2314\n",
      "Epoch [3/20], Loss: 2.6364\n",
      "Validation loss decreased (2.867903 --> 2.636447).  Saving model ...\n",
      "Batch [30/313], Loss: 3.0638\n",
      "Batch [60/313], Loss: 3.3308\n",
      "Batch [90/313], Loss: 2.7921\n",
      "Batch [120/313], Loss: 3.2498\n",
      "Batch [150/313], Loss: 3.1481\n",
      "Batch [180/313], Loss: 3.1889\n",
      "Batch [210/313], Loss: 3.0543\n",
      "Batch [240/313], Loss: 3.0965\n",
      "Batch [270/313], Loss: 2.8606\n",
      "Batch [300/313], Loss: 2.9331\n",
      "Epoch [4/20], Loss: 2.4342\n",
      "Validation loss decreased (2.636447 --> 2.434181).  Saving model ...\n",
      "Batch [30/313], Loss: 2.7520\n",
      "Batch [60/313], Loss: 2.8837\n",
      "Batch [90/313], Loss: 2.8434\n",
      "Batch [120/313], Loss: 2.9594\n",
      "Batch [150/313], Loss: 2.8707\n",
      "Batch [180/313], Loss: 2.9460\n",
      "Batch [210/313], Loss: 2.7539\n",
      "Batch [240/313], Loss: 2.7891\n",
      "Batch [270/313], Loss: 2.7339\n",
      "Batch [300/313], Loss: 2.6577\n",
      "Epoch [5/20], Loss: 2.2623\n",
      "Validation loss decreased (2.434181 --> 2.262292).  Saving model ...\n",
      "Batch [30/313], Loss: 2.7827\n",
      "Batch [60/313], Loss: 2.6262\n",
      "Batch [90/313], Loss: 2.5915\n",
      "Batch [120/313], Loss: 2.5823\n",
      "Batch [150/313], Loss: 2.4173\n",
      "Batch [180/313], Loss: 2.5805\n",
      "Batch [210/313], Loss: 2.4254\n",
      "Batch [240/313], Loss: 2.6243\n",
      "Batch [270/313], Loss: 2.8479\n",
      "Batch [300/313], Loss: 2.8098\n",
      "Epoch [6/20], Loss: 2.1010\n",
      "Validation loss decreased (2.262292 --> 2.100993).  Saving model ...\n",
      "Batch [30/313], Loss: 2.2533\n",
      "Batch [60/313], Loss: 2.5316\n",
      "Batch [90/313], Loss: 2.7511\n",
      "Batch [120/313], Loss: 2.4165\n",
      "Batch [150/313], Loss: 2.5930\n",
      "Batch [180/313], Loss: 2.3525\n",
      "Batch [210/313], Loss: 2.4225\n",
      "Batch [240/313], Loss: 2.5267\n",
      "Batch [270/313], Loss: 2.2637\n",
      "Batch [300/313], Loss: 2.4399\n",
      "Epoch [7/20], Loss: 1.9633\n",
      "Validation loss decreased (2.100993 --> 1.963350).  Saving model ...\n",
      "Batch [30/313], Loss: 2.3004\n",
      "Batch [60/313], Loss: 2.4973\n",
      "Batch [90/313], Loss: 2.6655\n",
      "Batch [120/313], Loss: 2.4930\n",
      "Batch [150/313], Loss: 2.4070\n",
      "Batch [180/313], Loss: 2.0866\n",
      "Batch [210/313], Loss: 2.7574\n",
      "Batch [240/313], Loss: 2.4033\n",
      "Batch [270/313], Loss: 2.2812\n",
      "Batch [300/313], Loss: 2.2996\n",
      "Epoch [8/20], Loss: 1.8458\n",
      "Validation loss decreased (1.963350 --> 1.845813).  Saving model ...\n",
      "Batch [30/313], Loss: 2.2257\n",
      "Batch [60/313], Loss: 2.2202\n",
      "Batch [90/313], Loss: 2.1715\n",
      "Batch [120/313], Loss: 2.2150\n",
      "Batch [150/313], Loss: 2.2490\n",
      "Batch [180/313], Loss: 2.2165\n",
      "Batch [210/313], Loss: 2.0758\n",
      "Batch [240/313], Loss: 2.1238\n",
      "Batch [270/313], Loss: 1.9828\n",
      "Batch [300/313], Loss: 1.8075\n",
      "Epoch [9/20], Loss: 1.7404\n",
      "Validation loss decreased (1.845813 --> 1.740418).  Saving model ...\n",
      "Batch [30/313], Loss: 2.2558\n",
      "Batch [60/313], Loss: 2.3284\n",
      "Batch [90/313], Loss: 2.1346\n",
      "Batch [120/313], Loss: 1.9259\n",
      "Batch [150/313], Loss: 1.9812\n",
      "Batch [180/313], Loss: 2.0712\n",
      "Batch [210/313], Loss: 2.1811\n",
      "Batch [240/313], Loss: 2.0177\n",
      "Batch [270/313], Loss: 2.1042\n",
      "Batch [300/313], Loss: 2.1404\n",
      "Epoch [10/20], Loss: 1.6498\n",
      "Validation loss decreased (1.740418 --> 1.649824).  Saving model ...\n",
      "Batch [30/313], Loss: 1.9833\n",
      "Batch [60/313], Loss: 1.9530\n",
      "Batch [90/313], Loss: 1.9928\n",
      "Batch [120/313], Loss: 1.8213\n",
      "Batch [150/313], Loss: 2.1292\n",
      "Batch [180/313], Loss: 1.9535\n",
      "Batch [210/313], Loss: 2.0678\n",
      "Batch [240/313], Loss: 1.9058\n",
      "Batch [270/313], Loss: 1.8126\n",
      "Batch [300/313], Loss: 1.7505\n",
      "Epoch [11/20], Loss: 1.5685\n",
      "Validation loss decreased (1.649824 --> 1.568471).  Saving model ...\n",
      "Batch [30/313], Loss: 1.8245\n",
      "Batch [60/313], Loss: 1.7648\n",
      "Batch [90/313], Loss: 1.7665\n",
      "Batch [120/313], Loss: 2.1566\n",
      "Batch [150/313], Loss: 1.4684\n",
      "Batch [180/313], Loss: 2.0406\n",
      "Batch [210/313], Loss: 2.0297\n",
      "Batch [240/313], Loss: 1.7172\n",
      "Batch [270/313], Loss: 1.7671\n",
      "Batch [300/313], Loss: 1.7740\n",
      "Epoch [12/20], Loss: 1.4875\n",
      "Validation loss decreased (1.568471 --> 1.487497).  Saving model ...\n",
      "Batch [30/313], Loss: 1.8441\n",
      "Batch [60/313], Loss: 1.9682\n",
      "Batch [90/313], Loss: 1.7002\n",
      "Batch [120/313], Loss: 1.6370\n",
      "Batch [150/313], Loss: 1.7212\n",
      "Batch [180/313], Loss: 2.0101\n",
      "Batch [210/313], Loss: 1.6377\n",
      "Batch [240/313], Loss: 1.7560\n",
      "Batch [270/313], Loss: 1.6477\n",
      "Batch [300/313], Loss: 1.6998\n",
      "Epoch [13/20], Loss: 1.4171\n",
      "Validation loss decreased (1.487497 --> 1.417089).  Saving model ...\n",
      "Batch [30/313], Loss: 1.7284\n",
      "Batch [60/313], Loss: 1.5865\n",
      "Batch [90/313], Loss: 1.5919\n",
      "Batch [120/313], Loss: 1.6474\n",
      "Batch [150/313], Loss: 1.7111\n",
      "Batch [180/313], Loss: 1.5271\n",
      "Batch [210/313], Loss: 1.9295\n",
      "Batch [240/313], Loss: 1.6688\n",
      "Batch [270/313], Loss: 1.6762\n",
      "Batch [300/313], Loss: 1.4415\n",
      "Epoch [14/20], Loss: 1.3533\n",
      "Validation loss decreased (1.417089 --> 1.353258).  Saving model ...\n",
      "Batch [30/313], Loss: 1.5144\n",
      "Batch [60/313], Loss: 1.6880\n",
      "Batch [90/313], Loss: 1.5479\n",
      "Batch [120/313], Loss: 1.4438\n",
      "Batch [150/313], Loss: 1.5484\n",
      "Batch [180/313], Loss: 1.5316\n",
      "Batch [210/313], Loss: 1.4598\n",
      "Batch [240/313], Loss: 1.5866\n",
      "Batch [270/313], Loss: 1.5443\n",
      "Batch [300/313], Loss: 1.8116\n",
      "Epoch [15/20], Loss: 1.2933\n",
      "Validation loss decreased (1.353258 --> 1.293322).  Saving model ...\n",
      "Batch [30/313], Loss: 1.4820\n",
      "Batch [60/313], Loss: 1.4737\n",
      "Batch [90/313], Loss: 1.6725\n",
      "Batch [120/313], Loss: 1.4938\n",
      "Batch [150/313], Loss: 1.3764\n",
      "Batch [180/313], Loss: 1.4565\n",
      "Batch [210/313], Loss: 1.5290\n",
      "Batch [240/313], Loss: 1.3880\n",
      "Batch [270/313], Loss: 1.6154\n",
      "Batch [300/313], Loss: 1.3534\n",
      "Epoch [16/20], Loss: 1.2380\n",
      "Validation loss decreased (1.293322 --> 1.237987).  Saving model ...\n",
      "Batch [30/313], Loss: 1.5244\n",
      "Batch [60/313], Loss: 1.3542\n",
      "Batch [90/313], Loss: 1.3156\n",
      "Batch [120/313], Loss: 1.6712\n",
      "Batch [150/313], Loss: 1.6935\n",
      "Batch [180/313], Loss: 1.5534\n",
      "Batch [210/313], Loss: 1.1978\n",
      "Batch [240/313], Loss: 1.3574\n",
      "Batch [270/313], Loss: 1.4143\n",
      "Batch [300/313], Loss: 1.6528\n",
      "Epoch [17/20], Loss: 1.1823\n",
      "Validation loss decreased (1.237987 --> 1.182264).  Saving model ...\n",
      "Batch [30/313], Loss: 1.2890\n",
      "Batch [60/313], Loss: 1.6497\n",
      "Batch [90/313], Loss: 1.4319\n",
      "Batch [120/313], Loss: 1.5365\n",
      "Batch [150/313], Loss: 1.2312\n",
      "Batch [180/313], Loss: 1.5585\n",
      "Batch [210/313], Loss: 1.5542\n",
      "Batch [240/313], Loss: 1.4325\n",
      "Batch [270/313], Loss: 1.2420\n",
      "Batch [300/313], Loss: 1.1262\n",
      "Epoch [18/20], Loss: 1.1306\n",
      "Validation loss decreased (1.182264 --> 1.130589).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1922\n",
      "Batch [60/313], Loss: 1.4085\n",
      "Batch [90/313], Loss: 1.3287\n",
      "Batch [120/313], Loss: 1.2687\n",
      "Batch [150/313], Loss: 1.5279\n",
      "Batch [180/313], Loss: 1.3621\n",
      "Batch [210/313], Loss: 1.3241\n",
      "Batch [240/313], Loss: 1.3887\n",
      "Batch [270/313], Loss: 1.4542\n",
      "Batch [300/313], Loss: 1.3346\n",
      "Epoch [19/20], Loss: 1.0893\n",
      "Validation loss decreased (1.130589 --> 1.089309).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1779\n",
      "Batch [60/313], Loss: 1.3068\n",
      "Batch [90/313], Loss: 1.1172\n",
      "Batch [120/313], Loss: 1.3744\n",
      "Batch [150/313], Loss: 1.4295\n",
      "Batch [180/313], Loss: 1.1953\n",
      "Batch [210/313], Loss: 1.2496\n",
      "Batch [240/313], Loss: 1.3429\n",
      "Batch [270/313], Loss: 1.3918\n",
      "Batch [300/313], Loss: 1.3838\n",
      "Epoch [20/20], Loss: 1.0414\n",
      "Validation loss decreased (1.089309 --> 1.041417).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 1/20 [03:11<1:00:40, 191.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]   Loss: 1.6968   Accuracy: 54.29%\n",
      "Batch [30/313], Loss: 1.2417\n",
      "Batch [60/313], Loss: 1.0816\n",
      "Batch [90/313], Loss: 1.0654\n",
      "Batch [120/313], Loss: 1.3992\n",
      "Batch [150/313], Loss: 1.0646\n",
      "Batch [180/313], Loss: 1.3713\n",
      "Batch [210/313], Loss: 1.1942\n",
      "Batch [240/313], Loss: 1.3772\n",
      "Batch [270/313], Loss: 1.1415\n",
      "Batch [300/313], Loss: 1.1031\n",
      "Epoch [1/20], Loss: 1.0047\n",
      "Validation loss decreased (1.041417 --> 1.004664).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1067\n",
      "Batch [60/313], Loss: 1.2287\n",
      "Batch [90/313], Loss: 1.3281\n",
      "Batch [120/313], Loss: 1.0633\n",
      "Batch [150/313], Loss: 1.2228\n",
      "Batch [180/313], Loss: 1.1257\n",
      "Batch [210/313], Loss: 1.1975\n",
      "Batch [240/313], Loss: 1.3296\n",
      "Batch [270/313], Loss: 1.1858\n",
      "Batch [300/313], Loss: 1.1422\n",
      "Epoch [2/20], Loss: 0.9582\n",
      "Validation loss decreased (1.004664 --> 0.958238).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0673\n",
      "Batch [60/313], Loss: 1.1804\n",
      "Batch [90/313], Loss: 1.2722\n",
      "Batch [120/313], Loss: 1.0283\n",
      "Batch [150/313], Loss: 1.0808\n",
      "Batch [180/313], Loss: 1.4206\n",
      "Batch [210/313], Loss: 0.9629\n",
      "Batch [240/313], Loss: 1.2725\n",
      "Batch [270/313], Loss: 1.1661\n",
      "Batch [300/313], Loss: 1.1411\n",
      "Epoch [3/20], Loss: 0.9212\n",
      "Validation loss decreased (0.958238 --> 0.921157).  Saving model ...\n",
      "Batch [30/313], Loss: 1.2576\n",
      "Batch [60/313], Loss: 1.1662\n",
      "Batch [90/313], Loss: 1.0506\n",
      "Batch [120/313], Loss: 1.1506\n",
      "Batch [150/313], Loss: 1.1157\n",
      "Batch [180/313], Loss: 0.9892\n",
      "Batch [210/313], Loss: 0.9556\n",
      "Batch [240/313], Loss: 1.0328\n",
      "Batch [270/313], Loss: 1.1211\n",
      "Batch [300/313], Loss: 1.1457\n",
      "Epoch [4/20], Loss: 0.8812\n",
      "Validation loss decreased (0.921157 --> 0.881150).  Saving model ...\n",
      "Batch [30/313], Loss: 0.9896\n",
      "Batch [60/313], Loss: 1.1122\n",
      "Batch [90/313], Loss: 1.1251\n",
      "Batch [120/313], Loss: 1.1279\n",
      "Batch [150/313], Loss: 0.9697\n",
      "Batch [180/313], Loss: 1.1580\n",
      "Batch [210/313], Loss: 1.1615\n",
      "Batch [240/313], Loss: 0.8850\n",
      "Batch [270/313], Loss: 0.9053\n",
      "Batch [300/313], Loss: 1.0136\n",
      "Epoch [5/20], Loss: 0.8479\n",
      "Validation loss decreased (0.881150 --> 0.847898).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7009\n",
      "Batch [60/313], Loss: 1.0256\n",
      "Batch [90/313], Loss: 0.9789\n",
      "Batch [120/313], Loss: 1.2123\n",
      "Batch [150/313], Loss: 1.0546\n",
      "Batch [180/313], Loss: 1.0497\n",
      "Batch [210/313], Loss: 1.0107\n",
      "Batch [240/313], Loss: 1.1336\n",
      "Batch [270/313], Loss: 0.8401\n",
      "Batch [300/313], Loss: 1.0009\n",
      "Epoch [6/20], Loss: 0.8173\n",
      "Validation loss decreased (0.847898 --> 0.817296).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1510\n",
      "Batch [60/313], Loss: 0.9865\n",
      "Batch [90/313], Loss: 0.7523\n",
      "Batch [120/313], Loss: 0.9482\n",
      "Batch [150/313], Loss: 0.9067\n",
      "Batch [180/313], Loss: 1.0463\n",
      "Batch [210/313], Loss: 0.9970\n",
      "Batch [240/313], Loss: 0.8651\n",
      "Batch [270/313], Loss: 1.1243\n",
      "Batch [300/313], Loss: 1.1179\n",
      "Epoch [7/20], Loss: 0.7820\n",
      "Validation loss decreased (0.817296 --> 0.781980).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0787\n",
      "Batch [60/313], Loss: 1.0177\n",
      "Batch [90/313], Loss: 1.0707\n",
      "Batch [120/313], Loss: 0.8622\n",
      "Batch [150/313], Loss: 0.8030\n",
      "Batch [180/313], Loss: 0.9004\n",
      "Batch [210/313], Loss: 0.8478\n",
      "Batch [240/313], Loss: 1.0655\n",
      "Batch [270/313], Loss: 1.0225\n",
      "Batch [300/313], Loss: 1.0891\n",
      "Epoch [8/20], Loss: 0.7528\n",
      "Validation loss decreased (0.781980 --> 0.752834).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8312\n",
      "Batch [60/313], Loss: 0.8001\n",
      "Batch [90/313], Loss: 0.9243\n",
      "Batch [120/313], Loss: 0.8440\n",
      "Batch [150/313], Loss: 1.0574\n",
      "Batch [180/313], Loss: 0.9511\n",
      "Batch [210/313], Loss: 0.9226\n",
      "Batch [240/313], Loss: 0.9162\n",
      "Batch [270/313], Loss: 0.8791\n",
      "Batch [300/313], Loss: 0.9642\n",
      "Epoch [9/20], Loss: 0.7234\n",
      "Validation loss decreased (0.752834 --> 0.723422).  Saving model ...\n",
      "Batch [30/313], Loss: 0.6505\n",
      "Batch [60/313], Loss: 0.9580\n",
      "Batch [90/313], Loss: 0.9502\n",
      "Batch [120/313], Loss: 0.9638\n",
      "Batch [150/313], Loss: 0.7265\n",
      "Batch [180/313], Loss: 0.8497\n",
      "Batch [210/313], Loss: 0.9552\n",
      "Batch [240/313], Loss: 0.8768\n",
      "Batch [270/313], Loss: 0.8482\n",
      "Batch [300/313], Loss: 0.7018\n",
      "Epoch [10/20], Loss: 0.6909\n",
      "Validation loss decreased (0.723422 --> 0.690911).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8605\n",
      "Batch [60/313], Loss: 0.7857\n",
      "Batch [90/313], Loss: 0.7895\n",
      "Batch [120/313], Loss: 0.8141\n",
      "Batch [150/313], Loss: 0.8586\n",
      "Batch [180/313], Loss: 0.9325\n",
      "Batch [210/313], Loss: 0.8163\n",
      "Batch [240/313], Loss: 0.7888\n",
      "Batch [270/313], Loss: 0.8273\n",
      "Batch [300/313], Loss: 0.6498\n",
      "Epoch [11/20], Loss: 0.6583\n",
      "Validation loss decreased (0.690911 --> 0.658312).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7742\n",
      "Batch [60/313], Loss: 0.8186\n",
      "Batch [90/313], Loss: 0.5759\n",
      "Batch [120/313], Loss: 0.7628\n",
      "Batch [150/313], Loss: 0.8408\n",
      "Batch [180/313], Loss: 0.7107\n",
      "Batch [210/313], Loss: 0.7135\n",
      "Batch [240/313], Loss: 0.8224\n",
      "Batch [270/313], Loss: 0.7832\n",
      "Batch [300/313], Loss: 0.9420\n",
      "Epoch [12/20], Loss: 0.6331\n",
      "Validation loss decreased (0.658312 --> 0.633099).  Saving model ...\n",
      "Batch [30/313], Loss: 0.9364\n",
      "Batch [60/313], Loss: 0.5987\n",
      "Batch [90/313], Loss: 0.9023\n",
      "Batch [120/313], Loss: 0.7444\n",
      "Batch [150/313], Loss: 0.7125\n",
      "Batch [180/313], Loss: 0.6690\n",
      "Batch [210/313], Loss: 0.7981\n",
      "Batch [240/313], Loss: 0.7544\n",
      "Batch [270/313], Loss: 0.9174\n",
      "Batch [300/313], Loss: 0.7715\n",
      "Epoch [13/20], Loss: 0.6084\n",
      "Validation loss decreased (0.633099 --> 0.608395).  Saving model ...\n",
      "Batch [30/313], Loss: 0.6054\n",
      "Batch [60/313], Loss: 0.6594\n",
      "Batch [90/313], Loss: 0.5743\n",
      "Batch [120/313], Loss: 0.6361\n",
      "Batch [150/313], Loss: 0.7653\n",
      "Batch [180/313], Loss: 0.8805\n",
      "Batch [210/313], Loss: 0.7289\n",
      "Batch [240/313], Loss: 0.7696\n",
      "Batch [270/313], Loss: 0.7025\n",
      "Batch [300/313], Loss: 0.7177\n",
      "Epoch [14/20], Loss: 0.5783\n",
      "Validation loss decreased (0.608395 --> 0.578335).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7045\n",
      "Batch [60/313], Loss: 0.5829\n",
      "Batch [90/313], Loss: 0.6516\n",
      "Batch [120/313], Loss: 0.7797\n",
      "Batch [150/313], Loss: 0.7932\n",
      "Batch [180/313], Loss: 0.7629\n",
      "Batch [210/313], Loss: 0.6834\n",
      "Batch [240/313], Loss: 0.8384\n",
      "Batch [270/313], Loss: 0.6041\n",
      "Batch [300/313], Loss: 1.0034\n",
      "Epoch [15/20], Loss: 0.5539\n",
      "Validation loss decreased (0.578335 --> 0.553867).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5279\n",
      "Batch [60/313], Loss: 0.6891\n",
      "Batch [90/313], Loss: 0.7650\n",
      "Batch [120/313], Loss: 0.6821\n",
      "Batch [150/313], Loss: 0.7531\n",
      "Batch [180/313], Loss: 0.5688\n",
      "Batch [210/313], Loss: 0.6373\n",
      "Batch [240/313], Loss: 0.7686\n",
      "Batch [270/313], Loss: 0.8182\n",
      "Batch [300/313], Loss: 0.7285\n",
      "Epoch [16/20], Loss: 0.5187\n",
      "Validation loss decreased (0.553867 --> 0.518661).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5498\n",
      "Batch [60/313], Loss: 0.7152\n",
      "Batch [90/313], Loss: 0.7138\n",
      "Batch [120/313], Loss: 0.5176\n",
      "Batch [150/313], Loss: 0.6312\n",
      "Batch [180/313], Loss: 0.5825\n",
      "Batch [210/313], Loss: 0.5209\n",
      "Batch [240/313], Loss: 0.7967\n",
      "Batch [270/313], Loss: 0.6065\n",
      "Batch [300/313], Loss: 0.6329\n",
      "Epoch [17/20], Loss: 0.4975\n",
      "Validation loss decreased (0.518661 --> 0.497544).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4360\n",
      "Batch [60/313], Loss: 0.7149\n",
      "Batch [90/313], Loss: 0.6074\n",
      "Batch [120/313], Loss: 0.6849\n",
      "Batch [150/313], Loss: 0.5744\n",
      "Batch [180/313], Loss: 0.6698\n",
      "Batch [210/313], Loss: 0.5901\n",
      "Batch [240/313], Loss: 0.7259\n",
      "Batch [270/313], Loss: 0.4993\n",
      "Batch [300/313], Loss: 0.6459\n",
      "Epoch [18/20], Loss: 0.4768\n",
      "Validation loss decreased (0.497544 --> 0.476830).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5518\n",
      "Batch [60/313], Loss: 0.5795\n",
      "Batch [90/313], Loss: 0.6399\n",
      "Batch [120/313], Loss: 0.5635\n",
      "Batch [150/313], Loss: 0.7631\n",
      "Batch [180/313], Loss: 0.5839\n",
      "Batch [210/313], Loss: 0.5396\n",
      "Batch [240/313], Loss: 0.5708\n",
      "Batch [270/313], Loss: 0.6197\n",
      "Batch [300/313], Loss: 0.6823\n",
      "Epoch [19/20], Loss: 0.4530\n",
      "Validation loss decreased (0.476830 --> 0.452987).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4550\n",
      "Batch [60/313], Loss: 0.4258\n",
      "Batch [90/313], Loss: 0.5365\n",
      "Batch [120/313], Loss: 0.6307\n",
      "Batch [150/313], Loss: 0.4947\n",
      "Batch [180/313], Loss: 0.6090\n",
      "Batch [210/313], Loss: 0.5341\n",
      "Batch [240/313], Loss: 0.7072\n",
      "Batch [270/313], Loss: 0.5067\n",
      "Batch [300/313], Loss: 0.4271\n",
      "Epoch [20/20], Loss: 0.4289\n",
      "Validation loss decreased (0.452987 --> 0.428892).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                     | 2/20 [09:14<1:27:46, 292.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]   Loss: 1.5548   Accuracy: 60.67%\n",
      "Batch [30/313], Loss: 0.4392\n",
      "Batch [60/313], Loss: 0.4752\n",
      "Batch [90/313], Loss: 0.3773\n",
      "Batch [120/313], Loss: 0.5768\n",
      "Batch [150/313], Loss: 0.4533\n",
      "Batch [180/313], Loss: 0.5021\n",
      "Batch [210/313], Loss: 0.4569\n",
      "Batch [240/313], Loss: 0.5794\n",
      "Batch [270/313], Loss: 0.4973\n",
      "Batch [300/313], Loss: 0.6400\n",
      "Epoch [1/20], Loss: 0.4130\n",
      "Validation loss decreased (0.428892 --> 0.412984).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4543\n",
      "Batch [60/313], Loss: 0.5295\n",
      "Batch [90/313], Loss: 0.5101\n",
      "Batch [120/313], Loss: 0.4314\n",
      "Batch [150/313], Loss: 0.4476\n",
      "Batch [180/313], Loss: 0.4476\n",
      "Batch [210/313], Loss: 0.5347\n",
      "Batch [240/313], Loss: 0.3987\n",
      "Batch [270/313], Loss: 0.4452\n",
      "Batch [300/313], Loss: 0.6242\n",
      "Epoch [2/20], Loss: 0.3863\n",
      "Validation loss decreased (0.412984 --> 0.386274).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2858\n",
      "Batch [60/313], Loss: 0.4334\n",
      "Batch [90/313], Loss: 0.5345\n",
      "Batch [120/313], Loss: 0.4790\n",
      "Batch [150/313], Loss: 0.4929\n",
      "Batch [180/313], Loss: 0.5488\n",
      "Batch [210/313], Loss: 0.4000\n",
      "Batch [240/313], Loss: 0.5000\n",
      "Batch [270/313], Loss: 0.4221\n",
      "Batch [300/313], Loss: 0.4176\n",
      "Epoch [3/20], Loss: 0.3672\n",
      "Validation loss decreased (0.386274 --> 0.367237).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5005\n",
      "Batch [60/313], Loss: 0.4250\n",
      "Batch [90/313], Loss: 0.4309\n",
      "Batch [120/313], Loss: 0.4134\n",
      "Batch [150/313], Loss: 0.3528\n",
      "Batch [180/313], Loss: 0.4883\n",
      "Batch [210/313], Loss: 0.5259\n",
      "Batch [240/313], Loss: 0.5898\n",
      "Batch [270/313], Loss: 0.3928\n",
      "Batch [300/313], Loss: 0.4977\n",
      "Epoch [4/20], Loss: 0.3486\n",
      "Validation loss decreased (0.367237 --> 0.348553).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3796\n",
      "Batch [60/313], Loss: 0.2845\n",
      "Batch [90/313], Loss: 0.3896\n",
      "Batch [120/313], Loss: 0.4575\n",
      "Batch [150/313], Loss: 0.3818\n",
      "Batch [180/313], Loss: 0.3977\n",
      "Batch [210/313], Loss: 0.4855\n",
      "Batch [240/313], Loss: 0.4088\n",
      "Batch [270/313], Loss: 0.4384\n",
      "Batch [300/313], Loss: 0.4078\n",
      "Epoch [5/20], Loss: 0.3305\n",
      "Validation loss decreased (0.348553 --> 0.330547).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3164\n",
      "Batch [60/313], Loss: 0.3910\n"
     ]
    }
   ],
   "source": [
    "# Per-Epoch Activity 코드\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    # 모델 학습\n",
    "    train_model(net, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "    \n",
    "    # 테스트 평가\n",
    "    test_loss, test_accuracy = test_model(net, test_loader, criterion, epoch)\n",
    "    \n",
    "    # TensorBoard에 테스트 결과 기록\n",
    "    writer.add_scalar(\"Test Loss\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Test Accuracy\", test_accuracy, epoch)\n",
    "\n",
    "    # 현재 epoch 결과 출력\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}]   Loss: {test_loss:.4f}   Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# TensorBoard writer 닫기\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271219f-96f2-4967-939d-a24d6def8eb0",
   "metadata": {},
   "source": [
    "### **Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f94ca2-f1e7-4452-b501-9b36e7025a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Result of ResNet = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5d42f-9728-4e40-94eb-997ad195b5b2",
   "metadata": {},
   "source": [
    "# Test - 나영(Accuracy) 현욱(Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59d485-f2bb-4dc0-85ac-55a5f7ef1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('10000개 테스트 이미지에서 모델 정확도: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b41eb1-d372-4e64-b1d9-d2552ed44d99",
   "metadata": {},
   "source": [
    "**Visualization of average loss(수정 필요)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45250e0a-4741-4228-a62a-28b9733fd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련과정에서 손실을 기록\n",
    "    train_loss = 0\n",
    "    total_samples = 0\n",
    "    net.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        total_samples += inputs.size(0)\n",
    "    \n",
    "    train_losses.append(train_loss / total_samples)\n",
    "\n",
    "    # 평가 과정에서 손실과 정확도를 기록\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_losses.append(test_loss / total)\n",
    "    test_accuracies.append(correct / total)\n",
    "\n",
    "# 손실과 정확도 그래프 그리기\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea3df5-03bd-4f43-8b2b-d251da3ea733",
   "metadata": {},
   "source": [
    "**Top-1 Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fbe81-49f4-431b-b1fd-e8bcb50d0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top1_accuracy(model, device, data_loader, criterion):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            # # 각 샘플에 대한 예측 결과와 실제 레이블 출력\n",
    "            # for i in range(data.size(0)):\n",
    "            #     print(f\"Sample {i + 1}: Predicted = {predicted[i].item()}, Actual = {target[i].item()}\")\n",
    "\n",
    "    top1_accuracy = 100 * correct / total\n",
    "    print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb41004-213b-4b75-8c10-2741a33871d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 후 검증 데이터셋에 대한 Top-1 정확도 계산 및 출력\n",
    "calculate_top1_accuracy(net, device, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0993a9-bc4f-40e1-909c-c63d6c7dd36e",
   "metadata": {},
   "source": [
    "**Top-5 Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec995a-2515-488b-b266-3d566d9490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_print_top5_accuracy(model, device, data_loader, criterion):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            # Top-5 예측 결과 가져오기\n",
    "            _, predicted_top5 = torch.topk(outputs, 5, dim=1)\n",
    "            total += target.size(0)\n",
    "            \n",
    "            # 예측된 Top-5 내에 실제 레이블이 있는지 확인\n",
    "            correct += (predicted_top5 == target.view(-1, 1)).sum().item()\n",
    "\n",
    "    top5_accuracy = 100 * correct / total\n",
    "    print(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761aaae-f57c-44e7-9b55-fc9959abdb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_print_top5_accuracy(net, device, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503fa03-bac6-4758-a623-8cec95a40985",
   "metadata": {},
   "source": [
    "# Data Analysis - 현욱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1321873-e871-4ee1-883e-637fe9aa843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./runs/resnet_18/tensorboard --port=8202 --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce3873-fb7d-447b-9e9e-2c2c68a8320f",
   "metadata": {},
   "source": [
    "### **Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fcbfd-53ee-4489-a204-c366745ff4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_data.classes\n",
    "coarse_classes = [\n",
    "    'aquatic mammals', 'fish', 'flowers', 'food containers', 'fruit and vegetables', 'household electrical devices', \n",
    "    'household furniture', 'insects', 'large carnivores', 'large man-made outdoor things', \n",
    "    'large natural outdoor scenes', 'large omnivores and herbivores', 'medium-sized mammals', \n",
    "    'non-insect invertebrates', 'people', 'reptiles', 'small mammals', 'trees', 'vehicles 1', 'vehicles 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12998ea-5e92-47e9-8f07-5506b467b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(classes), len(coarse_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65824d7-6382-46c5-a654-ce9c579aaee2",
   "metadata": {},
   "source": [
    "##### **Fine_to_coarse_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22925779-77ff-457d-bac1-1daa7f1746ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-100 세부 클래스(fine classes)와 상위 클래스(coarse classes) 매핑\n",
    "fine_to_coarse_mapping = {\n",
    "    # aquatic mammals\n",
    "    'beaver': 'aquatic mammals',\n",
    "    'dolphin': 'aquatic mammals',\n",
    "    'otter': 'aquatic mammals',\n",
    "    'seal': 'aquatic mammals',\n",
    "    'whale': 'aquatic mammals',\n",
    "    \n",
    "    # fish\n",
    "    'aquarium fish': 'fish',\n",
    "    'flatfish': 'fish',\n",
    "    'ray': 'fish',\n",
    "    'shark': 'fish',\n",
    "    'trout': 'fish',\n",
    "    \n",
    "    # flowers\n",
    "    'orchids': 'flowers',\n",
    "    'poppies': 'flowers',\n",
    "    'roses': 'flowers',\n",
    "    'sunflowers': 'flowers',\n",
    "    'tulips': 'flowers',\n",
    "    \n",
    "    # food containers\n",
    "    'bottles': 'food containers',\n",
    "    'bowls': 'food containers',\n",
    "    'cans': 'food containers',\n",
    "    'cups': 'food containers',\n",
    "    'plates': 'food containers',\n",
    "    \n",
    "    # fruit and vegetables\n",
    "    'apples': 'fruit and vegetables',\n",
    "    'mushrooms': 'fruit and vegetables',\n",
    "    'oranges': 'fruit and vegetables',\n",
    "    'pears': 'fruit and vegetables',\n",
    "    'sweet peppers': 'fruit and vegetables',\n",
    "    \n",
    "    # household electrical devices\n",
    "    'clock': 'household electrical devices',\n",
    "    'computer keyboard': 'household electrical devices',\n",
    "    'lamp': 'household electrical devices',\n",
    "    'telephone': 'household electrical devices',\n",
    "    'television': 'household electrical devices',\n",
    "    \n",
    "    # household furniture\n",
    "    'bed': 'household furniture',\n",
    "    'chair': 'household furniture',\n",
    "    'couch': 'household furniture',\n",
    "    'table': 'household furniture',\n",
    "    'wardrobe': 'household furniture',\n",
    "    \n",
    "    # insects\n",
    "    'bee': 'insects',\n",
    "    'beetle': 'insects',\n",
    "    'butterfly': 'insects',\n",
    "    'caterpillar': 'insects',\n",
    "    'cockroach': 'insects',\n",
    "    \n",
    "    # large carnivores\n",
    "    'bear': 'large carnivores',\n",
    "    'leopard': 'large carnivores',\n",
    "    'lion': 'large carnivores',\n",
    "    'tiger': 'large carnivores',\n",
    "    'wolf': 'large carnivores',\n",
    "    \n",
    "    # large man-made outdoor things\n",
    "    'bridge': 'large man-made outdoor things',\n",
    "    'castle': 'large man-made outdoor things',\n",
    "    'house': 'large man-made outdoor things',\n",
    "    'road': 'large man-made outdoor things',\n",
    "    'skyscraper': 'large man-made outdoor things',\n",
    "    \n",
    "    # large natural outdoor scenes\n",
    "    'cloud': 'large natural outdoor scenes',\n",
    "    'forest': 'large natural outdoor scenes',\n",
    "    'mountain': 'large natural outdoor scenes',\n",
    "    'plain': 'large natural outdoor scenes',\n",
    "    'sea': 'large natural outdoor scenes',\n",
    "    \n",
    "    # large omnivores and herbivores\n",
    "    'camel': 'large omnivores and herbivores',\n",
    "    'cattle': 'large omnivores and herbivores',\n",
    "    'chimpanzee': 'large omnivores and herbivores',\n",
    "    'elephant': 'large omnivores and herbivores',\n",
    "    'kangaroo': 'large omnivores and herbivores',\n",
    "    \n",
    "    # medium-sized mammals\n",
    "    'fox': 'medium-sized mammals',\n",
    "    'porcupine': 'medium-sized mammals',\n",
    "    'possum': 'medium-sized mammals',\n",
    "    'raccoon': 'medium-sized mammals',\n",
    "    'skunk': 'medium-sized mammals',\n",
    "    \n",
    "    # non-insect invertebrates\n",
    "    'crab': 'non-insect invertebrates',\n",
    "    'lobster': 'non-insect invertebrates',\n",
    "    'snail': 'non-insect invertebrates',\n",
    "    'spider': 'non-insect invertebrates',\n",
    "    'worm': 'non-insect invertebrates',\n",
    "    \n",
    "    # people\n",
    "    'baby': 'people',\n",
    "    'boy': 'people',\n",
    "    'girl': 'people',\n",
    "    'man': 'people',\n",
    "    'woman': 'people',\n",
    "    \n",
    "    # reptiles\n",
    "    'crocodile': 'reptiles',\n",
    "    'dinosaur': 'reptiles',\n",
    "    'lizard': 'reptiles',\n",
    "    'snake': 'reptiles',\n",
    "    'turtle': 'reptiles',\n",
    "    \n",
    "    # small mammals\n",
    "    'hamster': 'small mammals',\n",
    "    'mouse': 'small mammals',\n",
    "    'rabbit': 'small mammals',\n",
    "    'shrew': 'small mammals',\n",
    "    'squirrel': 'small mammals',\n",
    "    \n",
    "    # trees\n",
    "    'maple': 'trees',\n",
    "    'oak': 'trees',\n",
    "    'palm': 'trees',\n",
    "    'pine': 'trees',\n",
    "    'willow': 'trees',\n",
    "    \n",
    "    # vehicles 1\n",
    "    'bicycle': 'vehicles 1',\n",
    "    'bus': 'vehicles 1',\n",
    "    'motorcycle': 'vehicles 1',\n",
    "    'pickup truck': 'vehicles 1',\n",
    "    'train': 'vehicles 1',\n",
    "    \n",
    "    # vehicles 2\n",
    "    'lawn-mower': 'vehicles 2',\n",
    "    'rocket': 'vehicles 2',\n",
    "    'streetcar': 'vehicles 2',\n",
    "    'tank': 'vehicles 2',\n",
    "    'tractor': 'vehicles 2'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd13fc-9e00-4f14-8ce4-c568bf583a0b",
   "metadata": {},
   "source": [
    "### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08932ed-cd47-4196-ae9c-187bd20f02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for x, y in torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size):\n",
    "    \n",
    "    #print('iter val', i)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    z = net(x)\n",
    "    _, yhat = torch.max(z, 1)\n",
    "    pred = yhat.data.cpu().numpy()\n",
    "    y_pred.extend(pred) # Save Prediction\n",
    "\n",
    "    labels = y.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (128,70))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('Confusion Matrix of ResNet (CIFAR100)')\n",
    "plt.savefig('./runs/resnet_18/Confusion_matrix_ResNet_Cifar100.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdc8f9-0c1e-4787-aaea-0f00e2fa18b3",
   "metadata": {},
   "source": [
    "### **Confusion Matrix - Coarse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773340a7-fea7-41e1-87cf-b57e6bb8a934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be2bacf-9f08-4158-a1f5-388c2b93bd1b",
   "metadata": {},
   "source": [
    "### **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cb235-7bd0-429f-9a25-5bcf162d3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Classification Report of ResNet(CIFAR100)  \\n { classification_report(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ff632-9bd4-4ce6-9a3e-f4908b6c02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Classification Report as txt file \n",
    "with open(\"./runs/resnet_18/cr_ResNet18.txt\", \"w\") as text_file:\n",
    "    print(classification_report(y_true, y_pred, digits=4), file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06191708-b289-4ada-97c9-5d4d42eaf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Classification Report txt file \n",
    "with open(\"./runs/resnet_18/cr_ResNet18.txt\", \"r\") as f:\n",
    "  cr = f.read()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdae401-61f1-47fc-a281-fcc45a3be062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
