{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab70dee5-0563-44bf-aac5-fd2065985481",
   "metadata": {},
   "source": [
    "# **Data - 나영**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457d367-10af-4473-8f3d-77198447a7bb",
   "metadata": {},
   "source": [
    "### **Load Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "562d9cb0-9691-4f07-a788-38b1f17bb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from utility.early_stopping import EarlyStopping\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f8e0bb-e8d3-45cf-a26f-2405ff3fce13",
   "metadata": {},
   "source": [
    "**Seed Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d84c3f64-0389-4b7c-83c8-a32ee52e3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348e605-f472-4e8b-9e59-d7f9971c7c55",
   "metadata": {},
   "source": [
    "**Device Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035d096c-7962-4214-a220-c5b27b3d04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2a04d-7b38-4826-b55c-f31ad07811d9",
   "metadata": {},
   "source": [
    "**Set Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4225472f-8390-4f0e-b3ea-85598022cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936f9c8-6a53-4d17-8b05-2f7bbde99746",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb77a99-0ecc-4dee-8373-8f73d0814215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4), \n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2bee68-5466-4bdc-bbaa-2ae55ca6463e",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3ac53-39cd-458e-802e-6b7da0170f63",
   "metadata": {},
   "source": [
    "**Splitting th training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2cf780b-d6ba-4123-a0c1-be7a7a762575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_val_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_val_transform)\n",
    "test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "257be9c9-628b-4ef4-8f1e-a9466ee8d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
    "# test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f00da17f-0962-4907-8aae-505f5a64cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 train/val로 나누기\n",
    "num_train = len(train_val_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.2 * num_train))  # validation 데이터를 20%로 설정\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b3c41-7fe8-4959-81b8-50354ef33c9c",
   "metadata": {},
   "source": [
    "**Define DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6133b787-b855-4064-b019-88a62b64d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_val_data, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "val_loader = DataLoader(train_val_data, batch_size=batch_size, sampler=val_sampler, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b18f60-5d55-4b53-9506-788bcb425362",
   "metadata": {},
   "source": [
    "# **Model - 하연**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb4694-6995-4316-8009-49c47d4d5fdd",
   "metadata": {},
   "source": [
    "models 폴더에 만들고 import 하는 식으로 해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9548e-68bc-4b50-8f43-75c084ae7f3d",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16c71685-4257-4da5-8f8b-6d8f8945f4d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use: cuda:0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,728\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "            Conv2d-7         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-8         [-1, 64, 224, 224]             128\n",
      "        BasicBlock-9         [-1, 64, 224, 224]               0\n",
      "           Conv2d-10         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-11         [-1, 64, 224, 224]             128\n",
      "             ReLU-12         [-1, 64, 224, 224]               0\n",
      "           Conv2d-13         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-14         [-1, 64, 224, 224]             128\n",
      "       BasicBlock-15         [-1, 64, 224, 224]               0\n",
      "           Conv2d-16        [-1, 128, 112, 112]          73,728\n",
      "      BatchNorm2d-17        [-1, 128, 112, 112]             256\n",
      "             ReLU-18        [-1, 128, 112, 112]               0\n",
      "           Conv2d-19        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-20        [-1, 128, 112, 112]             256\n",
      "           Conv2d-21        [-1, 128, 112, 112]           8,192\n",
      "      BatchNorm2d-22        [-1, 128, 112, 112]             256\n",
      "       BasicBlock-23        [-1, 128, 112, 112]               0\n",
      "           Conv2d-24        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-25        [-1, 128, 112, 112]             256\n",
      "             ReLU-26        [-1, 128, 112, 112]               0\n",
      "           Conv2d-27        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-28        [-1, 128, 112, 112]             256\n",
      "       BasicBlock-29        [-1, 128, 112, 112]               0\n",
      "           Conv2d-30          [-1, 256, 56, 56]         294,912\n",
      "      BatchNorm2d-31          [-1, 256, 56, 56]             512\n",
      "             ReLU-32          [-1, 256, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "           Conv2d-35          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "       BasicBlock-37          [-1, 256, 56, 56]               0\n",
      "           Conv2d-38          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 56, 56]             512\n",
      "             ReLU-40          [-1, 256, 56, 56]               0\n",
      "           Conv2d-41          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-42          [-1, 256, 56, 56]             512\n",
      "       BasicBlock-43          [-1, 256, 56, 56]               0\n",
      "           Conv2d-44          [-1, 512, 28, 28]       1,179,648\n",
      "      BatchNorm2d-45          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-46          [-1, 512, 28, 28]               0\n",
      "           Conv2d-47          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-48          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "       BasicBlock-51          [-1, 512, 28, 28]               0\n",
      "           Conv2d-52          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-53          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-54          [-1, 512, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "       BasicBlock-57          [-1, 512, 28, 28]               0\n",
      "AdaptiveAvgPool2d-58            [-1, 512, 1, 1]               0\n",
      "           Linear-59                  [-1, 100]          51,300\n",
      "================================================================\n",
      "Total params: 11,220,132\n",
      "Trainable params: 11,220,132\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 667.63\n",
      "Params size (MB): 42.80\n",
      "Estimated Total Size (MB): 711.01\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # models 폴더의 경로 추가\n",
    "# sys.path.append('./models')\n",
    "\n",
    "print(\"use:\", device)\n",
    "\n",
    "# 모델 import 하기\n",
    "from models.resnetRS import ResNetRS18\n",
    "from models import resnet\n",
    "\n",
    "# 모델 초기화\n",
    "net = resnet.resnet18()\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "net.to(device)\n",
    "\n",
    "# 모델 구조 출력\n",
    "print(summary(net, (3, 224, 224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae781b4f-9e8b-4ea3-8b1e-9b67e857a088",
   "metadata": {},
   "source": [
    "### **Loss and Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1b668f-0288-43c3-a08a-83a11a0d85d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]}]\n"
     ]
    }
   ],
   "source": [
    "# 손실함수 초기화\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# 옵티마이저의 state_dict 출력\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09003b-468e-4e89-9285-b6ec501c20cf",
   "metadata": {},
   "source": [
    "# **Train - 하연**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a80805-e7a2-4bdc-b854-9d183c306bf5",
   "metadata": {},
   "source": [
    "### **Model Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4337e604-8477-4a57-80fc-a2d96afcb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./runs/resnet_18/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13f6bb1b-efc7-4146-acbb-b2b28de16580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./runs/resnet_18/checkpoints\"\n",
    "# early_stopping = EarlyStopping(save_path)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b20456-0576-49db-b3d1-97ef4cb49d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train_model(model, trainloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            labels = labels.type(torch.LongTensor).to(device)  # CPU에서 long type tensor로 변환\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 역전파 및 최적화\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # 30번째 배치마다 상태 출력\n",
    "            if (batch_idx + 1) % 30 == 0:\n",
    "                print(f\"Batch [{batch_idx+1}/{len(trainloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Epoch당 평균 손실 계산 및 출력\n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping 체크\n",
    "        early_stopping(epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825de7e7-59bc-49aa-bd7a-c27a61c10fcb",
   "metadata": {},
   "source": [
    "**Model Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15180770-96df-487a-8c70-5743cc4dd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 및 테스트 함수 (superclass 예측 포함)\n",
    "def test_model(model, testloader, criterion, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "            \n",
    "            # 예측 결과 저장 및 정확도 계산\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "\n",
    "            # TensorBoard에 테스트 손실 및 정확도 기록\n",
    "            writer.add_scalar(\"Test Loss\", test_loss / len(testloader.dataset), epoch)\n",
    "            writer.add_scalar(\"Test Accuracy\", correct / len(testloader.dataset), epoch)\n",
    "\n",
    "    # 평균 손실 및 정확도 계산\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0669a96-2d88-4b8b-bc33-82701eabf923",
   "metadata": {},
   "source": [
    "### **Per-Epoch Activity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c330ce51-1f1d-4ad8-a127-a82f34c3899e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [30/313], Loss: 4.5407\n",
      "Batch [60/313], Loss: 4.4200\n",
      "Batch [90/313], Loss: 4.2457\n",
      "Batch [120/313], Loss: 4.2392\n",
      "Batch [150/313], Loss: 3.9844\n",
      "Batch [180/313], Loss: 4.0849\n",
      "Batch [210/313], Loss: 3.9340\n",
      "Batch [240/313], Loss: 3.8321\n",
      "Batch [270/313], Loss: 3.8538\n",
      "Batch [300/313], Loss: 3.8021\n",
      "Epoch [1/20], Loss: 3.2889\n",
      "Validation loss decreased (inf --> 3.288852).  Saving model ...\n",
      "Batch [30/313], Loss: 3.9197\n",
      "Batch [60/313], Loss: 3.7285\n",
      "Batch [90/313], Loss: 3.4634\n",
      "Batch [120/313], Loss: 3.6148\n",
      "Batch [150/313], Loss: 3.5735\n",
      "Batch [180/313], Loss: 3.5115\n",
      "Batch [210/313], Loss: 3.5495\n",
      "Batch [240/313], Loss: 3.5395\n",
      "Batch [270/313], Loss: 3.4256\n",
      "Batch [300/313], Loss: 3.3767\n",
      "Epoch [2/20], Loss: 2.8679\n",
      "Validation loss decreased (3.288852 --> 2.867903).  Saving model ...\n",
      "Batch [30/313], Loss: 3.6272\n",
      "Batch [60/313], Loss: 3.4037\n",
      "Batch [90/313], Loss: 3.3992\n",
      "Batch [120/313], Loss: 3.1510\n",
      "Batch [150/313], Loss: 3.3535\n",
      "Batch [180/313], Loss: 3.2254\n",
      "Batch [210/313], Loss: 3.2571\n",
      "Batch [240/313], Loss: 3.1672\n",
      "Batch [270/313], Loss: 3.0323\n",
      "Batch [300/313], Loss: 3.2314\n",
      "Epoch [3/20], Loss: 2.6364\n",
      "Validation loss decreased (2.867903 --> 2.636447).  Saving model ...\n",
      "Batch [30/313], Loss: 3.0638\n",
      "Batch [60/313], Loss: 3.3308\n",
      "Batch [90/313], Loss: 2.7921\n",
      "Batch [120/313], Loss: 3.2498\n",
      "Batch [150/313], Loss: 3.1481\n",
      "Batch [180/313], Loss: 3.1889\n",
      "Batch [210/313], Loss: 3.0543\n",
      "Batch [240/313], Loss: 3.0965\n",
      "Batch [270/313], Loss: 2.8606\n",
      "Batch [300/313], Loss: 2.9331\n",
      "Epoch [4/20], Loss: 2.4342\n",
      "Validation loss decreased (2.636447 --> 2.434181).  Saving model ...\n",
      "Batch [30/313], Loss: 2.7520\n",
      "Batch [60/313], Loss: 2.8837\n",
      "Batch [90/313], Loss: 2.8434\n",
      "Batch [120/313], Loss: 2.9594\n",
      "Batch [150/313], Loss: 2.8707\n",
      "Batch [180/313], Loss: 2.9460\n",
      "Batch [210/313], Loss: 2.7539\n",
      "Batch [240/313], Loss: 2.7891\n",
      "Batch [270/313], Loss: 2.7339\n",
      "Batch [300/313], Loss: 2.6577\n",
      "Epoch [5/20], Loss: 2.2623\n",
      "Validation loss decreased (2.434181 --> 2.262292).  Saving model ...\n",
      "Batch [30/313], Loss: 2.7827\n",
      "Batch [60/313], Loss: 2.6262\n",
      "Batch [90/313], Loss: 2.5915\n",
      "Batch [120/313], Loss: 2.5823\n",
      "Batch [150/313], Loss: 2.4173\n",
      "Batch [180/313], Loss: 2.5805\n",
      "Batch [210/313], Loss: 2.4254\n",
      "Batch [240/313], Loss: 2.6243\n",
      "Batch [270/313], Loss: 2.8479\n",
      "Batch [300/313], Loss: 2.8098\n",
      "Epoch [6/20], Loss: 2.1010\n",
      "Validation loss decreased (2.262292 --> 2.100993).  Saving model ...\n",
      "Batch [30/313], Loss: 2.2533\n",
      "Batch [60/313], Loss: 2.5316\n",
      "Batch [90/313], Loss: 2.7511\n",
      "Batch [120/313], Loss: 2.4165\n",
      "Batch [150/313], Loss: 2.5930\n",
      "Batch [180/313], Loss: 2.3525\n",
      "Batch [210/313], Loss: 2.4225\n",
      "Batch [240/313], Loss: 2.5267\n",
      "Batch [270/313], Loss: 2.2637\n",
      "Batch [300/313], Loss: 2.4399\n",
      "Epoch [7/20], Loss: 1.9633\n",
      "Validation loss decreased (2.100993 --> 1.963350).  Saving model ...\n",
      "Batch [30/313], Loss: 2.3004\n",
      "Batch [60/313], Loss: 2.4973\n",
      "Batch [90/313], Loss: 2.6655\n",
      "Batch [120/313], Loss: 2.4930\n",
      "Batch [150/313], Loss: 2.4070\n",
      "Batch [180/313], Loss: 2.0866\n",
      "Batch [210/313], Loss: 2.7574\n",
      "Batch [240/313], Loss: 2.4033\n",
      "Batch [270/313], Loss: 2.2812\n",
      "Batch [300/313], Loss: 2.2996\n",
      "Epoch [8/20], Loss: 1.8458\n",
      "Validation loss decreased (1.963350 --> 1.845813).  Saving model ...\n",
      "Batch [30/313], Loss: 2.2257\n",
      "Batch [60/313], Loss: 2.2202\n",
      "Batch [90/313], Loss: 2.1715\n",
      "Batch [120/313], Loss: 2.2150\n",
      "Batch [150/313], Loss: 2.2490\n",
      "Batch [180/313], Loss: 2.2165\n",
      "Batch [210/313], Loss: 2.0758\n",
      "Batch [240/313], Loss: 2.1238\n",
      "Batch [270/313], Loss: 1.9828\n",
      "Batch [300/313], Loss: 1.8075\n",
      "Epoch [9/20], Loss: 1.7404\n",
      "Validation loss decreased (1.845813 --> 1.740418).  Saving model ...\n",
      "Batch [30/313], Loss: 2.2558\n",
      "Batch [60/313], Loss: 2.3284\n",
      "Batch [90/313], Loss: 2.1346\n",
      "Batch [120/313], Loss: 1.9259\n",
      "Batch [150/313], Loss: 1.9812\n",
      "Batch [180/313], Loss: 2.0712\n",
      "Batch [210/313], Loss: 2.1811\n",
      "Batch [240/313], Loss: 2.0177\n",
      "Batch [270/313], Loss: 2.1042\n",
      "Batch [300/313], Loss: 2.1404\n",
      "Epoch [10/20], Loss: 1.6498\n",
      "Validation loss decreased (1.740418 --> 1.649824).  Saving model ...\n",
      "Batch [30/313], Loss: 1.9833\n",
      "Batch [60/313], Loss: 1.9530\n",
      "Batch [90/313], Loss: 1.9928\n",
      "Batch [120/313], Loss: 1.8213\n",
      "Batch [150/313], Loss: 2.1292\n",
      "Batch [180/313], Loss: 1.9535\n",
      "Batch [210/313], Loss: 2.0678\n",
      "Batch [240/313], Loss: 1.9058\n",
      "Batch [270/313], Loss: 1.8126\n",
      "Batch [300/313], Loss: 1.7505\n",
      "Epoch [11/20], Loss: 1.5685\n",
      "Validation loss decreased (1.649824 --> 1.568471).  Saving model ...\n",
      "Batch [30/313], Loss: 1.8245\n",
      "Batch [60/313], Loss: 1.7648\n",
      "Batch [90/313], Loss: 1.7665\n",
      "Batch [120/313], Loss: 2.1566\n",
      "Batch [150/313], Loss: 1.4684\n",
      "Batch [180/313], Loss: 2.0406\n",
      "Batch [210/313], Loss: 2.0297\n",
      "Batch [240/313], Loss: 1.7172\n",
      "Batch [270/313], Loss: 1.7671\n",
      "Batch [300/313], Loss: 1.7740\n",
      "Epoch [12/20], Loss: 1.4875\n",
      "Validation loss decreased (1.568471 --> 1.487497).  Saving model ...\n",
      "Batch [30/313], Loss: 1.8441\n",
      "Batch [60/313], Loss: 1.9682\n",
      "Batch [90/313], Loss: 1.7002\n",
      "Batch [120/313], Loss: 1.6370\n",
      "Batch [150/313], Loss: 1.7212\n",
      "Batch [180/313], Loss: 2.0101\n",
      "Batch [210/313], Loss: 1.6377\n",
      "Batch [240/313], Loss: 1.7560\n",
      "Batch [270/313], Loss: 1.6477\n",
      "Batch [300/313], Loss: 1.6998\n",
      "Epoch [13/20], Loss: 1.4171\n",
      "Validation loss decreased (1.487497 --> 1.417089).  Saving model ...\n",
      "Batch [30/313], Loss: 1.7284\n",
      "Batch [60/313], Loss: 1.5865\n",
      "Batch [90/313], Loss: 1.5919\n",
      "Batch [120/313], Loss: 1.6474\n",
      "Batch [150/313], Loss: 1.7111\n",
      "Batch [180/313], Loss: 1.5271\n",
      "Batch [210/313], Loss: 1.9295\n",
      "Batch [240/313], Loss: 1.6688\n",
      "Batch [270/313], Loss: 1.6762\n",
      "Batch [300/313], Loss: 1.4415\n",
      "Epoch [14/20], Loss: 1.3533\n",
      "Validation loss decreased (1.417089 --> 1.353258).  Saving model ...\n",
      "Batch [30/313], Loss: 1.5144\n",
      "Batch [60/313], Loss: 1.6880\n",
      "Batch [90/313], Loss: 1.5479\n",
      "Batch [120/313], Loss: 1.4438\n",
      "Batch [150/313], Loss: 1.5484\n",
      "Batch [180/313], Loss: 1.5316\n",
      "Batch [210/313], Loss: 1.4598\n",
      "Batch [240/313], Loss: 1.5866\n",
      "Batch [270/313], Loss: 1.5443\n",
      "Batch [300/313], Loss: 1.8116\n",
      "Epoch [15/20], Loss: 1.2933\n",
      "Validation loss decreased (1.353258 --> 1.293322).  Saving model ...\n",
      "Batch [30/313], Loss: 1.4820\n",
      "Batch [60/313], Loss: 1.4737\n",
      "Batch [90/313], Loss: 1.6725\n",
      "Batch [120/313], Loss: 1.4938\n",
      "Batch [150/313], Loss: 1.3764\n",
      "Batch [180/313], Loss: 1.4565\n",
      "Batch [210/313], Loss: 1.5290\n",
      "Batch [240/313], Loss: 1.3880\n",
      "Batch [270/313], Loss: 1.6154\n",
      "Batch [300/313], Loss: 1.3534\n",
      "Epoch [16/20], Loss: 1.2380\n",
      "Validation loss decreased (1.293322 --> 1.237987).  Saving model ...\n",
      "Batch [30/313], Loss: 1.5244\n",
      "Batch [60/313], Loss: 1.3542\n",
      "Batch [90/313], Loss: 1.3156\n",
      "Batch [120/313], Loss: 1.6712\n",
      "Batch [150/313], Loss: 1.6935\n",
      "Batch [180/313], Loss: 1.5534\n",
      "Batch [210/313], Loss: 1.1978\n",
      "Batch [240/313], Loss: 1.3574\n",
      "Batch [270/313], Loss: 1.4143\n",
      "Batch [300/313], Loss: 1.6528\n",
      "Epoch [17/20], Loss: 1.1823\n",
      "Validation loss decreased (1.237987 --> 1.182264).  Saving model ...\n",
      "Batch [30/313], Loss: 1.2890\n",
      "Batch [60/313], Loss: 1.6497\n",
      "Batch [90/313], Loss: 1.4319\n",
      "Batch [120/313], Loss: 1.5365\n",
      "Batch [150/313], Loss: 1.2312\n",
      "Batch [180/313], Loss: 1.5585\n",
      "Batch [210/313], Loss: 1.5542\n",
      "Batch [240/313], Loss: 1.4325\n",
      "Batch [270/313], Loss: 1.2420\n",
      "Batch [300/313], Loss: 1.1262\n",
      "Epoch [18/20], Loss: 1.1306\n",
      "Validation loss decreased (1.182264 --> 1.130589).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1922\n",
      "Batch [60/313], Loss: 1.4085\n",
      "Batch [90/313], Loss: 1.3287\n",
      "Batch [120/313], Loss: 1.2687\n",
      "Batch [150/313], Loss: 1.5279\n",
      "Batch [180/313], Loss: 1.3621\n",
      "Batch [210/313], Loss: 1.3241\n",
      "Batch [240/313], Loss: 1.3887\n",
      "Batch [270/313], Loss: 1.4542\n",
      "Batch [300/313], Loss: 1.3346\n",
      "Epoch [19/20], Loss: 1.0893\n",
      "Validation loss decreased (1.130589 --> 1.089309).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1779\n",
      "Batch [60/313], Loss: 1.3068\n",
      "Batch [90/313], Loss: 1.1172\n",
      "Batch [120/313], Loss: 1.3744\n",
      "Batch [150/313], Loss: 1.4295\n",
      "Batch [180/313], Loss: 1.1953\n",
      "Batch [210/313], Loss: 1.2496\n",
      "Batch [240/313], Loss: 1.3429\n",
      "Batch [270/313], Loss: 1.3918\n",
      "Batch [300/313], Loss: 1.3838\n",
      "Epoch [20/20], Loss: 1.0414\n",
      "Validation loss decreased (1.089309 --> 1.041417).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 1/20 [03:11<1:00:40, 191.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]   Loss: 1.6968   Accuracy: 54.29%\n",
      "Batch [30/313], Loss: 1.2417\n",
      "Batch [60/313], Loss: 1.0816\n",
      "Batch [90/313], Loss: 1.0654\n",
      "Batch [120/313], Loss: 1.3992\n",
      "Batch [150/313], Loss: 1.0646\n",
      "Batch [180/313], Loss: 1.3713\n",
      "Batch [210/313], Loss: 1.1942\n",
      "Batch [240/313], Loss: 1.3772\n",
      "Batch [270/313], Loss: 1.1415\n",
      "Batch [300/313], Loss: 1.1031\n",
      "Epoch [1/20], Loss: 1.0047\n",
      "Validation loss decreased (1.041417 --> 1.004664).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1067\n",
      "Batch [60/313], Loss: 1.2287\n",
      "Batch [90/313], Loss: 1.3281\n",
      "Batch [120/313], Loss: 1.0633\n",
      "Batch [150/313], Loss: 1.2228\n",
      "Batch [180/313], Loss: 1.1257\n",
      "Batch [210/313], Loss: 1.1975\n",
      "Batch [240/313], Loss: 1.3296\n",
      "Batch [270/313], Loss: 1.1858\n",
      "Batch [300/313], Loss: 1.1422\n",
      "Epoch [2/20], Loss: 0.9582\n",
      "Validation loss decreased (1.004664 --> 0.958238).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0673\n",
      "Batch [60/313], Loss: 1.1804\n",
      "Batch [90/313], Loss: 1.2722\n",
      "Batch [120/313], Loss: 1.0283\n",
      "Batch [150/313], Loss: 1.0808\n",
      "Batch [180/313], Loss: 1.4206\n",
      "Batch [210/313], Loss: 0.9629\n",
      "Batch [240/313], Loss: 1.2725\n",
      "Batch [270/313], Loss: 1.1661\n",
      "Batch [300/313], Loss: 1.1411\n",
      "Epoch [3/20], Loss: 0.9212\n",
      "Validation loss decreased (0.958238 --> 0.921157).  Saving model ...\n",
      "Batch [30/313], Loss: 1.2576\n",
      "Batch [60/313], Loss: 1.1662\n",
      "Batch [90/313], Loss: 1.0506\n",
      "Batch [120/313], Loss: 1.1506\n",
      "Batch [150/313], Loss: 1.1157\n",
      "Batch [180/313], Loss: 0.9892\n",
      "Batch [210/313], Loss: 0.9556\n",
      "Batch [240/313], Loss: 1.0328\n",
      "Batch [270/313], Loss: 1.1211\n",
      "Batch [300/313], Loss: 1.1457\n",
      "Epoch [4/20], Loss: 0.8812\n",
      "Validation loss decreased (0.921157 --> 0.881150).  Saving model ...\n",
      "Batch [30/313], Loss: 0.9896\n",
      "Batch [60/313], Loss: 1.1122\n",
      "Batch [90/313], Loss: 1.1251\n",
      "Batch [120/313], Loss: 1.1279\n",
      "Batch [150/313], Loss: 0.9697\n",
      "Batch [180/313], Loss: 1.1580\n",
      "Batch [210/313], Loss: 1.1615\n",
      "Batch [240/313], Loss: 0.8850\n",
      "Batch [270/313], Loss: 0.9053\n",
      "Batch [300/313], Loss: 1.0136\n",
      "Epoch [5/20], Loss: 0.8479\n",
      "Validation loss decreased (0.881150 --> 0.847898).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7009\n",
      "Batch [60/313], Loss: 1.0256\n",
      "Batch [90/313], Loss: 0.9789\n",
      "Batch [120/313], Loss: 1.2123\n",
      "Batch [150/313], Loss: 1.0546\n",
      "Batch [180/313], Loss: 1.0497\n",
      "Batch [210/313], Loss: 1.0107\n",
      "Batch [240/313], Loss: 1.1336\n",
      "Batch [270/313], Loss: 0.8401\n",
      "Batch [300/313], Loss: 1.0009\n",
      "Epoch [6/20], Loss: 0.8173\n",
      "Validation loss decreased (0.847898 --> 0.817296).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1510\n",
      "Batch [60/313], Loss: 0.9865\n",
      "Batch [90/313], Loss: 0.7523\n",
      "Batch [120/313], Loss: 0.9482\n",
      "Batch [150/313], Loss: 0.9067\n",
      "Batch [180/313], Loss: 1.0463\n",
      "Batch [210/313], Loss: 0.9970\n",
      "Batch [240/313], Loss: 0.8651\n",
      "Batch [270/313], Loss: 1.1243\n",
      "Batch [300/313], Loss: 1.1179\n",
      "Epoch [7/20], Loss: 0.7820\n",
      "Validation loss decreased (0.817296 --> 0.781980).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0787\n",
      "Batch [60/313], Loss: 1.0177\n",
      "Batch [90/313], Loss: 1.0707\n",
      "Batch [120/313], Loss: 0.8622\n",
      "Batch [150/313], Loss: 0.8030\n",
      "Batch [180/313], Loss: 0.9004\n",
      "Batch [210/313], Loss: 0.8478\n",
      "Batch [240/313], Loss: 1.0655\n",
      "Batch [270/313], Loss: 1.0225\n",
      "Batch [300/313], Loss: 1.0891\n",
      "Epoch [8/20], Loss: 0.7528\n",
      "Validation loss decreased (0.781980 --> 0.752834).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8312\n",
      "Batch [60/313], Loss: 0.8001\n",
      "Batch [90/313], Loss: 0.9243\n",
      "Batch [120/313], Loss: 0.8440\n",
      "Batch [150/313], Loss: 1.0574\n",
      "Batch [180/313], Loss: 0.9511\n",
      "Batch [210/313], Loss: 0.9226\n",
      "Batch [240/313], Loss: 0.9162\n",
      "Batch [270/313], Loss: 0.8791\n",
      "Batch [300/313], Loss: 0.9642\n",
      "Epoch [9/20], Loss: 0.7234\n",
      "Validation loss decreased (0.752834 --> 0.723422).  Saving model ...\n",
      "Batch [30/313], Loss: 0.6505\n",
      "Batch [60/313], Loss: 0.9580\n",
      "Batch [90/313], Loss: 0.9502\n",
      "Batch [120/313], Loss: 0.9638\n",
      "Batch [150/313], Loss: 0.7265\n",
      "Batch [180/313], Loss: 0.8497\n",
      "Batch [210/313], Loss: 0.9552\n",
      "Batch [240/313], Loss: 0.8768\n",
      "Batch [270/313], Loss: 0.8482\n",
      "Batch [300/313], Loss: 0.7018\n",
      "Epoch [10/20], Loss: 0.6909\n",
      "Validation loss decreased (0.723422 --> 0.690911).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8605\n",
      "Batch [60/313], Loss: 0.7857\n",
      "Batch [90/313], Loss: 0.7895\n",
      "Batch [120/313], Loss: 0.8141\n",
      "Batch [150/313], Loss: 0.8586\n",
      "Batch [180/313], Loss: 0.9325\n",
      "Batch [210/313], Loss: 0.8163\n",
      "Batch [240/313], Loss: 0.7888\n",
      "Batch [270/313], Loss: 0.8273\n",
      "Batch [300/313], Loss: 0.6498\n",
      "Epoch [11/20], Loss: 0.6583\n",
      "Validation loss decreased (0.690911 --> 0.658312).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7742\n",
      "Batch [60/313], Loss: 0.8186\n",
      "Batch [90/313], Loss: 0.5759\n",
      "Batch [120/313], Loss: 0.7628\n",
      "Batch [150/313], Loss: 0.8408\n",
      "Batch [180/313], Loss: 0.7107\n",
      "Batch [210/313], Loss: 0.7135\n",
      "Batch [240/313], Loss: 0.8224\n",
      "Batch [270/313], Loss: 0.7832\n",
      "Batch [300/313], Loss: 0.9420\n",
      "Epoch [12/20], Loss: 0.6331\n",
      "Validation loss decreased (0.658312 --> 0.633099).  Saving model ...\n",
      "Batch [30/313], Loss: 0.9364\n",
      "Batch [60/313], Loss: 0.5987\n",
      "Batch [90/313], Loss: 0.9023\n",
      "Batch [120/313], Loss: 0.7444\n",
      "Batch [150/313], Loss: 0.7125\n",
      "Batch [180/313], Loss: 0.6690\n",
      "Batch [210/313], Loss: 0.7981\n",
      "Batch [240/313], Loss: 0.7544\n",
      "Batch [270/313], Loss: 0.9174\n",
      "Batch [300/313], Loss: 0.7715\n",
      "Epoch [13/20], Loss: 0.6084\n",
      "Validation loss decreased (0.633099 --> 0.608395).  Saving model ...\n",
      "Batch [30/313], Loss: 0.6054\n",
      "Batch [60/313], Loss: 0.6594\n",
      "Batch [90/313], Loss: 0.5743\n",
      "Batch [120/313], Loss: 0.6361\n",
      "Batch [150/313], Loss: 0.7653\n",
      "Batch [180/313], Loss: 0.8805\n",
      "Batch [210/313], Loss: 0.7289\n",
      "Batch [240/313], Loss: 0.7696\n",
      "Batch [270/313], Loss: 0.7025\n",
      "Batch [300/313], Loss: 0.7177\n",
      "Epoch [14/20], Loss: 0.5783\n",
      "Validation loss decreased (0.608395 --> 0.578335).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7045\n",
      "Batch [60/313], Loss: 0.5829\n",
      "Batch [90/313], Loss: 0.6516\n",
      "Batch [120/313], Loss: 0.7797\n",
      "Batch [150/313], Loss: 0.7932\n",
      "Batch [180/313], Loss: 0.7629\n",
      "Batch [210/313], Loss: 0.6834\n",
      "Batch [240/313], Loss: 0.8384\n",
      "Batch [270/313], Loss: 0.6041\n",
      "Batch [300/313], Loss: 1.0034\n",
      "Epoch [15/20], Loss: 0.5539\n",
      "Validation loss decreased (0.578335 --> 0.553867).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5279\n",
      "Batch [60/313], Loss: 0.6891\n",
      "Batch [90/313], Loss: 0.7650\n",
      "Batch [120/313], Loss: 0.6821\n",
      "Batch [150/313], Loss: 0.7531\n",
      "Batch [180/313], Loss: 0.5688\n",
      "Batch [210/313], Loss: 0.6373\n",
      "Batch [240/313], Loss: 0.7686\n",
      "Batch [270/313], Loss: 0.8182\n",
      "Batch [300/313], Loss: 0.7285\n",
      "Epoch [16/20], Loss: 0.5187\n",
      "Validation loss decreased (0.553867 --> 0.518661).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5498\n",
      "Batch [60/313], Loss: 0.7152\n",
      "Batch [90/313], Loss: 0.7138\n",
      "Batch [120/313], Loss: 0.5176\n",
      "Batch [150/313], Loss: 0.6312\n",
      "Batch [180/313], Loss: 0.5825\n",
      "Batch [210/313], Loss: 0.5209\n",
      "Batch [240/313], Loss: 0.7967\n",
      "Batch [270/313], Loss: 0.6065\n",
      "Batch [300/313], Loss: 0.6329\n",
      "Epoch [17/20], Loss: 0.4975\n",
      "Validation loss decreased (0.518661 --> 0.497544).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4360\n",
      "Batch [60/313], Loss: 0.7149\n",
      "Batch [90/313], Loss: 0.6074\n",
      "Batch [120/313], Loss: 0.6849\n",
      "Batch [150/313], Loss: 0.5744\n",
      "Batch [180/313], Loss: 0.6698\n",
      "Batch [210/313], Loss: 0.5901\n",
      "Batch [240/313], Loss: 0.7259\n",
      "Batch [270/313], Loss: 0.4993\n",
      "Batch [300/313], Loss: 0.6459\n",
      "Epoch [18/20], Loss: 0.4768\n",
      "Validation loss decreased (0.497544 --> 0.476830).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5518\n",
      "Batch [60/313], Loss: 0.5795\n",
      "Batch [90/313], Loss: 0.6399\n",
      "Batch [120/313], Loss: 0.5635\n",
      "Batch [150/313], Loss: 0.7631\n",
      "Batch [180/313], Loss: 0.5839\n",
      "Batch [210/313], Loss: 0.5396\n",
      "Batch [240/313], Loss: 0.5708\n",
      "Batch [270/313], Loss: 0.6197\n",
      "Batch [300/313], Loss: 0.6823\n",
      "Epoch [19/20], Loss: 0.4530\n",
      "Validation loss decreased (0.476830 --> 0.452987).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4550\n",
      "Batch [60/313], Loss: 0.4258\n",
      "Batch [90/313], Loss: 0.5365\n",
      "Batch [120/313], Loss: 0.6307\n",
      "Batch [150/313], Loss: 0.4947\n",
      "Batch [180/313], Loss: 0.6090\n",
      "Batch [210/313], Loss: 0.5341\n",
      "Batch [240/313], Loss: 0.7072\n",
      "Batch [270/313], Loss: 0.5067\n",
      "Batch [300/313], Loss: 0.4271\n",
      "Epoch [20/20], Loss: 0.4289\n",
      "Validation loss decreased (0.452987 --> 0.428892).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                     | 2/20 [09:14<1:27:46, 292.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]   Loss: 1.5548   Accuracy: 60.67%\n",
      "Batch [30/313], Loss: 0.4392\n",
      "Batch [60/313], Loss: 0.4752\n",
      "Batch [90/313], Loss: 0.3773\n",
      "Batch [120/313], Loss: 0.5768\n",
      "Batch [150/313], Loss: 0.4533\n",
      "Batch [180/313], Loss: 0.5021\n",
      "Batch [210/313], Loss: 0.4569\n",
      "Batch [240/313], Loss: 0.5794\n",
      "Batch [270/313], Loss: 0.4973\n",
      "Batch [300/313], Loss: 0.6400\n",
      "Epoch [1/20], Loss: 0.4130\n",
      "Validation loss decreased (0.428892 --> 0.412984).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4543\n",
      "Batch [60/313], Loss: 0.5295\n",
      "Batch [90/313], Loss: 0.5101\n",
      "Batch [120/313], Loss: 0.4314\n",
      "Batch [150/313], Loss: 0.4476\n",
      "Batch [180/313], Loss: 0.4476\n",
      "Batch [210/313], Loss: 0.5347\n",
      "Batch [240/313], Loss: 0.3987\n",
      "Batch [270/313], Loss: 0.4452\n",
      "Batch [300/313], Loss: 0.6242\n",
      "Epoch [2/20], Loss: 0.3863\n",
      "Validation loss decreased (0.412984 --> 0.386274).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2858\n",
      "Batch [60/313], Loss: 0.4334\n",
      "Batch [90/313], Loss: 0.5345\n",
      "Batch [120/313], Loss: 0.4790\n",
      "Batch [150/313], Loss: 0.4929\n",
      "Batch [180/313], Loss: 0.5488\n",
      "Batch [210/313], Loss: 0.4000\n",
      "Batch [240/313], Loss: 0.5000\n",
      "Batch [270/313], Loss: 0.4221\n",
      "Batch [300/313], Loss: 0.4176\n",
      "Epoch [3/20], Loss: 0.3672\n",
      "Validation loss decreased (0.386274 --> 0.367237).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5005\n",
      "Batch [60/313], Loss: 0.4250\n",
      "Batch [90/313], Loss: 0.4309\n",
      "Batch [120/313], Loss: 0.4134\n",
      "Batch [150/313], Loss: 0.3528\n",
      "Batch [180/313], Loss: 0.4883\n",
      "Batch [210/313], Loss: 0.5259\n",
      "Batch [240/313], Loss: 0.5898\n",
      "Batch [270/313], Loss: 0.3928\n",
      "Batch [300/313], Loss: 0.4977\n",
      "Epoch [4/20], Loss: 0.3486\n",
      "Validation loss decreased (0.367237 --> 0.348553).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3796\n",
      "Batch [60/313], Loss: 0.2845\n",
      "Batch [90/313], Loss: 0.3896\n",
      "Batch [120/313], Loss: 0.4575\n",
      "Batch [150/313], Loss: 0.3818\n",
      "Batch [180/313], Loss: 0.3977\n",
      "Batch [210/313], Loss: 0.4855\n",
      "Batch [240/313], Loss: 0.4088\n",
      "Batch [270/313], Loss: 0.4384\n",
      "Batch [300/313], Loss: 0.4078\n",
      "Epoch [5/20], Loss: 0.3305\n",
      "Validation loss decreased (0.348553 --> 0.330547).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3164\n",
      "Batch [60/313], Loss: 0.3910\n",
      "Batch [90/313], Loss: 0.3524\n",
      "Batch [120/313], Loss: 0.3148\n",
      "Batch [150/313], Loss: 0.3099\n",
      "Batch [180/313], Loss: 0.3962\n",
      "Batch [210/313], Loss: 0.4117\n",
      "Batch [240/313], Loss: 0.4468\n",
      "Batch [270/313], Loss: 0.3321\n",
      "Batch [300/313], Loss: 0.4828\n",
      "Epoch [6/20], Loss: 0.3099\n",
      "Validation loss decreased (0.330547 --> 0.309892).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3046\n",
      "Batch [60/313], Loss: 0.3562\n",
      "Batch [90/313], Loss: 0.2829\n",
      "Batch [120/313], Loss: 0.4203\n",
      "Batch [150/313], Loss: 0.2623\n",
      "Batch [180/313], Loss: 0.3323\n",
      "Batch [210/313], Loss: 0.3775\n",
      "Batch [240/313], Loss: 0.3995\n",
      "Batch [270/313], Loss: 0.3439\n",
      "Batch [300/313], Loss: 0.5479\n",
      "Epoch [7/20], Loss: 0.2977\n",
      "Validation loss decreased (0.309892 --> 0.297669).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3633\n",
      "Batch [60/313], Loss: 0.4762\n",
      "Batch [90/313], Loss: 0.3001\n",
      "Batch [120/313], Loss: 0.3404\n",
      "Batch [150/313], Loss: 0.3254\n",
      "Batch [180/313], Loss: 0.3605\n",
      "Batch [210/313], Loss: 0.3461\n",
      "Batch [240/313], Loss: 0.2780\n",
      "Batch [270/313], Loss: 0.3771\n",
      "Batch [300/313], Loss: 0.3296\n",
      "Epoch [8/20], Loss: 0.2812\n",
      "Validation loss decreased (0.297669 --> 0.281152).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2601\n",
      "Batch [60/313], Loss: 0.3214\n",
      "Batch [90/313], Loss: 0.2212\n",
      "Batch [120/313], Loss: 0.3676\n",
      "Batch [150/313], Loss: 0.3992\n",
      "Batch [180/313], Loss: 0.3596\n",
      "Batch [210/313], Loss: 0.3231\n",
      "Batch [240/313], Loss: 0.3660\n",
      "Batch [270/313], Loss: 0.3672\n",
      "Batch [300/313], Loss: 0.3762\n",
      "Epoch [9/20], Loss: 0.2586\n",
      "Validation loss decreased (0.281152 --> 0.258646).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2362\n",
      "Batch [60/313], Loss: 0.1839\n",
      "Batch [90/313], Loss: 0.3491\n",
      "Batch [120/313], Loss: 0.2722\n",
      "Batch [150/313], Loss: 0.2579\n",
      "Batch [180/313], Loss: 0.3639\n",
      "Batch [210/313], Loss: 0.3517\n",
      "Batch [240/313], Loss: 0.3512\n",
      "Batch [270/313], Loss: 0.2290\n",
      "Batch [300/313], Loss: 0.2519\n",
      "Epoch [10/20], Loss: 0.2496\n",
      "Validation loss decreased (0.258646 --> 0.249556).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2888\n",
      "Batch [60/313], Loss: 0.2447\n",
      "Batch [90/313], Loss: 0.2303\n",
      "Batch [120/313], Loss: 0.2490\n",
      "Batch [150/313], Loss: 0.3587\n",
      "Batch [180/313], Loss: 0.2154\n",
      "Batch [210/313], Loss: 0.1786\n",
      "Batch [240/313], Loss: 0.2524\n",
      "Batch [270/313], Loss: 0.3560\n",
      "Batch [300/313], Loss: 0.3018\n",
      "Epoch [11/20], Loss: 0.2368\n",
      "Validation loss decreased (0.249556 --> 0.236847).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2327\n",
      "Batch [60/313], Loss: 0.2160\n",
      "Batch [90/313], Loss: 0.2935\n",
      "Batch [120/313], Loss: 0.2814\n",
      "Batch [150/313], Loss: 0.2435\n",
      "Batch [180/313], Loss: 0.3868\n",
      "Batch [210/313], Loss: 0.2692\n",
      "Batch [240/313], Loss: 0.2372\n",
      "Batch [270/313], Loss: 0.3457\n",
      "Batch [300/313], Loss: 0.2102\n",
      "Epoch [12/20], Loss: 0.2139\n",
      "Validation loss decreased (0.236847 --> 0.213896).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1894\n",
      "Batch [60/313], Loss: 0.2313\n",
      "Batch [90/313], Loss: 0.3420\n",
      "Batch [120/313], Loss: 0.2042\n",
      "Batch [150/313], Loss: 0.2217\n",
      "Batch [180/313], Loss: 0.3502\n",
      "Batch [210/313], Loss: 0.2787\n",
      "Batch [240/313], Loss: 0.3052\n",
      "Batch [270/313], Loss: 0.3495\n",
      "Batch [300/313], Loss: 0.3470\n",
      "Epoch [13/20], Loss: 0.2106\n",
      "Validation loss decreased (0.213896 --> 0.210627).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2731\n",
      "Batch [60/313], Loss: 0.1906\n",
      "Batch [90/313], Loss: 0.2580\n",
      "Batch [120/313], Loss: 0.2545\n",
      "Batch [150/313], Loss: 0.2531\n",
      "Batch [180/313], Loss: 0.2426\n",
      "Batch [210/313], Loss: 0.2796\n",
      "Batch [240/313], Loss: 0.1886\n",
      "Batch [270/313], Loss: 0.1897\n",
      "Batch [300/313], Loss: 0.2427\n",
      "Epoch [14/20], Loss: 0.1941\n",
      "Validation loss decreased (0.210627 --> 0.194125).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1708\n",
      "Batch [60/313], Loss: 0.2894\n",
      "Batch [90/313], Loss: 0.2269\n",
      "Batch [120/313], Loss: 0.1737\n",
      "Batch [150/313], Loss: 0.1699\n",
      "Batch [180/313], Loss: 0.2018\n",
      "Batch [210/313], Loss: 0.2390\n",
      "Batch [240/313], Loss: 0.1846\n",
      "Batch [270/313], Loss: 0.2736\n",
      "Batch [300/313], Loss: 0.2459\n",
      "Epoch [15/20], Loss: 0.1801\n",
      "Validation loss decreased (0.194125 --> 0.180148).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2105\n",
      "Batch [60/313], Loss: 0.1873\n",
      "Batch [90/313], Loss: 0.1600\n",
      "Batch [120/313], Loss: 0.1719\n",
      "Batch [150/313], Loss: 0.2140\n",
      "Batch [180/313], Loss: 0.2151\n",
      "Batch [210/313], Loss: 0.2539\n",
      "Batch [240/313], Loss: 0.2567\n",
      "Batch [270/313], Loss: 0.2874\n",
      "Batch [300/313], Loss: 0.2013\n",
      "Epoch [16/20], Loss: 0.1788\n",
      "Validation loss decreased (0.180148 --> 0.178846).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1425\n",
      "Batch [60/313], Loss: 0.2882\n",
      "Batch [90/313], Loss: 0.1781\n",
      "Batch [120/313], Loss: 0.1917\n",
      "Batch [150/313], Loss: 0.2025\n",
      "Batch [180/313], Loss: 0.1724\n",
      "Batch [210/313], Loss: 0.1978\n",
      "Batch [240/313], Loss: 0.4342\n",
      "Batch [270/313], Loss: 0.2567\n",
      "Batch [300/313], Loss: 0.1699\n",
      "Epoch [17/20], Loss: 0.1682\n",
      "Validation loss decreased (0.178846 --> 0.168227).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1768\n",
      "Batch [60/313], Loss: 0.1419\n",
      "Batch [90/313], Loss: 0.1458\n",
      "Batch [120/313], Loss: 0.1686\n",
      "Batch [150/313], Loss: 0.1714\n",
      "Batch [180/313], Loss: 0.2548\n",
      "Batch [210/313], Loss: 0.1907\n",
      "Batch [240/313], Loss: 0.2289\n",
      "Batch [270/313], Loss: 0.2103\n",
      "Batch [300/313], Loss: 0.2515\n",
      "Epoch [18/20], Loss: 0.1513\n",
      "Validation loss decreased (0.168227 --> 0.151322).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1612\n",
      "Batch [60/313], Loss: 0.1597\n",
      "Batch [90/313], Loss: 0.1812\n",
      "Batch [120/313], Loss: 0.1743\n",
      "Batch [150/313], Loss: 0.1714\n",
      "Batch [180/313], Loss: 0.1885\n",
      "Batch [210/313], Loss: 0.2129\n",
      "Batch [240/313], Loss: 0.1555\n",
      "Batch [270/313], Loss: 0.1917\n",
      "Batch [300/313], Loss: 0.1806\n",
      "Epoch [19/20], Loss: 0.1471\n",
      "Validation loss decreased (0.151322 --> 0.147101).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2656\n",
      "Batch [60/313], Loss: 0.1751\n",
      "Batch [90/313], Loss: 0.1919\n",
      "Batch [120/313], Loss: 0.2162\n",
      "Batch [150/313], Loss: 0.1581\n",
      "Batch [180/313], Loss: 0.1902\n",
      "Batch [210/313], Loss: 0.1528\n",
      "Batch [240/313], Loss: 0.1729\n",
      "Batch [270/313], Loss: 0.1790\n",
      "Batch [300/313], Loss: 0.1909\n",
      "Epoch [20/20], Loss: 0.1383\n",
      "Validation loss decreased (0.147101 --> 0.138261).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████                                  | 3/20 [57:03<6:56:07, 1468.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]   Loss: 1.6898   Accuracy: 62.72%\n",
      "Batch [30/313], Loss: 0.1995\n",
      "Batch [60/313], Loss: 0.1808\n",
      "Batch [90/313], Loss: 0.1968\n",
      "Batch [120/313], Loss: 0.1539\n",
      "Batch [150/313], Loss: 0.1336\n",
      "Batch [180/313], Loss: 0.1630\n",
      "Batch [210/313], Loss: 0.1658\n",
      "Batch [240/313], Loss: 0.1858\n",
      "Batch [270/313], Loss: 0.1133\n",
      "Batch [300/313], Loss: 0.1480\n",
      "Epoch [1/20], Loss: 0.1302\n",
      "Validation loss decreased (0.138261 --> 0.130207).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0820\n",
      "Batch [60/313], Loss: 0.1533\n",
      "Batch [90/313], Loss: 0.1804\n",
      "Batch [120/313], Loss: 0.1144\n",
      "Batch [150/313], Loss: 0.1064\n",
      "Batch [180/313], Loss: 0.0941\n",
      "Batch [210/313], Loss: 0.2205\n",
      "Batch [240/313], Loss: 0.0934\n",
      "Batch [270/313], Loss: 0.1315\n",
      "Batch [300/313], Loss: 0.2128\n",
      "Epoch [2/20], Loss: 0.1138\n",
      "Validation loss decreased (0.130207 --> 0.113765).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2041\n",
      "Batch [60/313], Loss: 0.1162\n",
      "Batch [90/313], Loss: 0.1492\n",
      "Batch [120/313], Loss: 0.1270\n",
      "Batch [150/313], Loss: 0.1112\n",
      "Batch [180/313], Loss: 0.1720\n",
      "Batch [210/313], Loss: 0.2057\n",
      "Batch [240/313], Loss: 0.1103\n",
      "Batch [270/313], Loss: 0.1315\n",
      "Batch [300/313], Loss: 0.1959\n",
      "Epoch [3/20], Loss: 0.1122\n",
      "Validation loss decreased (0.113765 --> 0.112203).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1037\n",
      "Batch [60/313], Loss: 0.1824\n",
      "Batch [90/313], Loss: 0.1265\n",
      "Batch [120/313], Loss: 0.1653\n",
      "Batch [150/313], Loss: 0.1005\n",
      "Batch [180/313], Loss: 0.1205\n",
      "Batch [210/313], Loss: 0.1383\n",
      "Batch [240/313], Loss: 0.1559\n",
      "Batch [270/313], Loss: 0.1859\n",
      "Batch [300/313], Loss: 0.1235\n",
      "Epoch [4/20], Loss: 0.1051\n",
      "Validation loss decreased (0.112203 --> 0.105135).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1381\n",
      "Batch [60/313], Loss: 0.1212\n",
      "Batch [90/313], Loss: 0.1239\n",
      "Batch [120/313], Loss: 0.0770\n",
      "Batch [150/313], Loss: 0.0914\n",
      "Batch [180/313], Loss: 0.1127\n",
      "Batch [210/313], Loss: 0.0931\n",
      "Batch [240/313], Loss: 0.1340\n",
      "Batch [270/313], Loss: 0.1226\n",
      "Batch [300/313], Loss: 0.1129\n",
      "Epoch [5/20], Loss: 0.0992\n",
      "Validation loss decreased (0.105135 --> 0.099203).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1252\n",
      "Batch [60/313], Loss: 0.1071\n",
      "Batch [90/313], Loss: 0.1036\n",
      "Batch [120/313], Loss: 0.1131\n",
      "Batch [150/313], Loss: 0.1235\n",
      "Batch [180/313], Loss: 0.1515\n",
      "Batch [210/313], Loss: 0.1924\n",
      "Batch [240/313], Loss: 0.1273\n",
      "Batch [270/313], Loss: 0.1035\n",
      "Batch [300/313], Loss: 0.1112\n",
      "Epoch [6/20], Loss: 0.0952\n",
      "Validation loss decreased (0.099203 --> 0.095196).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0961\n",
      "Batch [60/313], Loss: 0.1485\n",
      "Batch [90/313], Loss: 0.1077\n",
      "Batch [120/313], Loss: 0.1420\n",
      "Batch [150/313], Loss: 0.1727\n",
      "Batch [180/313], Loss: 0.0955\n",
      "Batch [210/313], Loss: 0.0732\n",
      "Batch [240/313], Loss: 0.1127\n",
      "Batch [270/313], Loss: 0.1075\n",
      "Batch [300/313], Loss: 0.0825\n",
      "Epoch [7/20], Loss: 0.0864\n",
      "Validation loss decreased (0.095196 --> 0.086394).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0990\n",
      "Batch [60/313], Loss: 0.1555\n",
      "Batch [90/313], Loss: 0.0769\n",
      "Batch [120/313], Loss: 0.1254\n",
      "Batch [150/313], Loss: 0.0859\n",
      "Batch [180/313], Loss: 0.1169\n",
      "Batch [210/313], Loss: 0.1164\n",
      "Batch [240/313], Loss: 0.0776\n",
      "Batch [270/313], Loss: 0.1224\n",
      "Batch [300/313], Loss: 0.1260\n",
      "Epoch [8/20], Loss: 0.0879\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.1068\n",
      "Batch [60/313], Loss: 0.0773\n",
      "Batch [90/313], Loss: 0.1227\n",
      "Batch [120/313], Loss: 0.0747\n",
      "Batch [150/313], Loss: 0.0705\n",
      "Batch [180/313], Loss: 0.0851\n",
      "Batch [210/313], Loss: 0.1047\n",
      "Batch [240/313], Loss: 0.0768\n",
      "Batch [270/313], Loss: 0.0946\n",
      "Batch [300/313], Loss: 0.1432\n",
      "Epoch [9/20], Loss: 0.0779\n",
      "Validation loss decreased (0.086394 --> 0.077883).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0824\n",
      "Batch [60/313], Loss: 0.0663\n",
      "Batch [90/313], Loss: 0.0645\n",
      "Batch [120/313], Loss: 0.0985\n",
      "Batch [150/313], Loss: 0.0615\n",
      "Batch [180/313], Loss: 0.0891\n",
      "Batch [210/313], Loss: 0.0609\n",
      "Batch [240/313], Loss: 0.1050\n",
      "Batch [270/313], Loss: 0.1011\n",
      "Batch [300/313], Loss: 0.0697\n",
      "Epoch [10/20], Loss: 0.0745\n",
      "Validation loss decreased (0.077883 --> 0.074489).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0801\n",
      "Batch [60/313], Loss: 0.0548\n",
      "Batch [90/313], Loss: 0.1021\n",
      "Batch [120/313], Loss: 0.0885\n",
      "Batch [150/313], Loss: 0.0643\n",
      "Batch [180/313], Loss: 0.1369\n",
      "Batch [210/313], Loss: 0.0752\n",
      "Batch [240/313], Loss: 0.1150\n",
      "Batch [270/313], Loss: 0.0878\n",
      "Batch [300/313], Loss: 0.0675\n",
      "Epoch [11/20], Loss: 0.0681\n",
      "Validation loss decreased (0.074489 --> 0.068062).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0561\n",
      "Batch [60/313], Loss: 0.0700\n",
      "Batch [90/313], Loss: 0.0614\n",
      "Batch [120/313], Loss: 0.0831\n",
      "Batch [150/313], Loss: 0.1015\n",
      "Batch [180/313], Loss: 0.0808\n",
      "Batch [210/313], Loss: 0.0550\n",
      "Batch [240/313], Loss: 0.0866\n",
      "Batch [270/313], Loss: 0.0809\n",
      "Batch [300/313], Loss: 0.1329\n",
      "Epoch [12/20], Loss: 0.0671\n",
      "Validation loss decreased (0.068062 --> 0.067090).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0777\n",
      "Batch [60/313], Loss: 0.0721\n",
      "Batch [90/313], Loss: 0.0457\n",
      "Batch [120/313], Loss: 0.0699\n",
      "Batch [150/313], Loss: 0.0714\n",
      "Batch [180/313], Loss: 0.0930\n",
      "Batch [210/313], Loss: 0.0607\n",
      "Batch [240/313], Loss: 0.0740\n",
      "Batch [270/313], Loss: 0.0643\n",
      "Batch [300/313], Loss: 0.1202\n",
      "Epoch [13/20], Loss: 0.0642\n",
      "Validation loss decreased (0.067090 --> 0.064206).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0607\n",
      "Batch [60/313], Loss: 0.1199\n",
      "Batch [90/313], Loss: 0.0924\n",
      "Batch [120/313], Loss: 0.0637\n",
      "Batch [150/313], Loss: 0.0859\n",
      "Batch [180/313], Loss: 0.0902\n",
      "Batch [210/313], Loss: 0.0776\n",
      "Batch [240/313], Loss: 0.0671\n",
      "Batch [270/313], Loss: 0.0897\n",
      "Batch [300/313], Loss: 0.0772\n",
      "Epoch [14/20], Loss: 0.0650\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0753\n",
      "Batch [60/313], Loss: 0.0722\n",
      "Batch [90/313], Loss: 0.0760\n",
      "Batch [120/313], Loss: 0.0628\n",
      "Batch [150/313], Loss: 0.0723\n",
      "Batch [180/313], Loss: 0.0774\n",
      "Batch [210/313], Loss: 0.1448\n",
      "Batch [240/313], Loss: 0.0624\n",
      "Batch [270/313], Loss: 0.0739\n",
      "Batch [300/313], Loss: 0.0705\n",
      "Epoch [15/20], Loss: 0.0608\n",
      "Validation loss decreased (0.064206 --> 0.060849).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0496\n",
      "Batch [60/313], Loss: 0.0397\n",
      "Batch [90/313], Loss: 0.0808\n",
      "Batch [120/313], Loss: 0.0608\n",
      "Batch [150/313], Loss: 0.0830\n",
      "Batch [180/313], Loss: 0.0957\n",
      "Batch [210/313], Loss: 0.0786\n",
      "Batch [240/313], Loss: 0.0571\n",
      "Batch [270/313], Loss: 0.0762\n",
      "Batch [300/313], Loss: 0.0896\n",
      "Epoch [16/20], Loss: 0.0539\n",
      "Validation loss decreased (0.060849 --> 0.053902).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0363\n",
      "Batch [60/313], Loss: 0.0381\n",
      "Batch [90/313], Loss: 0.0531\n",
      "Batch [120/313], Loss: 0.0524\n",
      "Batch [150/313], Loss: 0.0483\n",
      "Batch [180/313], Loss: 0.0451\n",
      "Batch [210/313], Loss: 0.0609\n",
      "Batch [240/313], Loss: 0.0452\n",
      "Batch [270/313], Loss: 0.0539\n",
      "Batch [300/313], Loss: 0.0695\n",
      "Epoch [17/20], Loss: 0.0533\n",
      "Validation loss decreased (0.053902 --> 0.053250).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0537\n",
      "Batch [60/313], Loss: 0.0343\n",
      "Batch [90/313], Loss: 0.0698\n",
      "Batch [120/313], Loss: 0.0621\n",
      "Batch [150/313], Loss: 0.0602\n",
      "Batch [180/313], Loss: 0.0568\n",
      "Batch [210/313], Loss: 0.0730\n",
      "Batch [240/313], Loss: 0.0677\n",
      "Batch [270/313], Loss: 0.0630\n",
      "Batch [300/313], Loss: 0.0651\n",
      "Epoch [18/20], Loss: 0.0524\n",
      "Validation loss decreased (0.053250 --> 0.052433).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0540\n",
      "Batch [60/313], Loss: 0.0406\n",
      "Batch [90/313], Loss: 0.0530\n",
      "Batch [120/313], Loss: 0.0430\n",
      "Batch [150/313], Loss: 0.0410\n",
      "Batch [180/313], Loss: 0.0443\n",
      "Batch [210/313], Loss: 0.0746\n",
      "Batch [240/313], Loss: 0.0552\n",
      "Batch [270/313], Loss: 0.0461\n",
      "Batch [300/313], Loss: 0.0541\n",
      "Epoch [19/20], Loss: 0.0487\n",
      "Validation loss decreased (0.052433 --> 0.048685).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0424\n",
      "Batch [60/313], Loss: 0.0370\n",
      "Batch [90/313], Loss: 0.0505\n",
      "Batch [120/313], Loss: 0.0491\n",
      "Batch [150/313], Loss: 0.0332\n",
      "Batch [180/313], Loss: 0.0627\n",
      "Batch [210/313], Loss: 0.0511\n",
      "Batch [240/313], Loss: 0.0702\n",
      "Batch [270/313], Loss: 0.0731\n",
      "Batch [300/313], Loss: 0.0583\n",
      "Epoch [20/20], Loss: 0.0421\n",
      "Validation loss decreased (0.048685 --> 0.042095).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 4/20 [1:11:50<5:30:24, 1239.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]   Loss: 1.7646   Accuracy: 64.01%\n",
      "Batch [30/313], Loss: 0.0440\n",
      "Batch [60/313], Loss: 0.0777\n",
      "Batch [90/313], Loss: 0.0473\n",
      "Batch [120/313], Loss: 0.0349\n",
      "Batch [150/313], Loss: 0.0691\n",
      "Batch [180/313], Loss: 0.0378\n",
      "Batch [210/313], Loss: 0.0481\n",
      "Batch [240/313], Loss: 0.0490\n",
      "Batch [270/313], Loss: 0.0817\n",
      "Batch [300/313], Loss: 0.1086\n",
      "Epoch [1/20], Loss: 0.0429\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0365\n",
      "Batch [60/313], Loss: 0.0708\n",
      "Batch [90/313], Loss: 0.0574\n",
      "Batch [120/313], Loss: 0.0626\n",
      "Batch [150/313], Loss: 0.0629\n",
      "Batch [180/313], Loss: 0.0290\n",
      "Batch [210/313], Loss: 0.0270\n",
      "Batch [240/313], Loss: 0.0462\n",
      "Batch [270/313], Loss: 0.0320\n",
      "Batch [300/313], Loss: 0.0816\n",
      "Epoch [2/20], Loss: 0.0418\n",
      "Validation loss decreased (0.042095 --> 0.041829).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0444\n",
      "Batch [60/313], Loss: 0.0363\n",
      "Batch [90/313], Loss: 0.0367\n",
      "Batch [120/313], Loss: 0.0734\n",
      "Batch [150/313], Loss: 0.0340\n",
      "Batch [180/313], Loss: 0.0552\n",
      "Batch [210/313], Loss: 0.0743\n",
      "Batch [240/313], Loss: 0.0981\n",
      "Batch [270/313], Loss: 0.0664\n",
      "Batch [300/313], Loss: 0.0296\n",
      "Epoch [3/20], Loss: 0.0425\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.1083\n",
      "Batch [60/313], Loss: 0.0942\n",
      "Batch [90/313], Loss: 0.0501\n",
      "Batch [120/313], Loss: 0.0413\n",
      "Batch [150/313], Loss: 0.0711\n",
      "Batch [180/313], Loss: 0.0815\n",
      "Batch [210/313], Loss: 0.0445\n",
      "Batch [240/313], Loss: 0.0558\n",
      "Batch [270/313], Loss: 0.0524\n",
      "Batch [300/313], Loss: 0.0735\n",
      "Epoch [4/20], Loss: 0.0428\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0542\n",
      "Batch [60/313], Loss: 0.0517\n",
      "Batch [90/313], Loss: 0.0432\n",
      "Batch [120/313], Loss: 0.0348\n",
      "Batch [150/313], Loss: 0.0678\n",
      "Batch [180/313], Loss: 0.0290\n",
      "Batch [210/313], Loss: 0.0275\n",
      "Batch [240/313], Loss: 0.0592\n",
      "Batch [270/313], Loss: 0.0452\n",
      "Batch [300/313], Loss: 0.0509\n",
      "Epoch [5/20], Loss: 0.0414\n",
      "Validation loss decreased (0.041829 --> 0.041430).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0566\n",
      "Batch [60/313], Loss: 0.0353\n",
      "Batch [90/313], Loss: 0.0837\n",
      "Batch [120/313], Loss: 0.0249\n",
      "Batch [150/313], Loss: 0.0642\n",
      "Batch [180/313], Loss: 0.0560\n",
      "Batch [210/313], Loss: 0.0332\n",
      "Batch [240/313], Loss: 0.0827\n",
      "Batch [270/313], Loss: 0.0450\n",
      "Batch [300/313], Loss: 0.0387\n",
      "Epoch [6/20], Loss: 0.0394\n",
      "Validation loss decreased (0.041430 --> 0.039395).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0249\n",
      "Batch [60/313], Loss: 0.0410\n",
      "Batch [90/313], Loss: 0.0482\n",
      "Batch [120/313], Loss: 0.0969\n",
      "Batch [150/313], Loss: 0.0371\n",
      "Batch [180/313], Loss: 0.0701\n",
      "Batch [210/313], Loss: 0.0519\n",
      "Batch [240/313], Loss: 0.0337\n",
      "Batch [270/313], Loss: 0.0663\n",
      "Batch [300/313], Loss: 0.0599\n",
      "Epoch [7/20], Loss: 0.0384\n",
      "Validation loss decreased (0.039395 --> 0.038394).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0455\n",
      "Batch [60/313], Loss: 0.0347\n",
      "Batch [90/313], Loss: 0.0480\n",
      "Batch [120/313], Loss: 0.0257\n",
      "Batch [150/313], Loss: 0.0682\n",
      "Batch [180/313], Loss: 0.0652\n",
      "Batch [210/313], Loss: 0.0463\n",
      "Batch [240/313], Loss: 0.0398\n",
      "Batch [270/313], Loss: 0.0698\n",
      "Batch [300/313], Loss: 0.0514\n",
      "Epoch [8/20], Loss: 0.0359\n",
      "Validation loss decreased (0.038394 --> 0.035921).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0320\n",
      "Batch [60/313], Loss: 0.0239\n",
      "Batch [90/313], Loss: 0.0277\n",
      "Batch [120/313], Loss: 0.0446\n",
      "Batch [150/313], Loss: 0.0510\n",
      "Batch [180/313], Loss: 0.0421\n",
      "Batch [210/313], Loss: 0.0689\n",
      "Batch [240/313], Loss: 0.0345\n",
      "Batch [270/313], Loss: 0.0368\n",
      "Batch [300/313], Loss: 0.0449\n",
      "Epoch [9/20], Loss: 0.0326\n",
      "Validation loss decreased (0.035921 --> 0.032565).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0175\n",
      "Batch [60/313], Loss: 0.0434\n",
      "Batch [90/313], Loss: 0.0249\n",
      "Batch [120/313], Loss: 0.0482\n",
      "Batch [150/313], Loss: 0.0455\n",
      "Batch [180/313], Loss: 0.0465\n",
      "Batch [210/313], Loss: 0.0426\n",
      "Batch [240/313], Loss: 0.0249\n",
      "Batch [270/313], Loss: 0.0554\n",
      "Batch [300/313], Loss: 0.0476\n",
      "Epoch [10/20], Loss: 0.0319\n",
      "Validation loss decreased (0.032565 --> 0.031875).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0530\n",
      "Batch [60/313], Loss: 0.0430\n",
      "Batch [90/313], Loss: 0.0322\n",
      "Batch [120/313], Loss: 0.0529\n",
      "Batch [150/313], Loss: 0.0273\n",
      "Batch [180/313], Loss: 0.0344\n",
      "Batch [210/313], Loss: 0.0646\n",
      "Batch [240/313], Loss: 0.0486\n",
      "Batch [270/313], Loss: 0.0298\n",
      "Batch [300/313], Loss: 0.0414\n",
      "Epoch [11/20], Loss: 0.0299\n",
      "Validation loss decreased (0.031875 --> 0.029866).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0327\n",
      "Batch [60/313], Loss: 0.0269\n",
      "Batch [90/313], Loss: 0.0319\n",
      "Batch [120/313], Loss: 0.0352\n",
      "Batch [150/313], Loss: 0.0214\n",
      "Batch [180/313], Loss: 0.0418\n",
      "Batch [210/313], Loss: 0.0235\n",
      "Batch [240/313], Loss: 0.0291\n",
      "Batch [270/313], Loss: 0.0456\n",
      "Batch [300/313], Loss: 0.0828\n",
      "Epoch [12/20], Loss: 0.0267\n",
      "Validation loss decreased (0.029866 --> 0.026714).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0264\n",
      "Batch [60/313], Loss: 0.0248\n",
      "Batch [90/313], Loss: 0.0173\n",
      "Batch [120/313], Loss: 0.0407\n",
      "Batch [150/313], Loss: 0.0208\n",
      "Batch [180/313], Loss: 0.0299\n",
      "Batch [210/313], Loss: 0.0284\n",
      "Batch [240/313], Loss: 0.0330\n",
      "Batch [270/313], Loss: 0.0206\n",
      "Batch [300/313], Loss: 0.0405\n",
      "Epoch [13/20], Loss: 0.0251\n",
      "Validation loss decreased (0.026714 --> 0.025071).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0477\n",
      "Batch [60/313], Loss: 0.0431\n",
      "Batch [90/313], Loss: 0.0192\n",
      "Batch [120/313], Loss: 0.0296\n",
      "Batch [150/313], Loss: 0.0261\n",
      "Batch [180/313], Loss: 0.0247\n",
      "Batch [210/313], Loss: 0.0199\n",
      "Batch [240/313], Loss: 0.0329\n",
      "Batch [270/313], Loss: 0.0318\n",
      "Batch [300/313], Loss: 0.0256\n",
      "Epoch [14/20], Loss: 0.0232\n",
      "Validation loss decreased (0.025071 --> 0.023176).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0610\n",
      "Batch [60/313], Loss: 0.0140\n",
      "Batch [90/313], Loss: 0.0248\n",
      "Batch [120/313], Loss: 0.0457\n",
      "Batch [150/313], Loss: 0.0247\n",
      "Batch [180/313], Loss: 0.0458\n",
      "Batch [210/313], Loss: 0.0327\n",
      "Batch [240/313], Loss: 0.0365\n",
      "Batch [270/313], Loss: 0.1026\n",
      "Batch [300/313], Loss: 0.0515\n",
      "Epoch [15/20], Loss: 0.0271\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0301\n",
      "Batch [60/313], Loss: 0.0357\n",
      "Batch [90/313], Loss: 0.0207\n",
      "Batch [120/313], Loss: 0.0226\n",
      "Batch [150/313], Loss: 0.0276\n",
      "Batch [180/313], Loss: 0.0208\n",
      "Batch [210/313], Loss: 0.0835\n",
      "Batch [240/313], Loss: 0.0197\n",
      "Batch [270/313], Loss: 0.0509\n",
      "Batch [300/313], Loss: 0.0399\n",
      "Epoch [16/20], Loss: 0.0236\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0165\n",
      "Batch [60/313], Loss: 0.0171\n",
      "Batch [90/313], Loss: 0.0359\n",
      "Batch [120/313], Loss: 0.0516\n",
      "Batch [150/313], Loss: 0.0290\n",
      "Batch [180/313], Loss: 0.0197\n",
      "Batch [210/313], Loss: 0.0265\n",
      "Batch [240/313], Loss: 0.0224\n",
      "Batch [270/313], Loss: 0.0156\n",
      "Batch [300/313], Loss: 0.0317\n",
      "Epoch [17/20], Loss: 0.0205\n",
      "Validation loss decreased (0.023176 --> 0.020467).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0302\n",
      "Batch [60/313], Loss: 0.0192\n",
      "Batch [90/313], Loss: 0.0224\n",
      "Batch [120/313], Loss: 0.0242\n",
      "Batch [150/313], Loss: 0.0246\n",
      "Batch [180/313], Loss: 0.0220\n",
      "Batch [210/313], Loss: 0.0535\n",
      "Batch [240/313], Loss: 0.0267\n",
      "Batch [270/313], Loss: 0.0128\n",
      "Batch [300/313], Loss: 0.0462\n",
      "Epoch [18/20], Loss: 0.0204\n",
      "Validation loss decreased (0.020467 --> 0.020428).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0188\n",
      "Batch [60/313], Loss: 0.0182\n",
      "Batch [90/313], Loss: 0.0235\n",
      "Batch [120/313], Loss: 0.0405\n",
      "Batch [150/313], Loss: 0.0287\n",
      "Batch [180/313], Loss: 0.0351\n",
      "Batch [210/313], Loss: 0.0171\n",
      "Batch [240/313], Loss: 0.0207\n",
      "Batch [270/313], Loss: 0.0210\n",
      "Batch [300/313], Loss: 0.0301\n",
      "Epoch [19/20], Loss: 0.0206\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0445\n",
      "Batch [60/313], Loss: 0.0202\n",
      "Batch [90/313], Loss: 0.0284\n",
      "Batch [120/313], Loss: 0.0752\n",
      "Batch [150/313], Loss: 0.0541\n",
      "Batch [180/313], Loss: 0.0244\n",
      "Batch [210/313], Loss: 0.0175\n",
      "Batch [240/313], Loss: 0.0201\n",
      "Batch [270/313], Loss: 0.0302\n",
      "Batch [300/313], Loss: 0.0240\n",
      "Epoch [20/20], Loss: 0.0220\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▌                            | 5/20 [1:27:15<4:41:29, 1125.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]   Loss: 1.8390   Accuracy: 64.78%\n",
      "Batch [30/313], Loss: 0.0340\n",
      "Batch [60/313], Loss: 0.0271\n",
      "Batch [90/313], Loss: 0.0267\n",
      "Batch [120/313], Loss: 0.0228\n",
      "Batch [150/313], Loss: 0.0928\n",
      "Batch [180/313], Loss: 0.0187\n",
      "Batch [210/313], Loss: 0.0134\n",
      "Batch [240/313], Loss: 0.0317\n",
      "Batch [270/313], Loss: 0.0218\n",
      "Batch [300/313], Loss: 0.0233\n",
      "Epoch [1/20], Loss: 0.0217\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0257\n",
      "Batch [60/313], Loss: 0.0482\n",
      "Batch [90/313], Loss: 0.0241\n",
      "Batch [120/313], Loss: 0.0268\n",
      "Batch [150/313], Loss: 0.0260\n",
      "Batch [180/313], Loss: 0.0228\n",
      "Batch [210/313], Loss: 0.0560\n",
      "Batch [240/313], Loss: 0.0240\n",
      "Batch [270/313], Loss: 0.0182\n",
      "Batch [300/313], Loss: 0.0201\n",
      "Epoch [2/20], Loss: 0.0220\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Batch [30/313], Loss: 0.0159\n",
      "Batch [60/313], Loss: 0.0145\n",
      "Batch [90/313], Loss: 0.0204\n",
      "Batch [120/313], Loss: 0.0156\n",
      "Batch [150/313], Loss: 0.0160\n",
      "Batch [180/313], Loss: 0.0204\n",
      "Batch [210/313], Loss: 0.0268\n",
      "Batch [240/313], Loss: 0.0166\n",
      "Batch [270/313], Loss: 0.0227\n",
      "Batch [300/313], Loss: 0.0315\n",
      "Epoch [3/20], Loss: 0.0208\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▋                           | 6/20 [1:29:33<3:04:20, 790.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]   Loss: 1.8302   Accuracy: 64.64%\n",
      "Batch [30/313], Loss: 0.0171\n",
      "Batch [60/313], Loss: 0.0262\n",
      "Batch [90/313], Loss: 0.0267\n",
      "Batch [120/313], Loss: 0.0215\n",
      "Batch [150/313], Loss: 0.0225\n",
      "Batch [180/313], Loss: 0.0160\n",
      "Batch [210/313], Loss: 0.0367\n",
      "Batch [240/313], Loss: 0.0210\n",
      "Batch [270/313], Loss: 0.0222\n",
      "Batch [300/313], Loss: 0.0266\n",
      "Epoch [1/20], Loss: 0.0201\n",
      "Validation loss decreased (0.020428 --> 0.020126).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████▋                         | 7/20 [1:30:24<1:58:48, 548.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]   Loss: 1.8471   Accuracy: 64.49%\n",
      "Batch [30/313], Loss: 0.0303\n",
      "Batch [60/313], Loss: 0.0278\n",
      "Batch [90/313], Loss: 0.0220\n",
      "Batch [120/313], Loss: 0.0222\n",
      "Batch [150/313], Loss: 0.0201\n",
      "Batch [180/313], Loss: 0.0104\n",
      "Batch [210/313], Loss: 0.0225\n",
      "Batch [240/313], Loss: 0.0203\n",
      "Batch [270/313], Loss: 0.0407\n",
      "Batch [300/313], Loss: 0.0125\n",
      "Epoch [1/20], Loss: 0.0204\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▌                       | 8/20 [1:31:06<1:17:26, 387.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]   Loss: 1.8024   Accuracy: 65.09%\n",
      "Batch [30/313], Loss: 0.0233\n",
      "Batch [60/313], Loss: 0.0154\n",
      "Batch [90/313], Loss: 0.0223\n",
      "Batch [120/313], Loss: 0.0187\n",
      "Batch [150/313], Loss: 0.0159\n",
      "Batch [180/313], Loss: 0.0156\n",
      "Batch [210/313], Loss: 0.0201\n",
      "Batch [240/313], Loss: 0.0109\n",
      "Batch [270/313], Loss: 0.0230\n",
      "Batch [300/313], Loss: 0.0162\n",
      "Epoch [1/20], Loss: 0.0168\n",
      "Validation loss decreased (0.020126 --> 0.016797).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████▍                      | 9/20 [1:31:39<50:40, 276.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]   Loss: 1.8326   Accuracy: 65.05%\n",
      "Batch [30/313], Loss: 0.0221\n",
      "Batch [60/313], Loss: 0.0120\n",
      "Batch [90/313], Loss: 0.0473\n",
      "Batch [120/313], Loss: 0.0191\n",
      "Batch [150/313], Loss: 0.0129\n",
      "Batch [180/313], Loss: 0.0097\n",
      "Batch [210/313], Loss: 0.0133\n",
      "Batch [240/313], Loss: 0.0265\n",
      "Batch [270/313], Loss: 0.0140\n",
      "Batch [300/313], Loss: 0.0245\n",
      "Epoch [1/20], Loss: 0.0175\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████                    | 10/20 [1:32:11<33:30, 201.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]   Loss: 1.8162   Accuracy: 64.98%\n",
      "Batch [30/313], Loss: 0.0248\n",
      "Batch [60/313], Loss: 0.0083\n",
      "Batch [90/313], Loss: 0.0144\n",
      "Batch [120/313], Loss: 0.0131\n",
      "Batch [150/313], Loss: 0.0206\n",
      "Batch [180/313], Loss: 0.0101\n",
      "Batch [210/313], Loss: 0.0336\n",
      "Batch [240/313], Loss: 0.0211\n",
      "Batch [270/313], Loss: 0.0329\n",
      "Batch [300/313], Loss: 0.0164\n",
      "Epoch [1/20], Loss: 0.0163\n",
      "Validation loss decreased (0.016797 --> 0.016314).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████                  | 11/20 [1:32:44<22:26, 149.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]   Loss: 1.7909   Accuracy: 65.19%\n",
      "Batch [30/313], Loss: 0.0199\n",
      "Batch [60/313], Loss: 0.0101\n",
      "Batch [90/313], Loss: 0.0200\n",
      "Batch [120/313], Loss: 0.0108\n",
      "Batch [150/313], Loss: 0.0229\n",
      "Batch [180/313], Loss: 0.0104\n",
      "Batch [210/313], Loss: 0.0157\n",
      "Batch [240/313], Loss: 0.0184\n",
      "Batch [270/313], Loss: 0.0160\n",
      "Batch [300/313], Loss: 0.0181\n",
      "Epoch [1/20], Loss: 0.0168\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████                | 12/20 [1:33:16<15:09, 113.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]   Loss: 1.8471   Accuracy: 64.79%\n",
      "Batch [30/313], Loss: 0.0118\n",
      "Batch [60/313], Loss: 0.0257\n",
      "Batch [90/313], Loss: 0.0146\n",
      "Batch [120/313], Loss: 0.0158\n",
      "Batch [150/313], Loss: 0.0181\n",
      "Batch [180/313], Loss: 0.0157\n",
      "Batch [210/313], Loss: 0.0255\n",
      "Batch [240/313], Loss: 0.0220\n",
      "Batch [270/313], Loss: 0.0145\n",
      "Batch [300/313], Loss: 0.0136\n",
      "Epoch [1/20], Loss: 0.0172\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████▋              | 13/20 [1:33:48<10:24, 89.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]   Loss: 1.8207   Accuracy: 65.25%\n",
      "Batch [30/313], Loss: 0.0193\n",
      "Batch [60/313], Loss: 0.0112\n",
      "Batch [90/313], Loss: 0.0144\n",
      "Batch [120/313], Loss: 0.0117\n",
      "Batch [150/313], Loss: 0.0219\n",
      "Batch [180/313], Loss: 0.0080\n",
      "Batch [210/313], Loss: 0.0102\n",
      "Batch [240/313], Loss: 0.0147\n",
      "Batch [270/313], Loss: 0.0228\n",
      "Batch [300/313], Loss: 0.0128\n",
      "Epoch [1/20], Loss: 0.0161\n",
      "Validation loss decreased (0.016314 --> 0.016059).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████▋            | 14/20 [1:34:19<07:09, 71.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]   Loss: 1.8238   Accuracy: 64.66%\n",
      "Batch [30/313], Loss: 0.0158\n",
      "Batch [60/313], Loss: 0.0201\n",
      "Batch [90/313], Loss: 0.0096\n",
      "Batch [120/313], Loss: 0.0431\n",
      "Batch [150/313], Loss: 0.0114\n",
      "Batch [180/313], Loss: 0.0117\n",
      "Batch [210/313], Loss: 0.0381\n",
      "Batch [240/313], Loss: 0.0175\n",
      "Batch [270/313], Loss: 0.0105\n",
      "Batch [300/313], Loss: 0.0309\n",
      "Epoch [1/20], Loss: 0.0168\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████▊          | 15/20 [1:34:49<04:54, 58.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]   Loss: 1.8685   Accuracy: 64.83%\n",
      "Batch [30/313], Loss: 0.0182\n",
      "Batch [60/313], Loss: 0.0165\n",
      "Batch [90/313], Loss: 0.0130\n",
      "Batch [120/313], Loss: 0.0211\n",
      "Batch [150/313], Loss: 0.0153\n",
      "Batch [180/313], Loss: 0.0191\n",
      "Batch [210/313], Loss: 0.0409\n",
      "Batch [240/313], Loss: 0.0169\n",
      "Batch [270/313], Loss: 0.0125\n",
      "Batch [300/313], Loss: 0.0087\n",
      "Epoch [1/20], Loss: 0.0159\n",
      "Validation loss decreased (0.016059 --> 0.015883).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████▊        | 16/20 [1:35:19<03:21, 50.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]   Loss: 1.8298   Accuracy: 65.06%\n",
      "Batch [30/313], Loss: 0.0086\n",
      "Batch [60/313], Loss: 0.0105\n",
      "Batch [90/313], Loss: 0.0374\n",
      "Batch [120/313], Loss: 0.0119\n",
      "Batch [150/313], Loss: 0.0150\n",
      "Batch [180/313], Loss: 0.0264\n",
      "Batch [210/313], Loss: 0.0237\n",
      "Batch [240/313], Loss: 0.0105\n",
      "Batch [270/313], Loss: 0.0084\n",
      "Batch [300/313], Loss: 0.0323\n",
      "Epoch [1/20], Loss: 0.0148\n",
      "Validation loss decreased (0.015883 --> 0.014826).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████▊      | 17/20 [1:35:49<02:12, 44.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]   Loss: 1.8162   Accuracy: 65.07%\n",
      "Batch [30/313], Loss: 0.0147\n",
      "Batch [60/313], Loss: 0.0119\n",
      "Batch [90/313], Loss: 0.0181\n",
      "Batch [120/313], Loss: 0.0201\n",
      "Batch [150/313], Loss: 0.0122\n",
      "Batch [180/313], Loss: 0.0247\n",
      "Batch [210/313], Loss: 0.0186\n",
      "Batch [240/313], Loss: 0.0157\n",
      "Batch [270/313], Loss: 0.0159\n",
      "Batch [300/313], Loss: 0.0172\n",
      "Epoch [1/20], Loss: 0.0138\n",
      "Validation loss decreased (0.014826 --> 0.013825).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████▉    | 18/20 [1:36:20<01:20, 40.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]   Loss: 1.8243   Accuracy: 65.09%\n",
      "Batch [30/313], Loss: 0.0173\n",
      "Batch [60/313], Loss: 0.0130\n",
      "Batch [90/313], Loss: 0.0242\n",
      "Batch [120/313], Loss: 0.0140\n",
      "Batch [150/313], Loss: 0.0136\n",
      "Batch [180/313], Loss: 0.0131\n",
      "Batch [210/313], Loss: 0.0342\n",
      "Batch [240/313], Loss: 0.0092\n",
      "Batch [270/313], Loss: 0.0655\n",
      "Batch [300/313], Loss: 0.0136\n",
      "Epoch [1/20], Loss: 0.0128\n",
      "Validation loss decreased (0.013825 --> 0.012847).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████▉  | 19/20 [1:36:51<00:37, 37.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]   Loss: 1.8314   Accuracy: 65.00%\n",
      "Batch [30/313], Loss: 0.0085\n",
      "Batch [60/313], Loss: 0.0210\n",
      "Batch [90/313], Loss: 0.0065\n",
      "Batch [120/313], Loss: 0.0163\n",
      "Batch [150/313], Loss: 0.0084\n",
      "Batch [180/313], Loss: 0.0186\n",
      "Batch [210/313], Loss: 0.0091\n",
      "Batch [240/313], Loss: 0.0123\n",
      "Batch [270/313], Loss: 0.0245\n",
      "Batch [300/313], Loss: 0.0148\n",
      "Epoch [1/20], Loss: 0.0124\n",
      "Validation loss decreased (0.012847 --> 0.012449).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 20/20 [1:37:22<00:00, 292.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]   Loss: 1.8339   Accuracy: 65.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Per-Epoch Activity 코드\n",
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    # 모델 학습\n",
    "    train_model(net, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "    \n",
    "    # 테스트 평가\n",
    "    test_loss, test_accuracy = test_model(net, test_loader, criterion, epoch)\n",
    "    \n",
    "    # TensorBoard에 테스트 결과 기록\n",
    "    writer.add_scalar(\"Test Loss\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Test Accuracy\", test_accuracy, epoch)\n",
    "\n",
    "    # 현재 epoch 결과 출력\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}]   Loss: {test_loss:.4f}   Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# TensorBoard writer 닫기\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271219f-96f2-4967-939d-a24d6def8eb0",
   "metadata": {},
   "source": [
    "### **Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17f94ca2-f1e7-4452-b501-9b36e7025a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result of ResNet = Epoch : 20   Loss : 1.8338963832855224   Accuracy : 0.6506\n"
     ]
    }
   ],
   "source": [
    "print(f\" Result of ResNet = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb5d42f-9728-4e40-94eb-997ad195b5b2",
   "metadata": {},
   "source": [
    "# Test - 나영(Accuracy) 현욱(Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c59d485-f2bb-4dc0-85ac-55a5f7ef1289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000개 테스트 이미지에서 모델 정확도: 65 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('10000개 테스트 이미지에서 모델 정확도: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b41eb1-d372-4e64-b1d9-d2552ed44d99",
   "metadata": {},
   "source": [
    "**Visualization of average loss(수정 필요)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45250e0a-4741-4228-a62a-28b9733fd1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련과정에서 손실을 기록\n",
    "    train_loss = 0\n",
    "    total_samples = 0\n",
    "    net.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        total_samples += inputs.size(0)\n",
    "    \n",
    "    train_losses.append(train_loss / total_samples)\n",
    "\n",
    "    # 평가 과정에서 손실과 정확도를 기록\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_losses.append(test_loss / total)\n",
    "    test_accuracies.append(correct / total)\n",
    "\n",
    "# 손실과 정확도 그래프 그리기\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea3df5-03bd-4f43-8b2b-d251da3ea733",
   "metadata": {},
   "source": [
    "**Top-1 Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c32fbe81-49f4-431b-b1fd-e8bcb50d0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top1_accuracy(model, device, data_loader, criterion):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            # # 각 샘플에 대한 예측 결과와 실제 레이블 출력\n",
    "            # for i in range(data.size(0)):\n",
    "            #     print(f\"Sample {i + 1}: Predicted = {predicted[i].item()}, Actual = {target[i].item()}\")\n",
    "\n",
    "    top1_accuracy = 100 * correct / total\n",
    "    print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccb41004-213b-4b75-8c10-2741a33871d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 65.02%\n"
     ]
    }
   ],
   "source": [
    "calculate_top1_accuracy(net, device, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ece3fe-506f-4fda-86bd-b7f32112a23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b0993a9-bc4f-40e1-909c-c63d6c7dd36e",
   "metadata": {},
   "source": [
    "**Top-5 Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3ec995a-2515-488b-b266-3d566d9490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_print_top5_accuracy(model, device, data_loader, criterion):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            # Top-5 예측 결과 가져오기\n",
    "            _, predicted_top5 = torch.topk(outputs, 5, dim=1)\n",
    "            total += target.size(0)\n",
    "            \n",
    "            # 예측된 Top-5 내에 실제 레이블이 있는지 확인\n",
    "            correct += (predicted_top5 == target.view(-1, 1)).sum().item()\n",
    "\n",
    "    top5_accuracy = 100 * correct / total\n",
    "    print(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2761aaae-f57c-44e7-9b55-fc9959abdb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy: 87.88%\n"
     ]
    }
   ],
   "source": [
    "calculate_and_print_top5_accuracy(net, device, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503fa03-bac6-4758-a623-8cec95a40985",
   "metadata": {},
   "source": [
    "# Data Analysis - 현욱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1321873-e871-4ee1-883e-637fe9aa843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./runs/resnet_18/tensorboard --port=8202 --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce3873-fb7d-447b-9e9e-2c2c68a8320f",
   "metadata": {},
   "source": [
    "### **Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "459fcbfd-53ee-4489-a204-c366745ff4d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m      2\u001b[0m coarse_classes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maquatic mammals\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfish\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflowers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood containers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfruit and vegetables\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousehold electrical devices\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousehold furniture\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge carnivores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge man-made outdoor things\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge natural outdoor scenes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge omnivores and herbivores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium-sized mammals\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-insect invertebrates\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreptiles\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall mammals\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrees\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicles 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicles 2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "classes = train_data.classes\n",
    "coarse_classes = [\n",
    "    'aquatic mammals', 'fish', 'flowers', 'food containers', 'fruit and vegetables', 'household electrical devices', \n",
    "    'household furniture', 'insects', 'large carnivores', 'large man-made outdoor things', \n",
    "    'large natural outdoor scenes', 'large omnivores and herbivores', 'medium-sized mammals', \n",
    "    'non-insect invertebrates', 'people', 'reptiles', 'small mammals', 'trees', 'vehicles 1', 'vehicles 2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12998ea-5e92-47e9-8f07-5506b467b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(classes), len(coarse_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65824d7-6382-46c5-a654-ce9c579aaee2",
   "metadata": {},
   "source": [
    "##### **Fine_to_coarse_mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22925779-77ff-457d-bac1-1daa7f1746ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-100 세부 클래스(fine classes)와 상위 클래스(coarse classes) 매핑\n",
    "fine_to_coarse_mapping = {\n",
    "    # aquatic mammals\n",
    "    'beaver': 'aquatic mammals',\n",
    "    'dolphin': 'aquatic mammals',\n",
    "    'otter': 'aquatic mammals',\n",
    "    'seal': 'aquatic mammals',\n",
    "    'whale': 'aquatic mammals',\n",
    "    \n",
    "    # fish\n",
    "    'aquarium fish': 'fish',\n",
    "    'flatfish': 'fish',\n",
    "    'ray': 'fish',\n",
    "    'shark': 'fish',\n",
    "    'trout': 'fish',\n",
    "    \n",
    "    # flowers\n",
    "    'orchids': 'flowers',\n",
    "    'poppies': 'flowers',\n",
    "    'roses': 'flowers',\n",
    "    'sunflowers': 'flowers',\n",
    "    'tulips': 'flowers',\n",
    "    \n",
    "    # food containers\n",
    "    'bottles': 'food containers',\n",
    "    'bowls': 'food containers',\n",
    "    'cans': 'food containers',\n",
    "    'cups': 'food containers',\n",
    "    'plates': 'food containers',\n",
    "    \n",
    "    # fruit and vegetables\n",
    "    'apples': 'fruit and vegetables',\n",
    "    'mushrooms': 'fruit and vegetables',\n",
    "    'oranges': 'fruit and vegetables',\n",
    "    'pears': 'fruit and vegetables',\n",
    "    'sweet peppers': 'fruit and vegetables',\n",
    "    \n",
    "    # household electrical devices\n",
    "    'clock': 'household electrical devices',\n",
    "    'computer keyboard': 'household electrical devices',\n",
    "    'lamp': 'household electrical devices',\n",
    "    'telephone': 'household electrical devices',\n",
    "    'television': 'household electrical devices',\n",
    "    \n",
    "    # household furniture\n",
    "    'bed': 'household furniture',\n",
    "    'chair': 'household furniture',\n",
    "    'couch': 'household furniture',\n",
    "    'table': 'household furniture',\n",
    "    'wardrobe': 'household furniture',\n",
    "    \n",
    "    # insects\n",
    "    'bee': 'insects',\n",
    "    'beetle': 'insects',\n",
    "    'butterfly': 'insects',\n",
    "    'caterpillar': 'insects',\n",
    "    'cockroach': 'insects',\n",
    "    \n",
    "    # large carnivores\n",
    "    'bear': 'large carnivores',\n",
    "    'leopard': 'large carnivores',\n",
    "    'lion': 'large carnivores',\n",
    "    'tiger': 'large carnivores',\n",
    "    'wolf': 'large carnivores',\n",
    "    \n",
    "    # large man-made outdoor things\n",
    "    'bridge': 'large man-made outdoor things',\n",
    "    'castle': 'large man-made outdoor things',\n",
    "    'house': 'large man-made outdoor things',\n",
    "    'road': 'large man-made outdoor things',\n",
    "    'skyscraper': 'large man-made outdoor things',\n",
    "    \n",
    "    # large natural outdoor scenes\n",
    "    'cloud': 'large natural outdoor scenes',\n",
    "    'forest': 'large natural outdoor scenes',\n",
    "    'mountain': 'large natural outdoor scenes',\n",
    "    'plain': 'large natural outdoor scenes',\n",
    "    'sea': 'large natural outdoor scenes',\n",
    "    \n",
    "    # large omnivores and herbivores\n",
    "    'camel': 'large omnivores and herbivores',\n",
    "    'cattle': 'large omnivores and herbivores',\n",
    "    'chimpanzee': 'large omnivores and herbivores',\n",
    "    'elephant': 'large omnivores and herbivores',\n",
    "    'kangaroo': 'large omnivores and herbivores',\n",
    "    \n",
    "    # medium-sized mammals\n",
    "    'fox': 'medium-sized mammals',\n",
    "    'porcupine': 'medium-sized mammals',\n",
    "    'possum': 'medium-sized mammals',\n",
    "    'raccoon': 'medium-sized mammals',\n",
    "    'skunk': 'medium-sized mammals',\n",
    "    \n",
    "    # non-insect invertebrates\n",
    "    'crab': 'non-insect invertebrates',\n",
    "    'lobster': 'non-insect invertebrates',\n",
    "    'snail': 'non-insect invertebrates',\n",
    "    'spider': 'non-insect invertebrates',\n",
    "    'worm': 'non-insect invertebrates',\n",
    "    \n",
    "    # people\n",
    "    'baby': 'people',\n",
    "    'boy': 'people',\n",
    "    'girl': 'people',\n",
    "    'man': 'people',\n",
    "    'woman': 'people',\n",
    "    \n",
    "    # reptiles\n",
    "    'crocodile': 'reptiles',\n",
    "    'dinosaur': 'reptiles',\n",
    "    'lizard': 'reptiles',\n",
    "    'snake': 'reptiles',\n",
    "    'turtle': 'reptiles',\n",
    "    \n",
    "    # small mammals\n",
    "    'hamster': 'small mammals',\n",
    "    'mouse': 'small mammals',\n",
    "    'rabbit': 'small mammals',\n",
    "    'shrew': 'small mammals',\n",
    "    'squirrel': 'small mammals',\n",
    "    \n",
    "    # trees\n",
    "    'maple': 'trees',\n",
    "    'oak': 'trees',\n",
    "    'palm': 'trees',\n",
    "    'pine': 'trees',\n",
    "    'willow': 'trees',\n",
    "    \n",
    "    # vehicles 1\n",
    "    'bicycle': 'vehicles 1',\n",
    "    'bus': 'vehicles 1',\n",
    "    'motorcycle': 'vehicles 1',\n",
    "    'pickup truck': 'vehicles 1',\n",
    "    'train': 'vehicles 1',\n",
    "    \n",
    "    # vehicles 2\n",
    "    'lawn-mower': 'vehicles 2',\n",
    "    'rocket': 'vehicles 2',\n",
    "    'streetcar': 'vehicles 2',\n",
    "    'tank': 'vehicles 2',\n",
    "    'tractor': 'vehicles 2'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd13fc-9e00-4f14-8ce4-c568bf583a0b",
   "metadata": {},
   "source": [
    "### **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08932ed-cd47-4196-ae9c-187bd20f02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for x, y in torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size):\n",
    "    \n",
    "    #print('iter val', i)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    z = net(x)\n",
    "    _, yhat = torch.max(z, 1)\n",
    "    pred = yhat.data.cpu().numpy()\n",
    "    y_pred.extend(pred) # Save Prediction\n",
    "\n",
    "    labels = y.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (128,70))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('Confusion Matrix of ResNet (CIFAR100)')\n",
    "plt.savefig('./runs/resnet_18/Confusion_matrix_ResNet_Cifar100.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdc8f9-0c1e-4787-aaea-0f00e2fa18b3",
   "metadata": {},
   "source": [
    "### **Confusion Matrix - Coarse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773340a7-fea7-41e1-87cf-b57e6bb8a934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5be2bacf-9f08-4158-a1f5-388c2b93bd1b",
   "metadata": {},
   "source": [
    "### **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cb235-7bd0-429f-9a25-5bcf162d3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Classification Report of ResNet(CIFAR100)  \\n { classification_report(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ff632-9bd4-4ce6-9a3e-f4908b6c02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Classification Report as txt file \n",
    "with open(\"./runs/resnet_18/cr_ResNet18.txt\", \"w\") as text_file:\n",
    "    print(classification_report(y_true, y_pred, digits=4), file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06191708-b289-4ada-97c9-5d4d42eaf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Classification Report txt file \n",
    "with open(\"./runs/resnet_18/cr_ResNet18.txt\", \"r\") as f:\n",
    "  cr = f.read()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdae401-61f1-47fc-a281-fcc45a3be062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
