{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da55e5a3-cdd0-4b19-a405-6d25853d33f9",
   "metadata": {},
   "source": [
    "**Load Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83038a2e-883a-4da6-97bd-c5371f13c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from utility.early_stopping import EarlyStopping\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc13d1-90ff-4301-8dac-07977aaaddcf",
   "metadata": {},
   "source": [
    "**Seed Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8539ad-3c66-4c94-abb2-fcc33f97d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb9cd2-1723-4ab5-8dd9-6419f42ddf4f",
   "metadata": {},
   "source": [
    "**Device Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a29bcf9-99b3-4908-a05d-80f158d4de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957fbc7-d25b-4e3e-b201-b9e357d58826",
   "metadata": {},
   "source": [
    "**Set Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b910701-145a-408d-9309-37816c55b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04e253-49c0-4c37-8260-5e02f2c09452",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93758c0c-b1d2-4ab9-afb4-bdd60a04dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomCrop(32, padding=4), \n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ade0a7-66ce-48f4-96b0-f4719beaf090",
   "metadata": {},
   "source": [
    "**Splitting the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b4a6e5-9118-449a-bfb8-d05f9d339304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_val_data = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_val_transform)\n",
    "test_data = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c9ab44-2b89-4d17-b90d-f42d1e8fe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 train/val로 나누기\n",
    "num_train = len(train_val_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.2 * num_train))  # validation 데이터를 20%로 설정\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce676124-c073-4aec-a000-cb061ac3e10a",
   "metadata": {},
   "source": [
    "**Define Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824ddf7d-d749-456a-b717-e257489431b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_val_data, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "val_loader = DataLoader(train_val_data, batch_size=batch_size, sampler=val_sampler, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e300067-8688-4cb1-b34b-a9dcd504c860",
   "metadata": {},
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a58ae19-69f4-49a5-b704-d878caa5d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use: cuda:0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,728\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "            Conv2d-7         [-1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-8         [-1, 64, 224, 224]             128\n",
      "        BasicBlock-9         [-1, 64, 224, 224]               0\n",
      "           Conv2d-10         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-11         [-1, 64, 224, 224]             128\n",
      "             ReLU-12         [-1, 64, 224, 224]               0\n",
      "           Conv2d-13         [-1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-14         [-1, 64, 224, 224]             128\n",
      "       BasicBlock-15         [-1, 64, 224, 224]               0\n",
      "           Conv2d-16        [-1, 128, 112, 112]          73,728\n",
      "      BatchNorm2d-17        [-1, 128, 112, 112]             256\n",
      "             ReLU-18        [-1, 128, 112, 112]               0\n",
      "           Conv2d-19        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-20        [-1, 128, 112, 112]             256\n",
      "           Conv2d-21        [-1, 128, 112, 112]           8,192\n",
      "      BatchNorm2d-22        [-1, 128, 112, 112]             256\n",
      "       BasicBlock-23        [-1, 128, 112, 112]               0\n",
      "           Conv2d-24        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-25        [-1, 128, 112, 112]             256\n",
      "             ReLU-26        [-1, 128, 112, 112]               0\n",
      "           Conv2d-27        [-1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-28        [-1, 128, 112, 112]             256\n",
      "       BasicBlock-29        [-1, 128, 112, 112]               0\n",
      "           Conv2d-30          [-1, 256, 56, 56]         294,912\n",
      "      BatchNorm2d-31          [-1, 256, 56, 56]             512\n",
      "             ReLU-32          [-1, 256, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "           Conv2d-35          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "       BasicBlock-37          [-1, 256, 56, 56]               0\n",
      "           Conv2d-38          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 56, 56]             512\n",
      "             ReLU-40          [-1, 256, 56, 56]               0\n",
      "           Conv2d-41          [-1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-42          [-1, 256, 56, 56]             512\n",
      "       BasicBlock-43          [-1, 256, 56, 56]               0\n",
      "           Conv2d-44          [-1, 512, 28, 28]       1,179,648\n",
      "      BatchNorm2d-45          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-46          [-1, 512, 28, 28]               0\n",
      "           Conv2d-47          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-48          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "       BasicBlock-51          [-1, 512, 28, 28]               0\n",
      "           Conv2d-52          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-53          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-54          [-1, 512, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "       BasicBlock-57          [-1, 512, 28, 28]               0\n",
      "AdaptiveAvgPool2d-58            [-1, 512, 1, 1]               0\n",
      "           Linear-59                  [-1, 100]          51,300\n",
      "================================================================\n",
      "Total params: 11,220,132\n",
      "Trainable params: 11,220,132\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 667.63\n",
      "Params size (MB): 42.80\n",
      "Estimated Total Size (MB): 711.01\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from models import resnet\n",
    "\n",
    "print(\"use:\", device)\n",
    "\n",
    "# 모델 초기화\n",
    "# net = Net()\n",
    "net = resnet.resnet18()\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "net.to(device)\n",
    "\n",
    "print(summary(net, (3,224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4617a666-d3ad-4e82-b31f-419020476333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]}]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b49f37a-e104-42df-a9a6-6ba473a9881f",
   "metadata": {},
   "source": [
    "**Model Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "004a5573-52ba-4f9e-84e6-2a7d195f015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./runs/resnet_18/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7cf9f6-dd9a-45c2-b4cc-c4170b3a2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ba42f4-6da7-4f0c-983b-b8b82da34879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train_model(model, trainloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "            labels = labels.type(torch.LongTensor).to(device)  # CPU에서 long type tensor로 변환\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 역전파 및 최적화\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # 30번째 배치마다 상태 출력\n",
    "            if (batch_idx + 1) % 30 == 0:\n",
    "                print(f\"Batch [{batch_idx+1}/{len(trainloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Epoch당 평균 손실 계산 및 출력\n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping 체크\n",
    "        early_stopping(epoch_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9895f2f8-54c6-4882-ac5e-4a80611df282",
   "metadata": {},
   "source": [
    "**Model Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b995f7c8-7723-4053-83b6-2ae2336a9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 및 테스트 함수 (superclass 예측 포함)\n",
    "def test_model(model, testloader, criterion, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 모델 예측\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "\n",
    "            # 예측 결과 저장 및 정확도 계산\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == labels).sum().item()\n",
    "\n",
    "            # TensorBoard에 테스트 손실 및 정확도 기록\n",
    "            writer.add_scalar(\"Test Loss\", test_loss / len(testloader.dataset), epoch)\n",
    "            writer.add_scalar(\"Test Accuracy\", correct / len(testloader.dataset), epoch)\n",
    "\n",
    "    # 평균 손실 및 정확도 계산\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e2e73-edc7-4368-910e-e6a71133dd81",
   "metadata": {},
   "source": [
    "**Per-Epoch Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff6115a-12c7-4a72-94f1-661d4d620b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [30/313], Loss: 4.4863\n",
      "Batch [60/313], Loss: 4.3542\n",
      "Batch [90/313], Loss: 4.2681\n",
      "Batch [120/313], Loss: 4.1839\n",
      "Batch [150/313], Loss: 4.1910\n",
      "Batch [180/313], Loss: 4.1077\n",
      "Batch [210/313], Loss: 3.7774\n",
      "Batch [240/313], Loss: 3.9519\n",
      "Batch [270/313], Loss: 3.8174\n",
      "Batch [300/313], Loss: 3.9042\n",
      "Epoch [1/20], Loss: 3.2841\n",
      "Validation loss decreased (inf --> 3.284130).  Saving model ...\n",
      "Batch [30/313], Loss: 3.8484\n",
      "Batch [60/313], Loss: 3.8313\n",
      "Batch [90/313], Loss: 3.7540\n",
      "Batch [120/313], Loss: 3.5670\n",
      "Batch [150/313], Loss: 3.5606\n",
      "Batch [180/313], Loss: 3.7388\n",
      "Batch [210/313], Loss: 3.5672\n",
      "Batch [240/313], Loss: 3.4574\n",
      "Batch [270/313], Loss: 3.4971\n",
      "Batch [300/313], Loss: 3.3133\n",
      "Epoch [2/20], Loss: 2.8681\n",
      "Validation loss decreased (3.284130 --> 2.868148).  Saving model ...\n",
      "Batch [30/313], Loss: 3.4690\n",
      "Batch [60/313], Loss: 3.4504\n",
      "Batch [90/313], Loss: 3.1689\n",
      "Batch [120/313], Loss: 3.4471\n",
      "Batch [150/313], Loss: 3.5194\n",
      "Batch [180/313], Loss: 3.3565\n",
      "Batch [210/313], Loss: 3.0668\n",
      "Batch [240/313], Loss: 3.2763\n",
      "Batch [270/313], Loss: 3.3366\n",
      "Batch [300/313], Loss: 2.9579\n",
      "Epoch [3/20], Loss: 2.6373\n",
      "Validation loss decreased (2.868148 --> 2.637344).  Saving model ...\n",
      "Batch [30/313], Loss: 3.0055\n",
      "Batch [60/313], Loss: 3.0066\n",
      "Batch [90/313], Loss: 3.1666\n",
      "Batch [120/313], Loss: 3.0948\n",
      "Batch [150/313], Loss: 2.9105\n",
      "Batch [180/313], Loss: 2.9742\n",
      "Batch [210/313], Loss: 3.0045\n",
      "Batch [240/313], Loss: 2.8087\n",
      "Batch [270/313], Loss: 2.8408\n",
      "Batch [300/313], Loss: 2.9147\n",
      "Epoch [4/20], Loss: 2.4234\n",
      "Validation loss decreased (2.637344 --> 2.423419).  Saving model ...\n",
      "Batch [30/313], Loss: 2.9487\n",
      "Batch [60/313], Loss: 2.8925\n",
      "Batch [90/313], Loss: 2.6916\n",
      "Batch [120/313], Loss: 2.9119\n",
      "Batch [150/313], Loss: 3.0987\n",
      "Batch [180/313], Loss: 2.6829\n",
      "Batch [210/313], Loss: 2.8019\n",
      "Batch [240/313], Loss: 2.9166\n",
      "Batch [270/313], Loss: 2.6666\n",
      "Batch [300/313], Loss: 2.8376\n",
      "Epoch [5/20], Loss: 2.2446\n",
      "Validation loss decreased (2.423419 --> 2.244611).  Saving model ...\n",
      "Batch [30/313], Loss: 2.7262\n",
      "Batch [60/313], Loss: 2.7447\n",
      "Batch [90/313], Loss: 3.0144\n",
      "Batch [120/313], Loss: 2.7256\n",
      "Batch [150/313], Loss: 2.4738\n",
      "Batch [180/313], Loss: 2.6596\n",
      "Batch [210/313], Loss: 2.5379\n",
      "Batch [240/313], Loss: 2.5117\n",
      "Batch [270/313], Loss: 2.4200\n",
      "Batch [300/313], Loss: 2.6970\n",
      "Epoch [6/20], Loss: 2.0945\n",
      "Validation loss decreased (2.244611 --> 2.094502).  Saving model ...\n",
      "Batch [30/313], Loss: 2.4836\n",
      "Batch [60/313], Loss: 2.5063\n",
      "Batch [90/313], Loss: 2.5636\n",
      "Batch [120/313], Loss: 2.4422\n",
      "Batch [150/313], Loss: 2.4377\n",
      "Batch [180/313], Loss: 2.4439\n",
      "Batch [210/313], Loss: 2.4727\n",
      "Batch [240/313], Loss: 2.3599\n",
      "Batch [270/313], Loss: 2.5088\n",
      "Batch [300/313], Loss: 2.2089\n",
      "Epoch [7/20], Loss: 1.9674\n",
      "Validation loss decreased (2.094502 --> 1.967405).  Saving model ...\n",
      "Batch [30/313], Loss: 2.3564\n",
      "Batch [60/313], Loss: 2.1937\n",
      "Batch [90/313], Loss: 2.3586\n",
      "Batch [120/313], Loss: 2.4543\n",
      "Batch [150/313], Loss: 2.4195\n",
      "Batch [180/313], Loss: 2.2412\n",
      "Batch [210/313], Loss: 2.2365\n",
      "Batch [240/313], Loss: 2.2613\n",
      "Batch [270/313], Loss: 2.3457\n",
      "Batch [300/313], Loss: 2.4232\n",
      "Epoch [8/20], Loss: 1.8578\n",
      "Validation loss decreased (1.967405 --> 1.857753).  Saving model ...\n",
      "Batch [30/313], Loss: 2.3231\n",
      "Batch [60/313], Loss: 2.2729\n",
      "Batch [90/313], Loss: 2.2551\n",
      "Batch [120/313], Loss: 2.0745\n",
      "Batch [150/313], Loss: 1.8750\n",
      "Batch [180/313], Loss: 2.1523\n",
      "Batch [210/313], Loss: 2.1812\n",
      "Batch [240/313], Loss: 2.0293\n",
      "Batch [270/313], Loss: 2.2394\n",
      "Batch [300/313], Loss: 2.3334\n",
      "Epoch [9/20], Loss: 1.7546\n",
      "Validation loss decreased (1.857753 --> 1.754573).  Saving model ...\n",
      "Batch [30/313], Loss: 1.9577\n",
      "Batch [60/313], Loss: 2.0306\n",
      "Batch [90/313], Loss: 2.1494\n",
      "Batch [120/313], Loss: 2.0926\n",
      "Batch [150/313], Loss: 2.0253\n",
      "Batch [180/313], Loss: 1.7897\n",
      "Batch [210/313], Loss: 1.9973\n",
      "Batch [240/313], Loss: 1.9023\n",
      "Batch [270/313], Loss: 1.9815\n",
      "Batch [300/313], Loss: 2.0044\n",
      "Epoch [10/20], Loss: 1.6587\n",
      "Validation loss decreased (1.754573 --> 1.658741).  Saving model ...\n",
      "Batch [30/313], Loss: 2.1076\n",
      "Batch [60/313], Loss: 1.9344\n",
      "Batch [90/313], Loss: 2.0243\n",
      "Batch [120/313], Loss: 2.1350\n",
      "Batch [150/313], Loss: 1.9266\n",
      "Batch [180/313], Loss: 1.9733\n",
      "Batch [210/313], Loss: 2.0097\n",
      "Batch [240/313], Loss: 1.7069\n",
      "Batch [270/313], Loss: 1.8632\n",
      "Batch [300/313], Loss: 1.8604\n",
      "Epoch [11/20], Loss: 1.5818\n",
      "Validation loss decreased (1.658741 --> 1.581819).  Saving model ...\n",
      "Batch [30/313], Loss: 2.1479\n",
      "Batch [60/313], Loss: 1.9969\n",
      "Batch [90/313], Loss: 1.8086\n",
      "Batch [120/313], Loss: 1.9905\n",
      "Batch [150/313], Loss: 2.0273\n",
      "Batch [180/313], Loss: 1.8232\n",
      "Batch [210/313], Loss: 1.8674\n",
      "Batch [240/313], Loss: 2.1532\n",
      "Batch [270/313], Loss: 1.7319\n",
      "Batch [300/313], Loss: 1.7521\n",
      "Epoch [12/20], Loss: 1.5046\n",
      "Validation loss decreased (1.581819 --> 1.504556).  Saving model ...\n",
      "Batch [30/313], Loss: 1.7986\n",
      "Batch [60/313], Loss: 1.8657\n",
      "Batch [90/313], Loss: 1.8571\n",
      "Batch [120/313], Loss: 1.7886\n",
      "Batch [150/313], Loss: 1.7046\n",
      "Batch [180/313], Loss: 1.8050\n",
      "Batch [210/313], Loss: 1.8787\n",
      "Batch [240/313], Loss: 1.6792\n",
      "Batch [270/313], Loss: 1.7269\n",
      "Batch [300/313], Loss: 2.0408\n",
      "Epoch [13/20], Loss: 1.4315\n",
      "Validation loss decreased (1.504556 --> 1.431495).  Saving model ...\n",
      "Batch [30/313], Loss: 1.4915\n",
      "Batch [60/313], Loss: 1.8342\n",
      "Batch [90/313], Loss: 1.7659\n",
      "Batch [120/313], Loss: 1.7643\n",
      "Batch [150/313], Loss: 1.4321\n",
      "Batch [180/313], Loss: 1.5123\n",
      "Batch [210/313], Loss: 1.8805\n",
      "Batch [240/313], Loss: 1.5526\n",
      "Batch [270/313], Loss: 1.6847\n",
      "Batch [300/313], Loss: 1.8085\n",
      "Epoch [14/20], Loss: 1.3668\n",
      "Validation loss decreased (1.431495 --> 1.366798).  Saving model ...\n",
      "Batch [30/313], Loss: 1.9413\n",
      "Batch [60/313], Loss: 1.7191\n",
      "Batch [90/313], Loss: 1.7530\n",
      "Batch [120/313], Loss: 1.4503\n",
      "Batch [150/313], Loss: 1.7268\n",
      "Batch [180/313], Loss: 1.6709\n",
      "Batch [210/313], Loss: 1.8597\n",
      "Batch [240/313], Loss: 1.6909\n",
      "Batch [270/313], Loss: 1.7875\n",
      "Batch [300/313], Loss: 1.4229\n",
      "Epoch [15/20], Loss: 1.3099\n",
      "Validation loss decreased (1.366798 --> 1.309909).  Saving model ...\n",
      "Batch [30/313], Loss: 1.5124\n",
      "Batch [60/313], Loss: 1.4117\n",
      "Batch [90/313], Loss: 1.6438\n",
      "Batch [120/313], Loss: 1.4932\n",
      "Batch [150/313], Loss: 1.3273\n",
      "Batch [180/313], Loss: 1.5839\n",
      "Batch [210/313], Loss: 1.4187\n",
      "Batch [240/313], Loss: 1.3048\n",
      "Batch [270/313], Loss: 1.6220\n",
      "Batch [300/313], Loss: 1.5387\n",
      "Epoch [16/20], Loss: 1.2481\n",
      "Validation loss decreased (1.309909 --> 1.248054).  Saving model ...\n",
      "Batch [30/313], Loss: 1.7688\n",
      "Batch [60/313], Loss: 1.6166\n",
      "Batch [90/313], Loss: 1.6559\n",
      "Batch [120/313], Loss: 1.3788\n",
      "Batch [150/313], Loss: 1.4570\n",
      "Batch [180/313], Loss: 1.3568\n",
      "Batch [210/313], Loss: 1.4961\n",
      "Batch [240/313], Loss: 1.4607\n",
      "Batch [270/313], Loss: 1.5822\n",
      "Batch [300/313], Loss: 1.5276\n",
      "Epoch [17/20], Loss: 1.1969\n",
      "Validation loss decreased (1.248054 --> 1.196919).  Saving model ...\n",
      "Batch [30/313], Loss: 1.3009\n",
      "Batch [60/313], Loss: 1.4159\n",
      "Batch [90/313], Loss: 1.3534\n",
      "Batch [120/313], Loss: 1.3536\n",
      "Batch [150/313], Loss: 1.4137\n",
      "Batch [180/313], Loss: 1.6605\n",
      "Batch [210/313], Loss: 1.5064\n",
      "Batch [240/313], Loss: 1.2444\n",
      "Batch [270/313], Loss: 1.3590\n",
      "Batch [300/313], Loss: 1.3439\n",
      "Epoch [18/20], Loss: 1.1444\n",
      "Validation loss decreased (1.196919 --> 1.144428).  Saving model ...\n",
      "Batch [30/313], Loss: 1.2346\n",
      "Batch [60/313], Loss: 1.4192\n",
      "Batch [90/313], Loss: 1.2417\n",
      "Batch [120/313], Loss: 1.4871\n",
      "Batch [150/313], Loss: 1.4805\n",
      "Batch [180/313], Loss: 1.3207\n",
      "Batch [210/313], Loss: 1.2524\n",
      "Batch [240/313], Loss: 1.3846\n",
      "Batch [270/313], Loss: 1.2925\n",
      "Batch [300/313], Loss: 1.1868\n",
      "Epoch [19/20], Loss: 1.1002\n",
      "Validation loss decreased (1.144428 --> 1.100181).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0429\n",
      "Batch [60/313], Loss: 1.2312\n",
      "Batch [90/313], Loss: 1.3015\n",
      "Batch [120/313], Loss: 1.3054\n",
      "Batch [150/313], Loss: 1.2668\n",
      "Batch [180/313], Loss: 1.2946\n",
      "Batch [210/313], Loss: 1.4267\n",
      "Batch [240/313], Loss: 1.2623\n",
      "Batch [270/313], Loss: 1.2170\n",
      "Batch [300/313], Loss: 1.3781\n",
      "Epoch [20/20], Loss: 1.0538\n",
      "Validation loss decreased (1.100181 --> 1.053811).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                       | 1/20 [03:12<1:00:57, 192.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 1   Loss : 1.671552334022522   Accuracy : 0.5436\n",
      "Batch [30/313], Loss: 1.3281\n",
      "Batch [60/313], Loss: 1.2139\n",
      "Batch [90/313], Loss: 1.2368\n",
      "Batch [120/313], Loss: 1.0741\n",
      "Batch [150/313], Loss: 1.1371\n",
      "Batch [180/313], Loss: 1.5293\n",
      "Batch [210/313], Loss: 1.3238\n",
      "Batch [240/313], Loss: 0.9652\n",
      "Batch [270/313], Loss: 1.3251\n",
      "Batch [300/313], Loss: 1.3027\n",
      "Epoch [1/20], Loss: 1.0088\n",
      "Validation loss decreased (1.053811 --> 1.008788).  Saving model ...\n",
      "Batch [30/313], Loss: 1.1283\n",
      "Batch [60/313], Loss: 1.1368\n",
      "Batch [90/313], Loss: 1.0674\n",
      "Batch [120/313], Loss: 1.1415\n",
      "Batch [150/313], Loss: 1.1258\n",
      "Batch [180/313], Loss: 1.0599\n",
      "Batch [210/313], Loss: 1.2072\n",
      "Batch [240/313], Loss: 1.1885\n",
      "Batch [270/313], Loss: 1.1524\n",
      "Batch [300/313], Loss: 1.0471\n",
      "Epoch [2/20], Loss: 0.9680\n",
      "Validation loss decreased (1.008788 --> 0.967994).  Saving model ...\n",
      "Batch [30/313], Loss: 1.2256\n",
      "Batch [60/313], Loss: 1.1514\n",
      "Batch [90/313], Loss: 1.0114\n",
      "Batch [120/313], Loss: 1.2096\n",
      "Batch [150/313], Loss: 1.3804\n",
      "Batch [180/313], Loss: 1.2154\n",
      "Batch [210/313], Loss: 1.0890\n",
      "Batch [240/313], Loss: 1.0365\n",
      "Batch [270/313], Loss: 1.3546\n",
      "Batch [300/313], Loss: 1.1958\n",
      "Epoch [3/20], Loss: 0.9283\n",
      "Validation loss decreased (0.967994 --> 0.928341).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0122\n",
      "Batch [60/313], Loss: 1.1492\n",
      "Batch [90/313], Loss: 1.1576\n",
      "Batch [120/313], Loss: 1.0960\n",
      "Batch [150/313], Loss: 1.0660\n",
      "Batch [180/313], Loss: 1.1155\n",
      "Batch [210/313], Loss: 1.1947\n",
      "Batch [240/313], Loss: 1.2092\n",
      "Batch [270/313], Loss: 0.9989\n",
      "Batch [300/313], Loss: 1.1871\n",
      "Epoch [4/20], Loss: 0.8917\n",
      "Validation loss decreased (0.928341 --> 0.891658).  Saving model ...\n",
      "Batch [30/313], Loss: 1.0401\n",
      "Batch [60/313], Loss: 1.0740\n",
      "Batch [90/313], Loss: 0.8628\n",
      "Batch [120/313], Loss: 1.0402\n",
      "Batch [150/313], Loss: 1.1266\n",
      "Batch [180/313], Loss: 1.2157\n",
      "Batch [210/313], Loss: 1.1605\n",
      "Batch [240/313], Loss: 1.3202\n",
      "Batch [270/313], Loss: 0.9528\n",
      "Batch [300/313], Loss: 0.9697\n",
      "Epoch [5/20], Loss: 0.8579\n",
      "Validation loss decreased (0.891658 --> 0.857916).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8728\n",
      "Batch [60/313], Loss: 0.8384\n",
      "Batch [90/313], Loss: 0.9113\n",
      "Batch [120/313], Loss: 0.9516\n",
      "Batch [150/313], Loss: 1.0830\n",
      "Batch [180/313], Loss: 1.1061\n",
      "Batch [210/313], Loss: 1.1304\n",
      "Batch [240/313], Loss: 1.1263\n",
      "Batch [270/313], Loss: 0.9099\n",
      "Batch [300/313], Loss: 0.9922\n",
      "Epoch [6/20], Loss: 0.8216\n",
      "Validation loss decreased (0.857916 --> 0.821570).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8192\n",
      "Batch [60/313], Loss: 0.9165\n",
      "Batch [90/313], Loss: 1.0154\n",
      "Batch [120/313], Loss: 0.8623\n",
      "Batch [150/313], Loss: 0.8771\n",
      "Batch [180/313], Loss: 0.7882\n",
      "Batch [210/313], Loss: 0.9435\n",
      "Batch [240/313], Loss: 0.9899\n",
      "Batch [270/313], Loss: 1.0121\n",
      "Batch [300/313], Loss: 0.9742\n",
      "Epoch [7/20], Loss: 0.7874\n",
      "Validation loss decreased (0.821570 --> 0.787378).  Saving model ...\n",
      "Batch [30/313], Loss: 0.9532\n",
      "Batch [60/313], Loss: 0.8653\n",
      "Batch [90/313], Loss: 1.0884\n",
      "Batch [120/313], Loss: 0.8170\n",
      "Batch [150/313], Loss: 1.2393\n",
      "Batch [180/313], Loss: 0.9567\n",
      "Batch [210/313], Loss: 1.0459\n",
      "Batch [240/313], Loss: 1.0552\n",
      "Batch [270/313], Loss: 0.9460\n",
      "Batch [300/313], Loss: 1.1015\n",
      "Epoch [8/20], Loss: 0.7545\n",
      "Validation loss decreased (0.787378 --> 0.754524).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8716\n",
      "Batch [60/313], Loss: 0.9132\n",
      "Batch [90/313], Loss: 0.7481\n",
      "Batch [120/313], Loss: 0.8021\n",
      "Batch [150/313], Loss: 0.8481\n",
      "Batch [180/313], Loss: 0.9323\n",
      "Batch [210/313], Loss: 0.9312\n",
      "Batch [240/313], Loss: 0.8960\n",
      "Batch [270/313], Loss: 0.9322\n",
      "Batch [300/313], Loss: 0.8837\n",
      "Epoch [9/20], Loss: 0.7250\n",
      "Validation loss decreased (0.754524 --> 0.724956).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8787\n",
      "Batch [60/313], Loss: 0.8835\n",
      "Batch [90/313], Loss: 0.8752\n",
      "Batch [120/313], Loss: 0.8397\n",
      "Batch [150/313], Loss: 0.9744\n",
      "Batch [180/313], Loss: 0.8964\n",
      "Batch [210/313], Loss: 0.9240\n",
      "Batch [240/313], Loss: 0.9550\n",
      "Batch [270/313], Loss: 1.0308\n",
      "Batch [300/313], Loss: 0.7632\n",
      "Epoch [10/20], Loss: 0.6904\n",
      "Validation loss decreased (0.724956 --> 0.690405).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7780\n",
      "Batch [60/313], Loss: 0.7795\n",
      "Batch [90/313], Loss: 0.8324\n",
      "Batch [120/313], Loss: 0.7554\n",
      "Batch [150/313], Loss: 0.8726\n",
      "Batch [180/313], Loss: 0.9254\n",
      "Batch [210/313], Loss: 0.7381\n",
      "Batch [240/313], Loss: 0.8124\n",
      "Batch [270/313], Loss: 0.7361\n",
      "Batch [300/313], Loss: 0.9855\n",
      "Epoch [11/20], Loss: 0.6602\n",
      "Validation loss decreased (0.690405 --> 0.660228).  Saving model ...\n",
      "Batch [30/313], Loss: 0.8272\n",
      "Batch [60/313], Loss: 0.8796\n",
      "Batch [90/313], Loss: 0.7754\n",
      "Batch [120/313], Loss: 0.9531\n",
      "Batch [150/313], Loss: 0.6578\n",
      "Batch [180/313], Loss: 0.8937\n",
      "Batch [210/313], Loss: 0.7983\n",
      "Batch [240/313], Loss: 0.8565\n",
      "Batch [270/313], Loss: 0.7860\n",
      "Batch [300/313], Loss: 0.9365\n",
      "Epoch [12/20], Loss: 0.6323\n",
      "Validation loss decreased (0.660228 --> 0.632319).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7893\n",
      "Batch [60/313], Loss: 0.6667\n",
      "Batch [90/313], Loss: 0.7389\n",
      "Batch [120/313], Loss: 0.7055\n",
      "Batch [150/313], Loss: 0.7630\n",
      "Batch [180/313], Loss: 0.7606\n",
      "Batch [210/313], Loss: 0.6812\n",
      "Batch [240/313], Loss: 0.7534\n",
      "Batch [270/313], Loss: 0.7683\n",
      "Batch [300/313], Loss: 0.8525\n",
      "Epoch [13/20], Loss: 0.6071\n",
      "Validation loss decreased (0.632319 --> 0.607072).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7735\n",
      "Batch [60/313], Loss: 0.7601\n",
      "Batch [90/313], Loss: 0.6673\n",
      "Batch [120/313], Loss: 0.6754\n",
      "Batch [150/313], Loss: 0.7687\n",
      "Batch [180/313], Loss: 0.6813\n",
      "Batch [210/313], Loss: 0.7517\n",
      "Batch [240/313], Loss: 0.6958\n",
      "Batch [270/313], Loss: 0.8089\n",
      "Batch [300/313], Loss: 1.0045\n",
      "Epoch [14/20], Loss: 0.5821\n",
      "Validation loss decreased (0.607072 --> 0.582132).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5522\n",
      "Batch [60/313], Loss: 0.6053\n",
      "Batch [90/313], Loss: 0.6733\n",
      "Batch [120/313], Loss: 0.8212\n",
      "Batch [150/313], Loss: 0.6406\n",
      "Batch [180/313], Loss: 0.8810\n",
      "Batch [210/313], Loss: 0.7842\n",
      "Batch [240/313], Loss: 0.5373\n",
      "Batch [270/313], Loss: 0.7489\n",
      "Batch [300/313], Loss: 0.6384\n",
      "Epoch [15/20], Loss: 0.5525\n",
      "Validation loss decreased (0.582132 --> 0.552494).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5713\n",
      "Batch [60/313], Loss: 0.6646\n",
      "Batch [90/313], Loss: 0.7043\n",
      "Batch [120/313], Loss: 0.8257\n",
      "Batch [150/313], Loss: 0.6301\n",
      "Batch [180/313], Loss: 0.6443\n",
      "Batch [210/313], Loss: 0.6394\n",
      "Batch [240/313], Loss: 0.6994\n",
      "Batch [270/313], Loss: 0.6960\n",
      "Batch [300/313], Loss: 0.6874\n",
      "Epoch [16/20], Loss: 0.5251\n",
      "Validation loss decreased (0.552494 --> 0.525102).  Saving model ...\n",
      "Batch [30/313], Loss: 0.6375\n",
      "Batch [60/313], Loss: 0.7154\n",
      "Batch [90/313], Loss: 0.6793\n",
      "Batch [120/313], Loss: 0.6227\n",
      "Batch [150/313], Loss: 0.5863\n",
      "Batch [180/313], Loss: 0.7959\n",
      "Batch [210/313], Loss: 0.6297\n",
      "Batch [240/313], Loss: 0.7759\n",
      "Batch [270/313], Loss: 0.8105\n",
      "Batch [300/313], Loss: 0.5267\n",
      "Epoch [17/20], Loss: 0.5007\n",
      "Validation loss decreased (0.525102 --> 0.500704).  Saving model ...\n",
      "Batch [30/313], Loss: 0.5255\n",
      "Batch [60/313], Loss: 0.4660\n",
      "Batch [90/313], Loss: 0.5749\n",
      "Batch [120/313], Loss: 0.5095\n",
      "Batch [150/313], Loss: 0.6555\n",
      "Batch [180/313], Loss: 0.5944\n",
      "Batch [210/313], Loss: 0.6464\n",
      "Batch [240/313], Loss: 0.6693\n",
      "Batch [270/313], Loss: 0.6358\n",
      "Batch [300/313], Loss: 0.6121\n",
      "Epoch [18/20], Loss: 0.4818\n",
      "Validation loss decreased (0.500704 --> 0.481771).  Saving model ...\n",
      "Batch [30/313], Loss: 0.7490\n",
      "Batch [60/313], Loss: 0.5286\n",
      "Batch [90/313], Loss: 0.6008\n",
      "Batch [120/313], Loss: 0.6540\n",
      "Batch [150/313], Loss: 0.4849\n",
      "Batch [180/313], Loss: 0.5961\n",
      "Batch [210/313], Loss: 0.6324\n",
      "Batch [240/313], Loss: 0.7103\n",
      "Batch [270/313], Loss: 0.4759\n",
      "Batch [300/313], Loss: 0.5732\n",
      "Epoch [19/20], Loss: 0.4545\n",
      "Validation loss decreased (0.481771 --> 0.454462).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4688\n",
      "Batch [60/313], Loss: 0.5323\n",
      "Batch [90/313], Loss: 0.4372\n",
      "Batch [120/313], Loss: 0.5401\n",
      "Batch [150/313], Loss: 0.4940\n",
      "Batch [180/313], Loss: 0.5788\n",
      "Batch [210/313], Loss: 0.5477\n",
      "Batch [240/313], Loss: 0.4757\n",
      "Batch [270/313], Loss: 0.5227\n",
      "Batch [300/313], Loss: 0.6230\n",
      "Epoch [20/20], Loss: 0.4338\n",
      "Validation loss decreased (0.454462 --> 0.433822).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                     | 2/20 [06:49<1:02:00, 206.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 2   Loss : 1.5311786291122436   Accuracy : 0.6124\n",
      "Batch [30/313], Loss: 0.6210\n",
      "Batch [60/313], Loss: 0.4238\n",
      "Batch [90/313], Loss: 0.4567\n",
      "Batch [120/313], Loss: 0.5207\n",
      "Batch [150/313], Loss: 0.7208\n",
      "Batch [180/313], Loss: 0.4768\n",
      "Batch [210/313], Loss: 0.5087\n",
      "Batch [240/313], Loss: 0.5428\n",
      "Batch [270/313], Loss: 0.4595\n",
      "Batch [300/313], Loss: 0.4863\n",
      "Epoch [1/20], Loss: 0.4112\n",
      "Validation loss decreased (0.433822 --> 0.411212).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4103\n",
      "Batch [60/313], Loss: 0.3985\n",
      "Batch [90/313], Loss: 0.4712\n",
      "Batch [120/313], Loss: 0.5504\n",
      "Batch [150/313], Loss: 0.5881\n",
      "Batch [180/313], Loss: 0.4736\n",
      "Batch [210/313], Loss: 0.6061\n",
      "Batch [240/313], Loss: 0.4379\n",
      "Batch [270/313], Loss: 0.5698\n",
      "Batch [300/313], Loss: 0.5042\n",
      "Epoch [2/20], Loss: 0.3880\n",
      "Validation loss decreased (0.411212 --> 0.388030).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3722\n",
      "Batch [60/313], Loss: 0.4767\n",
      "Batch [90/313], Loss: 0.4236\n",
      "Batch [120/313], Loss: 0.4294\n",
      "Batch [150/313], Loss: 0.4358\n",
      "Batch [180/313], Loss: 0.4230\n",
      "Batch [210/313], Loss: 0.3273\n",
      "Batch [240/313], Loss: 0.5540\n",
      "Batch [270/313], Loss: 0.5968\n",
      "Batch [300/313], Loss: 0.6533\n",
      "Epoch [3/20], Loss: 0.3735\n",
      "Validation loss decreased (0.388030 --> 0.373462).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3334\n",
      "Batch [60/313], Loss: 0.3865\n",
      "Batch [90/313], Loss: 0.4545\n",
      "Batch [120/313], Loss: 0.3740\n",
      "Batch [150/313], Loss: 0.4557\n",
      "Batch [180/313], Loss: 0.4485\n",
      "Batch [210/313], Loss: 0.3772\n",
      "Batch [240/313], Loss: 0.4737\n",
      "Batch [270/313], Loss: 0.3699\n",
      "Batch [300/313], Loss: 0.5127\n",
      "Epoch [4/20], Loss: 0.3535\n",
      "Validation loss decreased (0.373462 --> 0.353497).  Saving model ...\n",
      "Batch [30/313], Loss: 0.4026\n",
      "Batch [60/313], Loss: 0.3419\n",
      "Batch [90/313], Loss: 0.4384\n",
      "Batch [120/313], Loss: 0.4040\n",
      "Batch [150/313], Loss: 0.3737\n",
      "Batch [180/313], Loss: 0.3741\n",
      "Batch [210/313], Loss: 0.3777\n",
      "Batch [240/313], Loss: 0.3900\n",
      "Batch [270/313], Loss: 0.4209\n",
      "Batch [300/313], Loss: 0.4420\n",
      "Epoch [5/20], Loss: 0.3275\n",
      "Validation loss decreased (0.353497 --> 0.327542).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3362\n",
      "Batch [60/313], Loss: 0.3841\n",
      "Batch [90/313], Loss: 0.4126\n",
      "Batch [120/313], Loss: 0.3242\n",
      "Batch [150/313], Loss: 0.3732\n",
      "Batch [180/313], Loss: 0.4468\n",
      "Batch [210/313], Loss: 0.3859\n",
      "Batch [240/313], Loss: 0.4318\n",
      "Batch [270/313], Loss: 0.3958\n",
      "Batch [300/313], Loss: 0.5367\n",
      "Epoch [6/20], Loss: 0.3168\n",
      "Validation loss decreased (0.327542 --> 0.316768).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3255\n",
      "Batch [60/313], Loss: 0.3728\n",
      "Batch [90/313], Loss: 0.3165\n",
      "Batch [120/313], Loss: 0.4672\n",
      "Batch [150/313], Loss: 0.4609\n",
      "Batch [180/313], Loss: 0.3718\n",
      "Batch [210/313], Loss: 0.3531\n",
      "Batch [240/313], Loss: 0.4030\n",
      "Batch [270/313], Loss: 0.3046\n",
      "Batch [300/313], Loss: 0.3768\n",
      "Epoch [7/20], Loss: 0.2958\n",
      "Validation loss decreased (0.316768 --> 0.295765).  Saving model ...\n",
      "Batch [30/313], Loss: 0.3432\n",
      "Batch [60/313], Loss: 0.1962\n",
      "Batch [90/313], Loss: 0.3018\n",
      "Batch [120/313], Loss: 0.4025\n",
      "Batch [150/313], Loss: 0.3321\n",
      "Batch [180/313], Loss: 0.4189\n",
      "Batch [210/313], Loss: 0.3144\n",
      "Batch [240/313], Loss: 0.3364\n",
      "Batch [270/313], Loss: 0.4952\n",
      "Batch [300/313], Loss: 0.4124\n",
      "Epoch [8/20], Loss: 0.2811\n",
      "Validation loss decreased (0.295765 --> 0.281112).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2481\n",
      "Batch [60/313], Loss: 0.3952\n",
      "Batch [90/313], Loss: 0.2763\n",
      "Batch [120/313], Loss: 0.2835\n",
      "Batch [150/313], Loss: 0.3011\n",
      "Batch [180/313], Loss: 0.3324\n",
      "Batch [210/313], Loss: 0.3890\n",
      "Batch [240/313], Loss: 0.3174\n",
      "Batch [270/313], Loss: 0.3625\n",
      "Batch [300/313], Loss: 0.4005\n",
      "Epoch [9/20], Loss: 0.2592\n",
      "Validation loss decreased (0.281112 --> 0.259228).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2297\n",
      "Batch [60/313], Loss: 0.2837\n",
      "Batch [90/313], Loss: 0.3305\n",
      "Batch [120/313], Loss: 0.3336\n",
      "Batch [150/313], Loss: 0.2870\n",
      "Batch [180/313], Loss: 0.3222\n",
      "Batch [210/313], Loss: 0.3949\n",
      "Batch [240/313], Loss: 0.2871\n",
      "Batch [270/313], Loss: 0.3045\n",
      "Batch [300/313], Loss: 0.2845\n",
      "Epoch [10/20], Loss: 0.2495\n",
      "Validation loss decreased (0.259228 --> 0.249518).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2961\n",
      "Batch [60/313], Loss: 0.2996\n",
      "Batch [90/313], Loss: 0.2421\n",
      "Batch [120/313], Loss: 0.2536\n",
      "Batch [150/313], Loss: 0.2911\n",
      "Batch [180/313], Loss: 0.3631\n",
      "Batch [210/313], Loss: 0.3184\n",
      "Batch [240/313], Loss: 0.2619\n",
      "Batch [270/313], Loss: 0.3220\n",
      "Batch [300/313], Loss: 0.2767\n",
      "Epoch [11/20], Loss: 0.2363\n",
      "Validation loss decreased (0.249518 --> 0.236326).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2793\n",
      "Batch [60/313], Loss: 0.2928\n",
      "Batch [90/313], Loss: 0.2690\n",
      "Batch [120/313], Loss: 0.2697\n",
      "Batch [150/313], Loss: 0.3024\n",
      "Batch [180/313], Loss: 0.2473\n",
      "Batch [210/313], Loss: 0.2896\n",
      "Batch [240/313], Loss: 0.2993\n",
      "Batch [270/313], Loss: 0.4741\n",
      "Batch [300/313], Loss: 0.2283\n",
      "Epoch [12/20], Loss: 0.2222\n",
      "Validation loss decreased (0.236326 --> 0.222223).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2129\n",
      "Batch [60/313], Loss: 0.2663\n",
      "Batch [90/313], Loss: 0.2147\n",
      "Batch [120/313], Loss: 0.2609\n",
      "Batch [150/313], Loss: 0.2547\n",
      "Batch [180/313], Loss: 0.2567\n",
      "Batch [210/313], Loss: 0.2117\n",
      "Batch [240/313], Loss: 0.2244\n",
      "Batch [270/313], Loss: 0.3474\n",
      "Batch [300/313], Loss: 0.3020\n",
      "Epoch [13/20], Loss: 0.2110\n",
      "Validation loss decreased (0.222223 --> 0.211006).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2740\n",
      "Batch [60/313], Loss: 0.2678\n",
      "Batch [90/313], Loss: 0.2596\n",
      "Batch [120/313], Loss: 0.1979\n",
      "Batch [150/313], Loss: 0.2736\n",
      "Batch [180/313], Loss: 0.2666\n",
      "Batch [210/313], Loss: 0.2091\n",
      "Batch [240/313], Loss: 0.2570\n",
      "Batch [270/313], Loss: 0.2455\n",
      "Batch [300/313], Loss: 0.2910\n",
      "Epoch [14/20], Loss: 0.1988\n",
      "Validation loss decreased (0.211006 --> 0.198819).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1970\n",
      "Batch [60/313], Loss: 0.2511\n",
      "Batch [90/313], Loss: 0.1304\n",
      "Batch [120/313], Loss: 0.2259\n",
      "Batch [150/313], Loss: 0.1724\n",
      "Batch [180/313], Loss: 0.3234\n",
      "Batch [210/313], Loss: 0.2586\n",
      "Batch [240/313], Loss: 0.1766\n",
      "Batch [270/313], Loss: 0.2204\n",
      "Batch [300/313], Loss: 0.2486\n",
      "Epoch [15/20], Loss: 0.1845\n",
      "Validation loss decreased (0.198819 --> 0.184500).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1318\n",
      "Batch [60/313], Loss: 0.2120\n",
      "Batch [90/313], Loss: 0.2192\n",
      "Batch [120/313], Loss: 0.1907\n",
      "Batch [150/313], Loss: 0.2361\n",
      "Batch [180/313], Loss: 0.1953\n",
      "Batch [210/313], Loss: 0.2162\n",
      "Batch [240/313], Loss: 0.2429\n",
      "Batch [270/313], Loss: 0.2532\n",
      "Batch [300/313], Loss: 0.2225\n",
      "Epoch [16/20], Loss: 0.1715\n",
      "Validation loss decreased (0.184500 --> 0.171518).  Saving model ...\n",
      "Batch [30/313], Loss: 0.2072\n",
      "Batch [60/313], Loss: 0.2181\n",
      "Batch [90/313], Loss: 0.1895\n",
      "Batch [120/313], Loss: 0.2204\n",
      "Batch [150/313], Loss: 0.1419\n",
      "Batch [180/313], Loss: 0.2085\n",
      "Batch [210/313], Loss: 0.1971\n",
      "Batch [240/313], Loss: 0.1663\n",
      "Batch [270/313], Loss: 0.1509\n",
      "Batch [300/313], Loss: 0.1953\n",
      "Epoch [17/20], Loss: 0.1622\n",
      "Validation loss decreased (0.171518 --> 0.162196).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1226\n",
      "Batch [60/313], Loss: 0.1869\n",
      "Batch [90/313], Loss: 0.2093\n",
      "Batch [120/313], Loss: 0.2506\n",
      "Batch [150/313], Loss: 0.1807\n",
      "Batch [180/313], Loss: 0.2214\n",
      "Batch [210/313], Loss: 0.2299\n",
      "Batch [240/313], Loss: 0.2275\n",
      "Batch [270/313], Loss: 0.1589\n",
      "Batch [300/313], Loss: 0.2006\n",
      "Epoch [18/20], Loss: 0.1583\n",
      "Validation loss decreased (0.162196 --> 0.158348).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1612\n",
      "Batch [60/313], Loss: 0.1739\n",
      "Batch [90/313], Loss: 0.1920\n",
      "Batch [120/313], Loss: 0.1366\n",
      "Batch [150/313], Loss: 0.1989\n",
      "Batch [180/313], Loss: 0.2912\n",
      "Batch [210/313], Loss: 0.2174\n",
      "Batch [240/313], Loss: 0.2011\n",
      "Batch [270/313], Loss: 0.1788\n",
      "Batch [300/313], Loss: 0.1962\n",
      "Epoch [19/20], Loss: 0.1481\n",
      "Validation loss decreased (0.158348 --> 0.148091).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1052\n",
      "Batch [60/313], Loss: 0.1880\n",
      "Batch [90/313], Loss: 0.1206\n",
      "Batch [120/313], Loss: 0.1693\n",
      "Batch [150/313], Loss: 0.1423\n",
      "Batch [180/313], Loss: 0.1799\n",
      "Batch [210/313], Loss: 0.1198\n",
      "Batch [240/313], Loss: 0.1587\n",
      "Batch [270/313], Loss: 0.1723\n",
      "Batch [300/313], Loss: 0.2299\n",
      "Epoch [20/20], Loss: 0.1346\n",
      "Validation loss decreased (0.148091 --> 0.134607).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████▏                                  | 3/20 [10:52<1:03:16, 223.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 3   Loss : 1.7094793077468873   Accuracy : 0.6236\n",
      "Batch [30/313], Loss: 0.1333\n",
      "Batch [60/313], Loss: 0.2545\n",
      "Batch [90/313], Loss: 0.1439\n",
      "Batch [120/313], Loss: 0.1751\n",
      "Batch [150/313], Loss: 0.1711\n",
      "Batch [180/313], Loss: 0.1421\n",
      "Batch [210/313], Loss: 0.1513\n",
      "Batch [240/313], Loss: 0.1297\n",
      "Batch [270/313], Loss: 0.2012\n",
      "Batch [300/313], Loss: 0.1482\n",
      "Epoch [1/20], Loss: 0.1270\n",
      "Validation loss decreased (0.134607 --> 0.127024).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1695\n",
      "Batch [60/313], Loss: 0.1119\n",
      "Batch [90/313], Loss: 0.0829\n",
      "Batch [120/313], Loss: 0.1368\n",
      "Batch [150/313], Loss: 0.1427\n",
      "Batch [180/313], Loss: 0.1150\n",
      "Batch [210/313], Loss: 0.1755\n",
      "Batch [240/313], Loss: 0.1238\n",
      "Batch [270/313], Loss: 0.1589\n",
      "Batch [300/313], Loss: 0.1478\n",
      "Epoch [2/20], Loss: 0.1185\n",
      "Validation loss decreased (0.127024 --> 0.118499).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1017\n",
      "Batch [60/313], Loss: 0.1124\n",
      "Batch [90/313], Loss: 0.1268\n",
      "Batch [120/313], Loss: 0.1169\n",
      "Batch [150/313], Loss: 0.1086\n",
      "Batch [180/313], Loss: 0.1255\n",
      "Batch [210/313], Loss: 0.1681\n",
      "Batch [240/313], Loss: 0.1222\n",
      "Batch [270/313], Loss: 0.2627\n",
      "Batch [300/313], Loss: 0.1617\n",
      "Epoch [3/20], Loss: 0.1101\n",
      "Validation loss decreased (0.118499 --> 0.110149).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1275\n",
      "Batch [60/313], Loss: 0.1323\n",
      "Batch [90/313], Loss: 0.1285\n",
      "Batch [120/313], Loss: 0.1413\n",
      "Batch [150/313], Loss: 0.1331\n",
      "Batch [180/313], Loss: 0.1590\n",
      "Batch [210/313], Loss: 0.1347\n",
      "Batch [240/313], Loss: 0.1758\n",
      "Batch [270/313], Loss: 0.1685\n",
      "Batch [300/313], Loss: 0.1552\n",
      "Epoch [4/20], Loss: 0.1092\n",
      "Validation loss decreased (0.110149 --> 0.109237).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1524\n",
      "Batch [60/313], Loss: 0.1054\n",
      "Batch [90/313], Loss: 0.2058\n",
      "Batch [120/313], Loss: 0.0969\n",
      "Batch [150/313], Loss: 0.1476\n",
      "Batch [180/313], Loss: 0.1254\n",
      "Batch [210/313], Loss: 0.1091\n",
      "Batch [240/313], Loss: 0.1261\n",
      "Batch [270/313], Loss: 0.1546\n",
      "Batch [300/313], Loss: 0.1363\n",
      "Epoch [5/20], Loss: 0.1032\n",
      "Validation loss decreased (0.109237 --> 0.103214).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0704\n",
      "Batch [60/313], Loss: 0.1223\n",
      "Batch [90/313], Loss: 0.1380\n",
      "Batch [120/313], Loss: 0.0925\n",
      "Batch [150/313], Loss: 0.1563\n",
      "Batch [180/313], Loss: 0.0792\n",
      "Batch [210/313], Loss: 0.1190\n",
      "Batch [240/313], Loss: 0.1606\n",
      "Batch [270/313], Loss: 0.1239\n",
      "Batch [300/313], Loss: 0.1349\n",
      "Epoch [6/20], Loss: 0.0968\n",
      "Validation loss decreased (0.103214 --> 0.096751).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1382\n",
      "Batch [60/313], Loss: 0.1147\n",
      "Batch [90/313], Loss: 0.1372\n",
      "Batch [120/313], Loss: 0.0987\n",
      "Batch [150/313], Loss: 0.0646\n",
      "Batch [180/313], Loss: 0.1175\n",
      "Batch [210/313], Loss: 0.1030\n",
      "Batch [240/313], Loss: 0.0881\n",
      "Batch [270/313], Loss: 0.0991\n",
      "Batch [300/313], Loss: 0.0680\n",
      "Epoch [7/20], Loss: 0.0906\n",
      "Validation loss decreased (0.096751 --> 0.090633).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0818\n",
      "Batch [60/313], Loss: 0.0842\n",
      "Batch [90/313], Loss: 0.0932\n",
      "Batch [120/313], Loss: 0.1097\n",
      "Batch [150/313], Loss: 0.1275\n",
      "Batch [180/313], Loss: 0.0831\n",
      "Batch [210/313], Loss: 0.0666\n",
      "Batch [240/313], Loss: 0.0811\n",
      "Batch [270/313], Loss: 0.1358\n",
      "Batch [300/313], Loss: 0.1231\n",
      "Epoch [8/20], Loss: 0.0851\n",
      "Validation loss decreased (0.090633 --> 0.085099).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1130\n",
      "Batch [60/313], Loss: 0.0815\n",
      "Batch [90/313], Loss: 0.0516\n",
      "Batch [120/313], Loss: 0.0766\n",
      "Batch [150/313], Loss: 0.0770\n",
      "Batch [180/313], Loss: 0.0950\n",
      "Batch [210/313], Loss: 0.1709\n",
      "Batch [240/313], Loss: 0.0549\n",
      "Batch [270/313], Loss: 0.1208\n",
      "Batch [300/313], Loss: 0.0992\n",
      "Epoch [9/20], Loss: 0.0786\n",
      "Validation loss decreased (0.085099 --> 0.078632).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0887\n",
      "Batch [60/313], Loss: 0.0982\n",
      "Batch [90/313], Loss: 0.1225\n",
      "Batch [120/313], Loss: 0.0737\n",
      "Batch [150/313], Loss: 0.0762\n",
      "Batch [180/313], Loss: 0.0825\n",
      "Batch [210/313], Loss: 0.0997\n",
      "Batch [240/313], Loss: 0.1100\n",
      "Batch [270/313], Loss: 0.1082\n",
      "Batch [300/313], Loss: 0.0674\n",
      "Epoch [10/20], Loss: 0.0731\n",
      "Validation loss decreased (0.078632 --> 0.073065).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1024\n",
      "Batch [60/313], Loss: 0.1179\n",
      "Batch [90/313], Loss: 0.0569\n",
      "Batch [120/313], Loss: 0.0885\n",
      "Batch [150/313], Loss: 0.1247\n",
      "Batch [180/313], Loss: 0.0748\n",
      "Batch [210/313], Loss: 0.0743\n",
      "Batch [240/313], Loss: 0.0675\n",
      "Batch [270/313], Loss: 0.1061\n",
      "Batch [300/313], Loss: 0.0866\n",
      "Epoch [11/20], Loss: 0.0724\n",
      "Validation loss decreased (0.073065 --> 0.072395).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0682\n",
      "Batch [60/313], Loss: 0.0908\n",
      "Batch [90/313], Loss: 0.0807\n",
      "Batch [120/313], Loss: 0.0767\n",
      "Batch [150/313], Loss: 0.0535\n",
      "Batch [180/313], Loss: 0.0750\n",
      "Batch [210/313], Loss: 0.0778\n",
      "Batch [240/313], Loss: 0.0906\n",
      "Batch [270/313], Loss: 0.1129\n",
      "Batch [300/313], Loss: 0.0950\n",
      "Epoch [12/20], Loss: 0.0666\n",
      "Validation loss decreased (0.072395 --> 0.066626).  Saving model ...\n",
      "Batch [30/313], Loss: 0.1149\n",
      "Batch [60/313], Loss: 0.1354\n",
      "Batch [90/313], Loss: 0.0627\n",
      "Batch [120/313], Loss: 0.0801\n",
      "Batch [150/313], Loss: 0.0657\n",
      "Batch [180/313], Loss: 0.0852\n",
      "Batch [210/313], Loss: 0.0602\n",
      "Batch [240/313], Loss: 0.0716\n",
      "Batch [270/313], Loss: 0.1004\n",
      "Batch [300/313], Loss: 0.0795\n",
      "Epoch [13/20], Loss: 0.0682\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0575\n",
      "Batch [60/313], Loss: 0.0416\n",
      "Batch [90/313], Loss: 0.1049\n",
      "Batch [120/313], Loss: 0.0331\n",
      "Batch [150/313], Loss: 0.0911\n",
      "Batch [180/313], Loss: 0.0733\n",
      "Batch [210/313], Loss: 0.0956\n",
      "Batch [240/313], Loss: 0.0964\n",
      "Batch [270/313], Loss: 0.0611\n",
      "Batch [300/313], Loss: 0.0915\n",
      "Epoch [14/20], Loss: 0.0610\n",
      "Validation loss decreased (0.066626 --> 0.060979).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0855\n",
      "Batch [60/313], Loss: 0.0857\n",
      "Batch [90/313], Loss: 0.1161\n",
      "Batch [120/313], Loss: 0.0499\n",
      "Batch [150/313], Loss: 0.0482\n",
      "Batch [180/313], Loss: 0.0742\n",
      "Batch [210/313], Loss: 0.0636\n",
      "Batch [240/313], Loss: 0.0709\n",
      "Batch [270/313], Loss: 0.0562\n",
      "Batch [300/313], Loss: 0.0741\n",
      "Epoch [15/20], Loss: 0.0630\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.1145\n",
      "Batch [60/313], Loss: 0.0702\n",
      "Batch [90/313], Loss: 0.0808\n",
      "Batch [120/313], Loss: 0.0334\n",
      "Batch [150/313], Loss: 0.0759\n",
      "Batch [180/313], Loss: 0.0437\n",
      "Batch [210/313], Loss: 0.0636\n",
      "Batch [240/313], Loss: 0.0752\n",
      "Batch [270/313], Loss: 0.0561\n",
      "Batch [300/313], Loss: 0.0638\n",
      "Epoch [16/20], Loss: 0.0587\n",
      "Validation loss decreased (0.060979 --> 0.058730).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0338\n",
      "Batch [60/313], Loss: 0.0651\n",
      "Batch [90/313], Loss: 0.0338\n",
      "Batch [120/313], Loss: 0.0761\n",
      "Batch [150/313], Loss: 0.0481\n",
      "Batch [180/313], Loss: 0.0818\n",
      "Batch [210/313], Loss: 0.0624\n",
      "Batch [240/313], Loss: 0.0556\n",
      "Batch [270/313], Loss: 0.0723\n",
      "Batch [300/313], Loss: 0.0569\n",
      "Epoch [17/20], Loss: 0.0517\n",
      "Validation loss decreased (0.058730 --> 0.051729).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0574\n",
      "Batch [60/313], Loss: 0.0663\n",
      "Batch [90/313], Loss: 0.0547\n",
      "Batch [120/313], Loss: 0.0502\n",
      "Batch [150/313], Loss: 0.0418\n",
      "Batch [180/313], Loss: 0.0487\n",
      "Batch [210/313], Loss: 0.0735\n",
      "Batch [240/313], Loss: 0.0627\n",
      "Batch [270/313], Loss: 0.0708\n",
      "Batch [300/313], Loss: 0.0660\n",
      "Epoch [18/20], Loss: 0.0516\n",
      "Validation loss decreased (0.051729 --> 0.051631).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0924\n",
      "Batch [60/313], Loss: 0.0871\n",
      "Batch [90/313], Loss: 0.0701\n",
      "Batch [120/313], Loss: 0.0725\n",
      "Batch [150/313], Loss: 0.0607\n",
      "Batch [180/313], Loss: 0.0566\n",
      "Batch [210/313], Loss: 0.0459\n",
      "Batch [240/313], Loss: 0.1114\n",
      "Batch [270/313], Loss: 0.0499\n",
      "Batch [300/313], Loss: 0.0834\n",
      "Epoch [19/20], Loss: 0.0508\n",
      "Validation loss decreased (0.051631 --> 0.050763).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0444\n",
      "Batch [60/313], Loss: 0.0527\n",
      "Batch [90/313], Loss: 0.0587\n",
      "Batch [120/313], Loss: 0.0473\n",
      "Batch [150/313], Loss: 0.0458\n",
      "Batch [180/313], Loss: 0.0657\n",
      "Batch [210/313], Loss: 0.0459\n",
      "Batch [240/313], Loss: 0.0806\n",
      "Batch [270/313], Loss: 0.0635\n",
      "Batch [300/313], Loss: 0.0752\n",
      "Epoch [20/20], Loss: 0.0494\n",
      "Validation loss decreased (0.050763 --> 0.049389).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▏                                | 4/20 [15:17<1:03:59, 240.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 4   Loss : 1.7359450660705567   Accuracy : 0.6454\n",
      "Batch [30/313], Loss: 0.0445\n",
      "Batch [60/313], Loss: 0.0627\n",
      "Batch [90/313], Loss: 0.0472\n",
      "Batch [120/313], Loss: 0.0360\n",
      "Batch [150/313], Loss: 0.0616\n",
      "Batch [180/313], Loss: 0.0575\n",
      "Batch [210/313], Loss: 0.0418\n",
      "Batch [240/313], Loss: 0.0555\n",
      "Batch [270/313], Loss: 0.0678\n",
      "Batch [300/313], Loss: 0.0444\n",
      "Epoch [1/20], Loss: 0.0431\n",
      "Validation loss decreased (0.049389 --> 0.043071).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0699\n",
      "Batch [60/313], Loss: 0.0601\n",
      "Batch [90/313], Loss: 0.0416\n",
      "Batch [120/313], Loss: 0.0438\n",
      "Batch [150/313], Loss: 0.0600\n",
      "Batch [180/313], Loss: 0.0512\n",
      "Batch [210/313], Loss: 0.0196\n",
      "Batch [240/313], Loss: 0.0393\n",
      "Batch [270/313], Loss: 0.0712\n",
      "Batch [300/313], Loss: 0.0579\n",
      "Epoch [2/20], Loss: 0.0405\n",
      "Validation loss decreased (0.043071 --> 0.040496).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0639\n",
      "Batch [60/313], Loss: 0.0271\n",
      "Batch [90/313], Loss: 0.0574\n",
      "Batch [120/313], Loss: 0.0268\n",
      "Batch [150/313], Loss: 0.0356\n",
      "Batch [180/313], Loss: 0.0444\n",
      "Batch [210/313], Loss: 0.0529\n",
      "Batch [240/313], Loss: 0.0604\n",
      "Batch [270/313], Loss: 0.0499\n",
      "Batch [300/313], Loss: 0.0351\n",
      "Epoch [3/20], Loss: 0.0423\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0273\n",
      "Batch [60/313], Loss: 0.0312\n",
      "Batch [90/313], Loss: 0.0421\n",
      "Batch [120/313], Loss: 0.0710\n",
      "Batch [150/313], Loss: 0.0733\n",
      "Batch [180/313], Loss: 0.0807\n",
      "Batch [210/313], Loss: 0.0513\n",
      "Batch [240/313], Loss: 0.0418\n",
      "Batch [270/313], Loss: 0.0412\n",
      "Batch [300/313], Loss: 0.0385\n",
      "Epoch [4/20], Loss: 0.0391\n",
      "Validation loss decreased (0.040496 --> 0.039120).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0296\n",
      "Batch [60/313], Loss: 0.0770\n",
      "Batch [90/313], Loss: 0.0508\n",
      "Batch [120/313], Loss: 0.0568\n",
      "Batch [150/313], Loss: 0.0625\n",
      "Batch [180/313], Loss: 0.0466\n",
      "Batch [210/313], Loss: 0.0451\n",
      "Batch [240/313], Loss: 0.0406\n",
      "Batch [270/313], Loss: 0.0430\n",
      "Batch [300/313], Loss: 0.0760\n",
      "Epoch [5/20], Loss: 0.0366\n",
      "Validation loss decreased (0.039120 --> 0.036641).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0256\n",
      "Batch [60/313], Loss: 0.0423\n",
      "Batch [90/313], Loss: 0.0637\n",
      "Batch [120/313], Loss: 0.0366\n",
      "Batch [150/313], Loss: 0.0258\n",
      "Batch [180/313], Loss: 0.0353\n",
      "Batch [210/313], Loss: 0.0365\n",
      "Batch [240/313], Loss: 0.0383\n",
      "Batch [270/313], Loss: 0.0395\n",
      "Batch [300/313], Loss: 0.0552\n",
      "Epoch [6/20], Loss: 0.0318\n",
      "Validation loss decreased (0.036641 --> 0.031839).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0392\n",
      "Batch [60/313], Loss: 0.0222\n",
      "Batch [90/313], Loss: 0.0316\n",
      "Batch [120/313], Loss: 0.0256\n",
      "Batch [150/313], Loss: 0.0516\n",
      "Batch [180/313], Loss: 0.0945\n",
      "Batch [210/313], Loss: 0.0470\n",
      "Batch [240/313], Loss: 0.0468\n",
      "Batch [270/313], Loss: 0.0493\n",
      "Batch [300/313], Loss: 0.0204\n",
      "Epoch [7/20], Loss: 0.0349\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0313\n",
      "Batch [60/313], Loss: 0.0666\n",
      "Batch [90/313], Loss: 0.0582\n",
      "Batch [120/313], Loss: 0.0406\n",
      "Batch [150/313], Loss: 0.0344\n",
      "Batch [180/313], Loss: 0.0366\n",
      "Batch [210/313], Loss: 0.0637\n",
      "Batch [240/313], Loss: 0.0601\n",
      "Batch [270/313], Loss: 0.0401\n",
      "Batch [300/313], Loss: 0.0719\n",
      "Epoch [8/20], Loss: 0.0405\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0440\n",
      "Batch [60/313], Loss: 0.0341\n",
      "Batch [90/313], Loss: 0.0257\n",
      "Batch [120/313], Loss: 0.0563\n",
      "Batch [150/313], Loss: 0.0575\n",
      "Batch [180/313], Loss: 0.0324\n",
      "Batch [210/313], Loss: 0.0271\n",
      "Batch [240/313], Loss: 0.0480\n",
      "Batch [270/313], Loss: 0.0638\n",
      "Batch [300/313], Loss: 0.0508\n",
      "Epoch [9/20], Loss: 0.0337\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0356\n",
      "Batch [60/313], Loss: 0.0266\n",
      "Batch [90/313], Loss: 0.0208\n",
      "Batch [120/313], Loss: 0.0291\n",
      "Batch [150/313], Loss: 0.0387\n",
      "Batch [180/313], Loss: 0.0416\n",
      "Batch [210/313], Loss: 0.0327\n",
      "Batch [240/313], Loss: 0.0357\n",
      "Batch [270/313], Loss: 0.0583\n",
      "Batch [300/313], Loss: 0.0413\n",
      "Epoch [10/20], Loss: 0.0302\n",
      "Validation loss decreased (0.031839 --> 0.030160).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0126\n",
      "Batch [60/313], Loss: 0.0212\n",
      "Batch [90/313], Loss: 0.0332\n",
      "Batch [120/313], Loss: 0.0307\n",
      "Batch [150/313], Loss: 0.0384\n",
      "Batch [180/313], Loss: 0.0210\n",
      "Batch [210/313], Loss: 0.0571\n",
      "Batch [240/313], Loss: 0.0211\n",
      "Batch [270/313], Loss: 0.0502\n",
      "Batch [300/313], Loss: 0.0300\n",
      "Epoch [11/20], Loss: 0.0305\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0232\n",
      "Batch [60/313], Loss: 0.0393\n",
      "Batch [90/313], Loss: 0.0243\n",
      "Batch [120/313], Loss: 0.0307\n",
      "Batch [150/313], Loss: 0.0368\n",
      "Batch [180/313], Loss: 0.0321\n",
      "Batch [210/313], Loss: 0.0719\n",
      "Batch [240/313], Loss: 0.0388\n",
      "Batch [270/313], Loss: 0.0729\n",
      "Batch [300/313], Loss: 0.0337\n",
      "Epoch [12/20], Loss: 0.0276\n",
      "Validation loss decreased (0.030160 --> 0.027619).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0274\n",
      "Batch [60/313], Loss: 0.0476\n",
      "Batch [90/313], Loss: 0.0740\n",
      "Batch [120/313], Loss: 0.0381\n",
      "Batch [150/313], Loss: 0.0356\n",
      "Batch [180/313], Loss: 0.0273\n",
      "Batch [210/313], Loss: 0.0281\n",
      "Batch [240/313], Loss: 0.0214\n",
      "Batch [270/313], Loss: 0.0377\n",
      "Batch [300/313], Loss: 0.0369\n",
      "Epoch [13/20], Loss: 0.0291\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0415\n",
      "Batch [60/313], Loss: 0.0178\n",
      "Batch [90/313], Loss: 0.0286\n",
      "Batch [120/313], Loss: 0.0337\n",
      "Batch [150/313], Loss: 0.0367\n",
      "Batch [180/313], Loss: 0.0215\n",
      "Batch [210/313], Loss: 0.0190\n",
      "Batch [240/313], Loss: 0.0614\n",
      "Batch [270/313], Loss: 0.0352\n",
      "Batch [300/313], Loss: 0.0243\n",
      "Epoch [14/20], Loss: 0.0276\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0197\n",
      "Batch [60/313], Loss: 0.0378\n",
      "Batch [90/313], Loss: 0.0363\n",
      "Batch [120/313], Loss: 0.0573\n",
      "Batch [150/313], Loss: 0.0333\n",
      "Batch [180/313], Loss: 0.0199\n",
      "Batch [210/313], Loss: 0.0232\n",
      "Batch [240/313], Loss: 0.0505\n",
      "Batch [270/313], Loss: 0.0476\n",
      "Batch [300/313], Loss: 0.0319\n",
      "Epoch [15/20], Loss: 0.0254\n",
      "Validation loss decreased (0.027619 --> 0.025355).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0233\n",
      "Batch [60/313], Loss: 0.0337\n",
      "Batch [90/313], Loss: 0.0446\n",
      "Batch [120/313], Loss: 0.0140\n",
      "Batch [150/313], Loss: 0.0238\n",
      "Batch [180/313], Loss: 0.0430\n",
      "Batch [210/313], Loss: 0.0489\n",
      "Batch [240/313], Loss: 0.0302\n",
      "Batch [270/313], Loss: 0.0354\n",
      "Batch [300/313], Loss: 0.0206\n",
      "Epoch [16/20], Loss: 0.0246\n",
      "Validation loss decreased (0.025355 --> 0.024616).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0251\n",
      "Batch [60/313], Loss: 0.0261\n",
      "Batch [90/313], Loss: 0.0236\n",
      "Batch [120/313], Loss: 0.0310\n",
      "Batch [150/313], Loss: 0.0364\n",
      "Batch [180/313], Loss: 0.0268\n",
      "Batch [210/313], Loss: 0.0150\n",
      "Batch [240/313], Loss: 0.0446\n",
      "Batch [270/313], Loss: 0.0489\n",
      "Batch [300/313], Loss: 0.0203\n",
      "Epoch [17/20], Loss: 0.0235\n",
      "Validation loss decreased (0.024616 --> 0.023549).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0281\n",
      "Batch [60/313], Loss: 0.0455\n",
      "Batch [90/313], Loss: 0.0350\n",
      "Batch [120/313], Loss: 0.0317\n",
      "Batch [150/313], Loss: 0.0360\n",
      "Batch [180/313], Loss: 0.0194\n",
      "Batch [210/313], Loss: 0.0248\n",
      "Batch [240/313], Loss: 0.0375\n",
      "Batch [270/313], Loss: 0.0309\n",
      "Batch [300/313], Loss: 0.0276\n",
      "Epoch [18/20], Loss: 0.0217\n",
      "Validation loss decreased (0.023549 --> 0.021701).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0163\n",
      "Batch [60/313], Loss: 0.0217\n",
      "Batch [90/313], Loss: 0.0151\n",
      "Batch [120/313], Loss: 0.0112\n",
      "Batch [150/313], Loss: 0.0300\n",
      "Batch [180/313], Loss: 0.0382\n",
      "Batch [210/313], Loss: 0.0131\n",
      "Batch [240/313], Loss: 0.0121\n",
      "Batch [270/313], Loss: 0.0313\n",
      "Batch [300/313], Loss: 0.0456\n",
      "Epoch [19/20], Loss: 0.0218\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0268\n",
      "Batch [60/313], Loss: 0.0294\n",
      "Batch [90/313], Loss: 0.0237\n",
      "Batch [120/313], Loss: 0.0281\n",
      "Batch [150/313], Loss: 0.0259\n",
      "Batch [180/313], Loss: 0.0184\n",
      "Batch [210/313], Loss: 0.0183\n",
      "Batch [240/313], Loss: 0.0211\n",
      "Batch [270/313], Loss: 0.0157\n",
      "Batch [300/313], Loss: 0.0274\n",
      "Epoch [20/20], Loss: 0.0214\n",
      "Validation loss decreased (0.021701 --> 0.021395).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████▎                              | 5/20 [19:50<1:02:55, 251.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 5   Loss : 1.797564345741272   Accuracy : 0.6521\n",
      "Batch [30/313], Loss: 0.0161\n",
      "Batch [60/313], Loss: 0.0226\n",
      "Batch [90/313], Loss: 0.0261\n",
      "Batch [120/313], Loss: 0.0205\n",
      "Batch [150/313], Loss: 0.0235\n",
      "Batch [180/313], Loss: 0.0366\n",
      "Batch [210/313], Loss: 0.0226\n",
      "Batch [240/313], Loss: 0.0366\n",
      "Batch [270/313], Loss: 0.0227\n",
      "Batch [300/313], Loss: 0.0227\n",
      "Epoch [1/20], Loss: 0.0191\n",
      "Validation loss decreased (0.021395 --> 0.019082).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0285\n",
      "Batch [60/313], Loss: 0.0430\n",
      "Batch [90/313], Loss: 0.0193\n",
      "Batch [120/313], Loss: 0.0230\n",
      "Batch [150/313], Loss: 0.0511\n",
      "Batch [180/313], Loss: 0.0403\n",
      "Batch [210/313], Loss: 0.0168\n",
      "Batch [240/313], Loss: 0.0225\n",
      "Batch [270/313], Loss: 0.0176\n",
      "Batch [300/313], Loss: 0.0392\n",
      "Epoch [2/20], Loss: 0.0190\n",
      "Validation loss decreased (0.019082 --> 0.018955).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0163\n",
      "Batch [60/313], Loss: 0.0260\n",
      "Batch [90/313], Loss: 0.0238\n",
      "Batch [120/313], Loss: 0.0193\n",
      "Batch [150/313], Loss: 0.0141\n",
      "Batch [180/313], Loss: 0.0231\n",
      "Batch [210/313], Loss: 0.0259\n",
      "Batch [240/313], Loss: 0.0193\n",
      "Batch [270/313], Loss: 0.0152\n",
      "Batch [300/313], Loss: 0.0146\n",
      "Epoch [3/20], Loss: 0.0197\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0129\n",
      "Batch [60/313], Loss: 0.0392\n",
      "Batch [90/313], Loss: 0.0096\n",
      "Batch [120/313], Loss: 0.0248\n",
      "Batch [150/313], Loss: 0.0171\n",
      "Batch [180/313], Loss: 0.0148\n",
      "Batch [210/313], Loss: 0.0155\n",
      "Batch [240/313], Loss: 0.0311\n",
      "Batch [270/313], Loss: 0.0305\n",
      "Batch [300/313], Loss: 0.0430\n",
      "Epoch [4/20], Loss: 0.0164\n",
      "Validation loss decreased (0.018955 --> 0.016355).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0139\n",
      "Batch [60/313], Loss: 0.0293\n",
      "Batch [90/313], Loss: 0.0162\n",
      "Batch [120/313], Loss: 0.0156\n",
      "Batch [150/313], Loss: 0.0331\n",
      "Batch [180/313], Loss: 0.0138\n",
      "Batch [210/313], Loss: 0.0215\n",
      "Batch [240/313], Loss: 0.0161\n",
      "Batch [270/313], Loss: 0.0122\n",
      "Batch [300/313], Loss: 0.0586\n",
      "Epoch [5/20], Loss: 0.0177\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0203\n",
      "Batch [60/313], Loss: 0.0160\n",
      "Batch [90/313], Loss: 0.0463\n",
      "Batch [120/313], Loss: 0.0221\n",
      "Batch [150/313], Loss: 0.0146\n",
      "Batch [180/313], Loss: 0.0213\n",
      "Batch [210/313], Loss: 0.0135\n",
      "Batch [240/313], Loss: 0.0177\n",
      "Batch [270/313], Loss: 0.0146\n",
      "Batch [300/313], Loss: 0.0190\n",
      "Epoch [6/20], Loss: 0.0168\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0208\n",
      "Batch [60/313], Loss: 0.0202\n",
      "Batch [90/313], Loss: 0.0185\n",
      "Batch [120/313], Loss: 0.0548\n",
      "Batch [150/313], Loss: 0.0177\n",
      "Batch [180/313], Loss: 0.0138\n",
      "Batch [210/313], Loss: 0.0218\n",
      "Batch [240/313], Loss: 0.0314\n",
      "Batch [270/313], Loss: 0.0272\n",
      "Batch [300/313], Loss: 0.0259\n",
      "Epoch [7/20], Loss: 0.0170\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0206\n",
      "Batch [60/313], Loss: 0.0119\n",
      "Batch [90/313], Loss: 0.0243\n",
      "Batch [120/313], Loss: 0.0129\n",
      "Batch [150/313], Loss: 0.0236\n",
      "Batch [180/313], Loss: 0.0137\n",
      "Batch [210/313], Loss: 0.0238\n",
      "Batch [240/313], Loss: 0.0133\n",
      "Batch [270/313], Loss: 0.0238\n",
      "Batch [300/313], Loss: 0.0157\n",
      "Epoch [8/20], Loss: 0.0166\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Batch [30/313], Loss: 0.0189\n",
      "Batch [60/313], Loss: 0.0099\n",
      "Batch [90/313], Loss: 0.0115\n",
      "Batch [120/313], Loss: 0.0153\n",
      "Batch [150/313], Loss: 0.0187\n",
      "Batch [180/313], Loss: 0.0157\n",
      "Batch [210/313], Loss: 0.0181\n",
      "Batch [240/313], Loss: 0.0126\n",
      "Batch [270/313], Loss: 0.0257\n",
      "Batch [300/313], Loss: 0.0119\n",
      "Epoch [9/20], Loss: 0.0163\n",
      "Validation loss decreased (0.016355 --> 0.016319).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0265\n",
      "Batch [60/313], Loss: 0.0180\n",
      "Batch [90/313], Loss: 0.0196\n",
      "Batch [120/313], Loss: 0.0190\n",
      "Batch [150/313], Loss: 0.0164\n",
      "Batch [180/313], Loss: 0.0151\n",
      "Batch [210/313], Loss: 0.0204\n",
      "Batch [240/313], Loss: 0.0225\n",
      "Batch [270/313], Loss: 0.0106\n",
      "Batch [300/313], Loss: 0.0222\n",
      "Epoch [10/20], Loss: 0.0162\n",
      "Validation loss decreased (0.016319 --> 0.016184).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0134\n",
      "Batch [60/313], Loss: 0.0173\n",
      "Batch [90/313], Loss: 0.0131\n",
      "Batch [120/313], Loss: 0.0231\n",
      "Batch [150/313], Loss: 0.0151\n",
      "Batch [180/313], Loss: 0.0201\n",
      "Batch [210/313], Loss: 0.0121\n",
      "Batch [240/313], Loss: 0.0124\n",
      "Batch [270/313], Loss: 0.0283\n",
      "Batch [300/313], Loss: 0.0127\n",
      "Epoch [11/20], Loss: 0.0145\n",
      "Validation loss decreased (0.016184 --> 0.014493).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0212\n",
      "Batch [60/313], Loss: 0.0113\n",
      "Batch [90/313], Loss: 0.0150\n",
      "Batch [120/313], Loss: 0.0098\n",
      "Batch [150/313], Loss: 0.0184\n",
      "Batch [180/313], Loss: 0.0252\n",
      "Batch [210/313], Loss: 0.0105\n",
      "Batch [240/313], Loss: 0.0168\n",
      "Batch [270/313], Loss: 0.0138\n",
      "Batch [300/313], Loss: 0.0112\n",
      "Epoch [12/20], Loss: 0.0135\n",
      "Validation loss decreased (0.014493 --> 0.013523).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0117\n",
      "Batch [60/313], Loss: 0.0169\n",
      "Batch [90/313], Loss: 0.0109\n",
      "Batch [120/313], Loss: 0.0214\n",
      "Batch [150/313], Loss: 0.0121\n",
      "Batch [180/313], Loss: 0.0205\n",
      "Batch [210/313], Loss: 0.0121\n",
      "Batch [240/313], Loss: 0.0144\n",
      "Batch [270/313], Loss: 0.0113\n",
      "Batch [300/313], Loss: 0.0128\n",
      "Epoch [13/20], Loss: 0.0140\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0176\n",
      "Batch [60/313], Loss: 0.0116\n",
      "Batch [90/313], Loss: 0.0132\n",
      "Batch [120/313], Loss: 0.0394\n",
      "Batch [150/313], Loss: 0.0131\n",
      "Batch [180/313], Loss: 0.0164\n",
      "Batch [210/313], Loss: 0.0255\n",
      "Batch [240/313], Loss: 0.0123\n",
      "Batch [270/313], Loss: 0.0369\n",
      "Batch [300/313], Loss: 0.0082\n",
      "Epoch [14/20], Loss: 0.0141\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0274\n",
      "Batch [60/313], Loss: 0.0104\n",
      "Batch [90/313], Loss: 0.0128\n",
      "Batch [120/313], Loss: 0.0457\n",
      "Batch [150/313], Loss: 0.0170\n",
      "Batch [180/313], Loss: 0.0176\n",
      "Batch [210/313], Loss: 0.0350\n",
      "Batch [240/313], Loss: 0.0183\n",
      "Batch [270/313], Loss: 0.0130\n",
      "Batch [300/313], Loss: 0.0261\n",
      "Epoch [15/20], Loss: 0.0135\n",
      "Validation loss decreased (0.013523 --> 0.013487).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0191\n",
      "Batch [60/313], Loss: 0.0195\n",
      "Batch [90/313], Loss: 0.0149\n",
      "Batch [120/313], Loss: 0.0385\n",
      "Batch [150/313], Loss: 0.0156\n",
      "Batch [180/313], Loss: 0.0107\n",
      "Batch [210/313], Loss: 0.0168\n",
      "Batch [240/313], Loss: 0.0169\n",
      "Batch [270/313], Loss: 0.0237\n",
      "Batch [300/313], Loss: 0.0214\n",
      "Epoch [16/20], Loss: 0.0158\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0124\n",
      "Batch [60/313], Loss: 0.0104\n",
      "Batch [90/313], Loss: 0.0096\n",
      "Batch [120/313], Loss: 0.0155\n",
      "Batch [150/313], Loss: 0.0220\n",
      "Batch [180/313], Loss: 0.0128\n",
      "Batch [210/313], Loss: 0.0077\n",
      "Batch [240/313], Loss: 0.0179\n",
      "Batch [270/313], Loss: 0.0103\n",
      "Batch [300/313], Loss: 0.0162\n",
      "Epoch [17/20], Loss: 0.0132\n",
      "Validation loss decreased (0.013487 --> 0.013186).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0171\n",
      "Batch [60/313], Loss: 0.0122\n",
      "Batch [90/313], Loss: 0.0131\n",
      "Batch [120/313], Loss: 0.0157\n",
      "Batch [150/313], Loss: 0.0272\n",
      "Batch [180/313], Loss: 0.0109\n",
      "Batch [210/313], Loss: 0.0150\n",
      "Batch [240/313], Loss: 0.0111\n",
      "Batch [270/313], Loss: 0.0219\n",
      "Batch [300/313], Loss: 0.0137\n",
      "Epoch [18/20], Loss: 0.0129\n",
      "Validation loss decreased (0.013186 --> 0.012867).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0123\n",
      "Batch [60/313], Loss: 0.0195\n",
      "Batch [90/313], Loss: 0.0111\n",
      "Batch [120/313], Loss: 0.0097\n",
      "Batch [150/313], Loss: 0.0095\n",
      "Batch [180/313], Loss: 0.0093\n",
      "Batch [210/313], Loss: 0.0261\n",
      "Batch [240/313], Loss: 0.0092\n",
      "Batch [270/313], Loss: 0.0157\n",
      "Batch [300/313], Loss: 0.0324\n",
      "Epoch [19/20], Loss: 0.0138\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0103\n",
      "Batch [60/313], Loss: 0.0243\n",
      "Batch [90/313], Loss: 0.0076\n",
      "Batch [120/313], Loss: 0.0248\n",
      "Batch [150/313], Loss: 0.0190\n",
      "Batch [180/313], Loss: 0.0507\n",
      "Batch [210/313], Loss: 0.0534\n",
      "Batch [240/313], Loss: 0.0181\n",
      "Batch [270/313], Loss: 0.0272\n",
      "Batch [300/313], Loss: 0.0227\n",
      "Epoch [20/20], Loss: 0.0141\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▎                            | 6/20 [24:22<1:00:19, 258.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 6   Loss : 1.8667784387588502   Accuracy : 0.654\n",
      "Batch [30/313], Loss: 0.0118\n",
      "Batch [60/313], Loss: 0.0172\n",
      "Batch [90/313], Loss: 0.0145\n",
      "Batch [120/313], Loss: 0.0089\n",
      "Batch [150/313], Loss: 0.0275\n",
      "Batch [180/313], Loss: 0.0141\n",
      "Batch [210/313], Loss: 0.0104\n",
      "Batch [240/313], Loss: 0.0092\n",
      "Batch [270/313], Loss: 0.0288\n",
      "Batch [300/313], Loss: 0.0139\n",
      "Epoch [1/20], Loss: 0.0143\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0298\n",
      "Batch [60/313], Loss: 0.0278\n",
      "Batch [90/313], Loss: 0.0083\n",
      "Batch [120/313], Loss: 0.0133\n",
      "Batch [150/313], Loss: 0.0101\n",
      "Batch [180/313], Loss: 0.0114\n",
      "Batch [210/313], Loss: 0.0123\n",
      "Batch [240/313], Loss: 0.0130\n",
      "Batch [270/313], Loss: 0.0176\n",
      "Batch [300/313], Loss: 0.0236\n",
      "Epoch [2/20], Loss: 0.0121\n",
      "Validation loss decreased (0.012867 --> 0.012144).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0151\n",
      "Batch [60/313], Loss: 0.0113\n",
      "Batch [90/313], Loss: 0.0265\n",
      "Batch [120/313], Loss: 0.0122\n",
      "Batch [150/313], Loss: 0.0106\n",
      "Batch [180/313], Loss: 0.0119\n",
      "Batch [210/313], Loss: 0.0115\n",
      "Batch [240/313], Loss: 0.0063\n",
      "Batch [270/313], Loss: 0.0175\n",
      "Batch [300/313], Loss: 0.0107\n",
      "Epoch [3/20], Loss: 0.0113\n",
      "Validation loss decreased (0.012144 --> 0.011312).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0281\n",
      "Batch [60/313], Loss: 0.0255\n",
      "Batch [90/313], Loss: 0.0180\n",
      "Batch [120/313], Loss: 0.0117\n",
      "Batch [150/313], Loss: 0.0091\n",
      "Batch [180/313], Loss: 0.0098\n",
      "Batch [210/313], Loss: 0.0044\n",
      "Batch [240/313], Loss: 0.0118\n",
      "Batch [270/313], Loss: 0.0161\n",
      "Batch [300/313], Loss: 0.0072\n",
      "Epoch [4/20], Loss: 0.0113\n",
      "Validation loss decreased (0.011312 --> 0.011266).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0077\n",
      "Batch [60/313], Loss: 0.0169\n",
      "Batch [90/313], Loss: 0.0099\n",
      "Batch [120/313], Loss: 0.0179\n",
      "Batch [150/313], Loss: 0.0171\n",
      "Batch [180/313], Loss: 0.0100\n",
      "Batch [210/313], Loss: 0.0108\n",
      "Batch [240/313], Loss: 0.0178\n",
      "Batch [270/313], Loss: 0.0311\n",
      "Batch [300/313], Loss: 0.0101\n",
      "Epoch [5/20], Loss: 0.0109\n",
      "Validation loss decreased (0.011266 --> 0.010917).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0091\n",
      "Batch [60/313], Loss: 0.0134\n",
      "Batch [90/313], Loss: 0.0104\n",
      "Batch [120/313], Loss: 0.0110\n",
      "Batch [150/313], Loss: 0.0172\n",
      "Batch [180/313], Loss: 0.0087\n",
      "Batch [210/313], Loss: 0.0089\n",
      "Batch [240/313], Loss: 0.0139\n",
      "Batch [270/313], Loss: 0.0251\n",
      "Batch [300/313], Loss: 0.0147\n",
      "Epoch [6/20], Loss: 0.0121\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0159\n",
      "Batch [60/313], Loss: 0.0070\n",
      "Batch [90/313], Loss: 0.0143\n",
      "Batch [120/313], Loss: 0.0119\n",
      "Batch [150/313], Loss: 0.0069\n",
      "Batch [180/313], Loss: 0.0219\n",
      "Batch [210/313], Loss: 0.0081\n",
      "Batch [240/313], Loss: 0.0192\n",
      "Batch [270/313], Loss: 0.0098\n",
      "Batch [300/313], Loss: 0.0147\n",
      "Epoch [7/20], Loss: 0.0104\n",
      "Validation loss decreased (0.010917 --> 0.010378).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0135\n",
      "Batch [60/313], Loss: 0.0067\n",
      "Batch [90/313], Loss: 0.0107\n",
      "Batch [120/313], Loss: 0.0181\n",
      "Batch [150/313], Loss: 0.0261\n",
      "Batch [180/313], Loss: 0.0102\n",
      "Batch [210/313], Loss: 0.0137\n",
      "Batch [240/313], Loss: 0.0082\n",
      "Batch [270/313], Loss: 0.0113\n",
      "Batch [300/313], Loss: 0.0105\n",
      "Epoch [8/20], Loss: 0.0092\n",
      "Validation loss decreased (0.010378 --> 0.009177).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0151\n",
      "Batch [60/313], Loss: 0.0109\n",
      "Batch [90/313], Loss: 0.0093\n",
      "Batch [120/313], Loss: 0.0095\n",
      "Batch [150/313], Loss: 0.0093\n",
      "Batch [180/313], Loss: 0.0294\n",
      "Batch [210/313], Loss: 0.0112\n",
      "Batch [240/313], Loss: 0.0083\n",
      "Batch [270/313], Loss: 0.0116\n",
      "Batch [300/313], Loss: 0.0189\n",
      "Epoch [9/20], Loss: 0.0098\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0070\n",
      "Batch [60/313], Loss: 0.0083\n",
      "Batch [90/313], Loss: 0.0072\n",
      "Batch [120/313], Loss: 0.0053\n",
      "Batch [150/313], Loss: 0.0150\n",
      "Batch [180/313], Loss: 0.0147\n",
      "Batch [210/313], Loss: 0.0088\n",
      "Batch [240/313], Loss: 0.0114\n",
      "Batch [270/313], Loss: 0.0182\n",
      "Batch [300/313], Loss: 0.0116\n",
      "Epoch [10/20], Loss: 0.0104\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0079\n",
      "Batch [60/313], Loss: 0.0157\n",
      "Batch [90/313], Loss: 0.0044\n",
      "Batch [120/313], Loss: 0.0080\n",
      "Batch [150/313], Loss: 0.0090\n",
      "Batch [180/313], Loss: 0.0144\n",
      "Batch [210/313], Loss: 0.0076\n",
      "Batch [240/313], Loss: 0.0174\n",
      "Batch [270/313], Loss: 0.0074\n",
      "Batch [300/313], Loss: 0.0152\n",
      "Epoch [11/20], Loss: 0.0099\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0063\n",
      "Batch [60/313], Loss: 0.0088\n",
      "Batch [90/313], Loss: 0.0077\n",
      "Batch [120/313], Loss: 0.0119\n",
      "Batch [150/313], Loss: 0.0042\n",
      "Batch [180/313], Loss: 0.0149\n",
      "Batch [210/313], Loss: 0.0107\n",
      "Batch [240/313], Loss: 0.0069\n",
      "Batch [270/313], Loss: 0.0075\n",
      "Batch [300/313], Loss: 0.0107\n",
      "Epoch [12/20], Loss: 0.0089\n",
      "Validation loss decreased (0.009177 --> 0.008859).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0065\n",
      "Batch [60/313], Loss: 0.0236\n",
      "Batch [90/313], Loss: 0.0092\n",
      "Batch [120/313], Loss: 0.0075\n",
      "Batch [150/313], Loss: 0.0146\n",
      "Batch [180/313], Loss: 0.0146\n",
      "Batch [210/313], Loss: 0.0231\n",
      "Batch [240/313], Loss: 0.0036\n",
      "Batch [270/313], Loss: 0.0056\n",
      "Batch [300/313], Loss: 0.0119\n",
      "Epoch [13/20], Loss: 0.0092\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0103\n",
      "Batch [60/313], Loss: 0.0169\n",
      "Batch [90/313], Loss: 0.0087\n",
      "Batch [120/313], Loss: 0.0086\n",
      "Batch [150/313], Loss: 0.0046\n",
      "Batch [180/313], Loss: 0.0134\n",
      "Batch [210/313], Loss: 0.0187\n",
      "Batch [240/313], Loss: 0.0097\n",
      "Batch [270/313], Loss: 0.0079\n",
      "Batch [300/313], Loss: 0.0316\n",
      "Epoch [14/20], Loss: 0.0091\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0077\n",
      "Batch [60/313], Loss: 0.0185\n",
      "Batch [90/313], Loss: 0.0118\n",
      "Batch [120/313], Loss: 0.0117\n",
      "Batch [150/313], Loss: 0.0082\n",
      "Batch [180/313], Loss: 0.0088\n",
      "Batch [210/313], Loss: 0.0084\n",
      "Batch [240/313], Loss: 0.0250\n",
      "Batch [270/313], Loss: 0.0068\n",
      "Batch [300/313], Loss: 0.0105\n",
      "Epoch [15/20], Loss: 0.0088\n",
      "Validation loss decreased (0.008859 --> 0.008843).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0300\n",
      "Batch [60/313], Loss: 0.0097\n",
      "Batch [90/313], Loss: 0.0146\n",
      "Batch [120/313], Loss: 0.0058\n",
      "Batch [150/313], Loss: 0.0077\n",
      "Batch [180/313], Loss: 0.0049\n",
      "Batch [210/313], Loss: 0.0082\n",
      "Batch [240/313], Loss: 0.0317\n",
      "Batch [270/313], Loss: 0.0101\n",
      "Batch [300/313], Loss: 0.0115\n",
      "Epoch [16/20], Loss: 0.0096\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0069\n",
      "Batch [60/313], Loss: 0.0070\n",
      "Batch [90/313], Loss: 0.0121\n",
      "Batch [120/313], Loss: 0.0421\n",
      "Batch [150/313], Loss: 0.0077\n",
      "Batch [180/313], Loss: 0.0092\n",
      "Batch [210/313], Loss: 0.0104\n",
      "Batch [240/313], Loss: 0.0088\n",
      "Batch [270/313], Loss: 0.0117\n",
      "Batch [300/313], Loss: 0.0095\n",
      "Epoch [17/20], Loss: 0.0090\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0041\n",
      "Batch [60/313], Loss: 0.0064\n",
      "Batch [90/313], Loss: 0.0058\n",
      "Batch [120/313], Loss: 0.0032\n",
      "Batch [150/313], Loss: 0.0044\n",
      "Batch [180/313], Loss: 0.0246\n",
      "Batch [210/313], Loss: 0.0060\n",
      "Batch [240/313], Loss: 0.0084\n",
      "Batch [270/313], Loss: 0.0076\n",
      "Batch [300/313], Loss: 0.0180\n",
      "Epoch [18/20], Loss: 0.0075\n",
      "Validation loss decreased (0.008843 --> 0.007508).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0075\n",
      "Batch [60/313], Loss: 0.0047\n",
      "Batch [90/313], Loss: 0.0151\n",
      "Batch [120/313], Loss: 0.0082\n",
      "Batch [150/313], Loss: 0.0064\n",
      "Batch [180/313], Loss: 0.0063\n",
      "Batch [210/313], Loss: 0.0114\n",
      "Batch [240/313], Loss: 0.0077\n",
      "Batch [270/313], Loss: 0.0041\n",
      "Batch [300/313], Loss: 0.0054\n",
      "Epoch [19/20], Loss: 0.0078\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0099\n",
      "Batch [60/313], Loss: 0.0102\n",
      "Batch [90/313], Loss: 0.0086\n",
      "Batch [120/313], Loss: 0.0070\n",
      "Batch [150/313], Loss: 0.0329\n",
      "Batch [180/313], Loss: 0.0162\n",
      "Batch [210/313], Loss: 0.0110\n",
      "Batch [240/313], Loss: 0.0111\n",
      "Batch [270/313], Loss: 0.0068\n",
      "Batch [300/313], Loss: 0.0087\n",
      "Epoch [20/20], Loss: 0.0081\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████                            | 7/20 [28:52<56:51, 262.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 7   Loss : 1.8418288753509522   Accuracy : 0.6598\n",
      "Batch [30/313], Loss: 0.0089\n",
      "Batch [60/313], Loss: 0.0063\n",
      "Batch [90/313], Loss: 0.0070\n",
      "Batch [120/313], Loss: 0.0145\n",
      "Batch [150/313], Loss: 0.0063\n",
      "Batch [180/313], Loss: 0.0184\n",
      "Batch [210/313], Loss: 0.0120\n",
      "Batch [240/313], Loss: 0.0089\n",
      "Batch [270/313], Loss: 0.0061\n",
      "Batch [300/313], Loss: 0.0081\n",
      "Epoch [1/20], Loss: 0.0091\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0121\n",
      "Batch [60/313], Loss: 0.0100\n",
      "Batch [90/313], Loss: 0.0058\n",
      "Batch [120/313], Loss: 0.0175\n",
      "Batch [150/313], Loss: 0.0155\n",
      "Batch [180/313], Loss: 0.0055\n",
      "Batch [210/313], Loss: 0.0114\n",
      "Batch [240/313], Loss: 0.0253\n",
      "Batch [270/313], Loss: 0.0142\n",
      "Batch [300/313], Loss: 0.0064\n",
      "Epoch [2/20], Loss: 0.0084\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Batch [30/313], Loss: 0.0089\n",
      "Batch [60/313], Loss: 0.0046\n",
      "Batch [90/313], Loss: 0.0074\n",
      "Batch [120/313], Loss: 0.0111\n",
      "Batch [150/313], Loss: 0.0078\n",
      "Batch [180/313], Loss: 0.0175\n",
      "Batch [210/313], Loss: 0.0039\n",
      "Batch [240/313], Loss: 0.0091\n",
      "Batch [270/313], Loss: 0.0070\n",
      "Batch [300/313], Loss: 0.0073\n",
      "Epoch [3/20], Loss: 0.0071\n",
      "Validation loss decreased (0.007508 --> 0.007107).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0054\n",
      "Batch [60/313], Loss: 0.0081\n",
      "Batch [90/313], Loss: 0.0077\n",
      "Batch [120/313], Loss: 0.0049\n",
      "Batch [150/313], Loss: 0.0256\n",
      "Batch [180/313], Loss: 0.0117\n",
      "Batch [210/313], Loss: 0.0066\n",
      "Batch [240/313], Loss: 0.0183\n",
      "Batch [270/313], Loss: 0.0140\n",
      "Batch [300/313], Loss: 0.0077\n",
      "Epoch [4/20], Loss: 0.0074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0091\n",
      "Batch [60/313], Loss: 0.0275\n",
      "Batch [90/313], Loss: 0.0118\n",
      "Batch [120/313], Loss: 0.0052\n",
      "Batch [150/313], Loss: 0.0095\n",
      "Batch [180/313], Loss: 0.0084\n",
      "Batch [210/313], Loss: 0.0167\n",
      "Batch [240/313], Loss: 0.0099\n",
      "Batch [270/313], Loss: 0.0117\n",
      "Batch [300/313], Loss: 0.0098\n",
      "Epoch [5/20], Loss: 0.0077\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0146\n",
      "Batch [60/313], Loss: 0.0059\n",
      "Batch [90/313], Loss: 0.0122\n",
      "Batch [120/313], Loss: 0.0073\n",
      "Batch [150/313], Loss: 0.0049\n",
      "Batch [180/313], Loss: 0.0126\n",
      "Batch [210/313], Loss: 0.0091\n",
      "Batch [240/313], Loss: 0.0208\n",
      "Batch [270/313], Loss: 0.0073\n",
      "Batch [300/313], Loss: 0.0051\n",
      "Epoch [6/20], Loss: 0.0078\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0111\n",
      "Batch [60/313], Loss: 0.0171\n",
      "Batch [90/313], Loss: 0.0112\n",
      "Batch [120/313], Loss: 0.0072\n",
      "Batch [150/313], Loss: 0.0068\n",
      "Batch [180/313], Loss: 0.0070\n",
      "Batch [210/313], Loss: 0.0096\n",
      "Batch [240/313], Loss: 0.0086\n",
      "Batch [270/313], Loss: 0.0052\n",
      "Batch [300/313], Loss: 0.0060\n",
      "Epoch [7/20], Loss: 0.0065\n",
      "Validation loss decreased (0.007107 --> 0.006531).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0110\n",
      "Batch [60/313], Loss: 0.0082\n",
      "Batch [90/313], Loss: 0.0127\n",
      "Batch [120/313], Loss: 0.0076\n",
      "Batch [150/313], Loss: 0.0047\n",
      "Batch [180/313], Loss: 0.0061\n",
      "Batch [210/313], Loss: 0.0076\n",
      "Batch [240/313], Loss: 0.0157\n",
      "Batch [270/313], Loss: 0.0070\n",
      "Batch [300/313], Loss: 0.0038\n",
      "Epoch [8/20], Loss: 0.0062\n",
      "Validation loss decreased (0.006531 --> 0.006182).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0136\n",
      "Batch [60/313], Loss: 0.0046\n",
      "Batch [90/313], Loss: 0.0121\n",
      "Batch [120/313], Loss: 0.0063\n",
      "Batch [150/313], Loss: 0.0064\n",
      "Batch [180/313], Loss: 0.0046\n",
      "Batch [210/313], Loss: 0.0142\n",
      "Batch [240/313], Loss: 0.0051\n",
      "Batch [270/313], Loss: 0.0071\n",
      "Batch [300/313], Loss: 0.0040\n",
      "Epoch [9/20], Loss: 0.0065\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0080\n",
      "Batch [60/313], Loss: 0.0065\n",
      "Batch [90/313], Loss: 0.0066\n",
      "Batch [120/313], Loss: 0.0191\n",
      "Batch [150/313], Loss: 0.0035\n",
      "Batch [180/313], Loss: 0.0046\n",
      "Batch [210/313], Loss: 0.0079\n",
      "Batch [240/313], Loss: 0.0112\n",
      "Batch [270/313], Loss: 0.0074\n",
      "Batch [300/313], Loss: 0.0044\n",
      "Epoch [10/20], Loss: 0.0071\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0132\n",
      "Batch [60/313], Loss: 0.0040\n",
      "Batch [90/313], Loss: 0.0113\n",
      "Batch [120/313], Loss: 0.0041\n",
      "Batch [150/313], Loss: 0.0081\n",
      "Batch [180/313], Loss: 0.0114\n",
      "Batch [210/313], Loss: 0.0169\n",
      "Batch [240/313], Loss: 0.0083\n",
      "Batch [270/313], Loss: 0.0028\n",
      "Batch [300/313], Loss: 0.0048\n",
      "Epoch [11/20], Loss: 0.0063\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0058\n",
      "Batch [60/313], Loss: 0.0090\n",
      "Batch [90/313], Loss: 0.0029\n",
      "Batch [120/313], Loss: 0.0062\n",
      "Batch [150/313], Loss: 0.0059\n",
      "Batch [180/313], Loss: 0.0064\n",
      "Batch [210/313], Loss: 0.0120\n",
      "Batch [240/313], Loss: 0.0049\n",
      "Batch [270/313], Loss: 0.0061\n",
      "Batch [300/313], Loss: 0.0036\n",
      "Epoch [12/20], Loss: 0.0051\n",
      "Validation loss decreased (0.006182 --> 0.005103).  Saving model ...\n",
      "Batch [30/313], Loss: 0.0097\n",
      "Batch [60/313], Loss: 0.0084\n",
      "Batch [90/313], Loss: 0.0073\n",
      "Batch [120/313], Loss: 0.0031\n",
      "Batch [150/313], Loss: 0.0075\n",
      "Batch [180/313], Loss: 0.0032\n",
      "Batch [210/313], Loss: 0.0120\n",
      "Batch [240/313], Loss: 0.0100\n",
      "Batch [270/313], Loss: 0.0047\n",
      "Batch [300/313], Loss: 0.0161\n",
      "Epoch [13/20], Loss: 0.0060\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Batch [30/313], Loss: 0.0095\n",
      "Batch [60/313], Loss: 0.0098\n",
      "Batch [90/313], Loss: 0.0033\n",
      "Batch [120/313], Loss: 0.0116\n",
      "Batch [150/313], Loss: 0.0096\n",
      "Batch [180/313], Loss: 0.0054\n",
      "Batch [210/313], Loss: 0.0061\n",
      "Batch [240/313], Loss: 0.0063\n",
      "Batch [270/313], Loss: 0.0093\n",
      "Batch [300/313], Loss: 0.0113\n",
      "Epoch [14/20], Loss: 0.0066\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Batch [30/313], Loss: 0.0077\n",
      "Batch [60/313], Loss: 0.0307\n",
      "Batch [90/313], Loss: 0.0045\n",
      "Batch [120/313], Loss: 0.0054\n",
      "Batch [150/313], Loss: 0.0088\n",
      "Batch [180/313], Loss: 0.0044\n",
      "Batch [210/313], Loss: 0.0078\n",
      "Batch [240/313], Loss: 0.0039\n",
      "Batch [270/313], Loss: 0.0097\n",
      "Batch [300/313], Loss: 0.0049\n",
      "Epoch [15/20], Loss: 0.0072\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Batch [30/313], Loss: 0.0082\n",
      "Batch [60/313], Loss: 0.0110\n",
      "Batch [90/313], Loss: 0.0136\n",
      "Batch [120/313], Loss: 0.0079\n",
      "Batch [150/313], Loss: 0.0048\n",
      "Batch [180/313], Loss: 0.0055\n",
      "Batch [210/313], Loss: 0.0068\n",
      "Batch [240/313], Loss: 0.0038\n",
      "Batch [270/313], Loss: 0.0067\n",
      "Batch [300/313], Loss: 0.0031\n",
      "Epoch [16/20], Loss: 0.0067\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Batch [30/313], Loss: 0.0040\n",
      "Batch [60/313], Loss: 0.0087\n",
      "Batch [90/313], Loss: 0.0035\n",
      "Batch [120/313], Loss: 0.0045\n",
      "Batch [150/313], Loss: 0.0094\n",
      "Batch [180/313], Loss: 0.0343\n",
      "Batch [210/313], Loss: 0.0054\n",
      "Batch [240/313], Loss: 0.0040\n",
      "Batch [270/313], Loss: 0.0047\n",
      "Batch [300/313], Loss: 0.0034\n",
      "Epoch [17/20], Loss: 0.0058\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 8/20 [32:41<50:21, 251.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 8   Loss : 1.8662958948135375   Accuracy : 0.6599\n",
      "Batch [30/313], Loss: 0.0058\n",
      "Batch [60/313], Loss: 0.0151\n",
      "Batch [90/313], Loss: 0.0054\n",
      "Batch [120/313], Loss: 0.0045\n",
      "Batch [150/313], Loss: 0.0077\n",
      "Batch [180/313], Loss: 0.0070\n",
      "Batch [210/313], Loss: 0.0055\n",
      "Batch [240/313], Loss: 0.0145\n",
      "Batch [270/313], Loss: 0.0115\n",
      "Batch [300/313], Loss: 0.0401\n",
      "Epoch [1/20], Loss: 0.0059\n",
      "EarlyStopping counter: 6 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████▎                       | 9/20 [32:56<32:33, 177.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 9   Loss : 1.865315894317627   Accuracy : 0.6625\n",
      "Batch [30/313], Loss: 0.0085\n",
      "Batch [60/313], Loss: 0.0051\n",
      "Batch [90/313], Loss: 0.0128\n",
      "Batch [120/313], Loss: 0.0051\n",
      "Batch [150/313], Loss: 0.0047\n",
      "Batch [180/313], Loss: 0.0029\n",
      "Batch [210/313], Loss: 0.0072\n",
      "Batch [240/313], Loss: 0.0040\n",
      "Batch [270/313], Loss: 0.0064\n",
      "Batch [300/313], Loss: 0.0389\n",
      "Epoch [1/20], Loss: 0.0050\n",
      "Validation loss decreased (0.005103 --> 0.005028).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████                     | 10/20 [33:10<21:13, 127.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 10   Loss : 1.8631847387313842   Accuracy : 0.6648\n",
      "Batch [30/313], Loss: 0.0029\n",
      "Batch [60/313], Loss: 0.0093\n",
      "Batch [90/313], Loss: 0.0063\n",
      "Batch [120/313], Loss: 0.0055\n",
      "Batch [150/313], Loss: 0.0029\n",
      "Batch [180/313], Loss: 0.0043\n",
      "Batch [210/313], Loss: 0.0041\n",
      "Batch [240/313], Loss: 0.0049\n",
      "Batch [270/313], Loss: 0.0034\n",
      "Batch [300/313], Loss: 0.0038\n",
      "Epoch [1/20], Loss: 0.0047\n",
      "Validation loss decreased (0.005028 --> 0.004724).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████▋                   | 11/20 [33:25<13:55, 92.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 11   Loss : 1.8563789834976197   Accuracy : 0.6645\n",
      "Batch [30/313], Loss: 0.0050\n",
      "Batch [60/313], Loss: 0.0060\n",
      "Batch [90/313], Loss: 0.0029\n",
      "Batch [120/313], Loss: 0.0036\n",
      "Batch [150/313], Loss: 0.0057\n",
      "Batch [180/313], Loss: 0.0032\n",
      "Batch [210/313], Loss: 0.0075\n",
      "Batch [240/313], Loss: 0.0051\n",
      "Batch [270/313], Loss: 0.0318\n",
      "Batch [300/313], Loss: 0.0079\n",
      "Epoch [1/20], Loss: 0.0047\n",
      "Validation loss decreased (0.004724 --> 0.004696).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 12/20 [33:39<09:11, 68.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 12   Loss : 1.8693509323120117   Accuracy : 0.6637\n",
      "Batch [30/313], Loss: 0.0086\n",
      "Batch [60/313], Loss: 0.0083\n",
      "Batch [90/313], Loss: 0.0064\n",
      "Batch [120/313], Loss: 0.0065\n",
      "Batch [150/313], Loss: 0.0085\n",
      "Batch [180/313], Loss: 0.0054\n",
      "Batch [210/313], Loss: 0.0053\n",
      "Batch [240/313], Loss: 0.0079\n",
      "Batch [270/313], Loss: 0.0039\n",
      "Batch [300/313], Loss: 0.0075\n",
      "Epoch [1/20], Loss: 0.0047\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████▉               | 13/20 [33:54<06:07, 52.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 13   Loss : 1.8668282299041747   Accuracy : 0.6618\n",
      "Batch [30/313], Loss: 0.0062\n",
      "Batch [60/313], Loss: 0.0039\n",
      "Batch [90/313], Loss: 0.0082\n",
      "Batch [120/313], Loss: 0.0071\n",
      "Batch [150/313], Loss: 0.0042\n",
      "Batch [180/313], Loss: 0.0028\n",
      "Batch [210/313], Loss: 0.0032\n",
      "Batch [240/313], Loss: 0.0031\n",
      "Batch [270/313], Loss: 0.0037\n",
      "Batch [300/313], Loss: 0.0103\n",
      "Epoch [1/20], Loss: 0.0044\n",
      "Validation loss decreased (0.004696 --> 0.004356).  Saving model ...\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 14/20 [34:08<04:05, 40.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 14   Loss : 1.8666073148727418   Accuracy : 0.665\n",
      "Batch [30/313], Loss: 0.0026\n",
      "Batch [60/313], Loss: 0.0030\n",
      "Batch [90/313], Loss: 0.0196\n",
      "Batch [120/313], Loss: 0.0124\n",
      "Batch [150/313], Loss: 0.0029\n",
      "Batch [180/313], Loss: 0.0408\n",
      "Batch [210/313], Loss: 0.0034\n",
      "Batch [240/313], Loss: 0.0077\n",
      "Batch [270/313], Loss: 0.0088\n",
      "Batch [300/313], Loss: 0.0149\n",
      "Epoch [1/20], Loss: 0.0057\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████▎          | 15/20 [34:23<02:45, 33.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 15   Loss : 1.8768393379211425   Accuracy : 0.6604\n",
      "Batch [30/313], Loss: 0.0045\n",
      "Batch [60/313], Loss: 0.0030\n",
      "Batch [90/313], Loss: 0.0357\n",
      "Batch [120/313], Loss: 0.0023\n",
      "Batch [150/313], Loss: 0.0063\n",
      "Batch [180/313], Loss: 0.0048\n",
      "Batch [210/313], Loss: 0.0096\n",
      "Batch [240/313], Loss: 0.0033\n",
      "Batch [270/313], Loss: 0.0109\n",
      "Batch [300/313], Loss: 0.0021\n",
      "Epoch [1/20], Loss: 0.0049\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 16/20 [34:37<01:49, 27.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 16   Loss : 1.8683209217071532   Accuracy : 0.665\n",
      "Batch [30/313], Loss: 0.0057\n",
      "Batch [60/313], Loss: 0.0051\n",
      "Batch [90/313], Loss: 0.0055\n",
      "Batch [120/313], Loss: 0.0069\n",
      "Batch [150/313], Loss: 0.0046\n",
      "Batch [180/313], Loss: 0.0068\n",
      "Batch [210/313], Loss: 0.0100\n",
      "Batch [240/313], Loss: 0.0041\n",
      "Batch [270/313], Loss: 0.0042\n",
      "Batch [300/313], Loss: 0.0087\n",
      "Epoch [1/20], Loss: 0.0056\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████▌      | 17/20 [34:52<01:10, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 17   Loss : 1.8644814086914063   Accuracy : 0.6619\n",
      "Batch [30/313], Loss: 0.0055\n",
      "Batch [60/313], Loss: 0.0057\n",
      "Batch [90/313], Loss: 0.0042\n",
      "Batch [120/313], Loss: 0.0027\n",
      "Batch [150/313], Loss: 0.0039\n",
      "Batch [180/313], Loss: 0.0042\n",
      "Batch [210/313], Loss: 0.0038\n",
      "Batch [240/313], Loss: 0.0040\n",
      "Batch [270/313], Loss: 0.0059\n",
      "Batch [300/313], Loss: 0.0035\n",
      "Epoch [1/20], Loss: 0.0051\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 18/20 [35:07<00:41, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 18   Loss : 1.8687571321487426   Accuracy : 0.6612\n",
      "Batch [30/313], Loss: 0.0108\n",
      "Batch [60/313], Loss: 0.0092\n",
      "Batch [90/313], Loss: 0.0033\n",
      "Batch [120/313], Loss: 0.0096\n",
      "Batch [150/313], Loss: 0.0039\n",
      "Batch [180/313], Loss: 0.0093\n",
      "Batch [210/313], Loss: 0.0044\n",
      "Batch [240/313], Loss: 0.0057\n",
      "Batch [270/313], Loss: 0.0137\n",
      "Batch [300/313], Loss: 0.0080\n",
      "Epoch [1/20], Loss: 0.0057\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████▊  | 19/20 [35:21<00:19, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 19   Loss : 1.8856626342773437   Accuracy : 0.6625\n",
      "Batch [30/313], Loss: 0.0076\n",
      "Batch [60/313], Loss: 0.0071\n",
      "Batch [90/313], Loss: 0.0074\n",
      "Batch [120/313], Loss: 0.0416\n",
      "Batch [150/313], Loss: 0.0035\n",
      "Batch [180/313], Loss: 0.0056\n",
      "Batch [210/313], Loss: 0.0053\n",
      "Batch [240/313], Loss: 0.0151\n",
      "Batch [270/313], Loss: 0.0040\n",
      "Batch [300/313], Loss: 0.0077\n",
      "Epoch [1/20], Loss: 0.0048\n",
      "EarlyStopping counter: 6 out of 5\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 20/20 [35:36<00:00, 106.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Result = Epoch : 20   Loss : 1.8754571912765503   Accuracy : 0.6657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "    train_model(net, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "    test_loss, test_accuracy = test_model(net, test_loader, criterion, epoch)\n",
    "    writer.add_scalar(\"Test Loss\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Test Accuracy\", test_accuracy, epoch)\n",
    "    print(f\"Processing Result = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be87a752-18b4-426b-a826-8207fe856c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data, target in val_loader:\n",
    "#     data, target = data.to(device), target.to(device)\n",
    "#     output = model(data)\n",
    "#     print(\"Sample output:\", output)  # 모델의 출력 예시를 출력\n",
    "#     break  # 첫 번째 배치만 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa545b-514f-4839-81ac-2ee9d4043d64",
   "metadata": {},
   "source": [
    "**Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027bb618-b06d-4510-8d8c-45a86d2b9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result of ResNet = Epoch : 20   Loss : 1.8754571912765503   Accuracy : 0.6657\n"
     ]
    }
   ],
   "source": [
    "print(f\" Result of ResNet = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba4f2a-2cb2-47a0-97ab-cb92669dd063",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aa22644-2f03-4165-ac1e-1b15e4b5ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000개 테스트 이미지에서 모델 정확도: 66.57 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('10000개 테스트 이미지에서 모델 정확도: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd9a55-51f7-4820-86dc-bb2a531134a0",
   "metadata": {},
   "source": [
    "**Visualization of average loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6528ff87-705d-43c3-b799-baffbe11161f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 훈련과정에서 손실을 기록\n",
    "    train_loss = 0\n",
    "    total_samples = 0\n",
    "    net.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        total_samples += inputs.size(0)\n",
    "    \n",
    "    train_losses.append(train_loss / total_samples)\n",
    "\n",
    "    # 평가 과정에서 손실과 정확도를 기록\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_losses.append(test_loss / total)\n",
    "    test_accuracies.append(correct / total)\n",
    "\n",
    "# 손실과 정확도 그래프 그리기\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fe74b-41e9-41c7-8f1d-ac320f2b821e",
   "metadata": {},
   "source": [
    "**Top-1 Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "127d3a88-236c-4833-afa4-ad772f878041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top1_accuracy(model, device, data_loader, criterion):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            # # 각 샘플에 대한 예측 결과와 실제 레이블 출력\n",
    "            # for i in range(data.size(0)):\n",
    "            #     print(f\"Sample {i + 1}: Predicted = {predicted[i].item()}, Actual = {target[i].item()}\")\n",
    "\n",
    "    top1_accuracy = 100 * correct / total\n",
    "    print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c70cb58b-59a7-4921-b66d-337ae39a3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 65.20%\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련 후 검증 데이터셋에 대한 Top-1 정확도 계산 및 출력\n",
    "calculate_top1_accuracy(net, device, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9685776-2742-4899-bc03-69bab0fdf760",
   "metadata": {},
   "source": [
    "**Top-5 Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3833597-d6f0-4061-9acd-98773f9c2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_print_top5_accuracy(model, device, data_loader, criterion):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            # Top-5 예측 결과 가져오기\n",
    "            _, predicted_top5 = torch.topk(outputs, 5, dim=1)\n",
    "            total += target.size(0)\n",
    "            \n",
    "            # 예측된 Top-5 내에 실제 레이블이 있는지 확인\n",
    "            correct += (predicted_top5 == target.view(-1, 1)).sum().item()\n",
    "\n",
    "    top5_accuracy = 100 * correct / total\n",
    "    print(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "606ba241-4e9a-49c1-8f74-99b59f6649ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy: 88.06%\n"
     ]
    }
   ],
   "source": [
    "calculate_and_print_top5_accuracy(net, device, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700b560-e4d2-4c26-9d1f-ddd264c808a6",
   "metadata": {},
   "source": [
    "**Super Class Accuracy**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
